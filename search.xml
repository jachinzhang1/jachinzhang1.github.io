<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Arcaea第1章主线剧情解读</title>
    <url>/2025/02/07/ArcCh1Interpretation/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script>
  <div class="note-large yellow">
    <div class="notel-title rounded-t-lg p-3 font-bold text-lg flex flex-row gap-2 items-center">
      <p>参考</p>

    </div>
    <div class="notel-content">
      <ul>
<li><a class="link" 
 href="https://www.bilibili.com/opus/683108200712503298" >[自整理][小更新]Arcaea主线剧情第一幕全整理<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link" 
 href="https://www.bilibili.com/opus/684984779318231056" >[Arcaea]主线剧情解析——聊聊Arcaea的故事<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
</ul>

    </div>
  </div>

  <div class="note p-4 mb-4 rounded-small blue">
    <p>这部分剧情的<b>原文</b>见此博客：<a
href="/2025/02/06/ArcaeaStoryChapter1">Arcaea故事模式第1章剧情原文</a></p>

  </div>
<h2 id="写在前面">写在前面</h2>
<p>众所周知，Arcaea的剧情文字以抽象和晦涩难懂著称。推动剧情的文字夹杂着大量描述性的辞藻，极易使人失去仔细阅读下去的耐心。<del class="mask">尤其是主线曲包的歌曲要阅读完剧情才能打，文字故弄玄虚加上急着打歌谁会去慢慢看剧情啊！</del>因此大多数人对整个故事的印象基本停留在：<u>光和对立诞生了
-&gt; 光和对立相遇了 -&gt; 对立要打光光 -&gt; 两人势均力敌 -&gt;
光开始被压制 -&gt; 光频临死亡 -&gt; 光把对立捅死了 -&gt;
光把对立复活了（HE线） -&gt; 二人幸终（囍）</u>。</p>
<p>不过作为一个源批，对梳理清楚整个Arcaea剧情的走向这件事情还是具有一定的热情的（毕竟这是一个连载了七年的故事啊）。主线第一章的文本量大约三四万字，差不多相当于一篇短篇小说的体量。对应剧情配合主线曲目食用更佳。</p>
<p>（虽然616把故事情节写的很抽象，但描写战斗场面和过程的时候对整体的气氛把握还是很好的，后期的风暴对立给人的压迫感很强。）</p>
<p>这篇解读我会配合个人对剧情文本的理解，结合一些参考的资料和原文附注，尽可能把这个关于两名少女——来自光明和纷争的灵魂——的故事讲清楚。</p>
<h2 id="arcaea之始">Arcaea之始</h2>
<h3 id="光被无意义禁锢的神之少女">光：被“无意义”禁锢的神之少女</h3>
<p>事实上，“光”和“对立”——这两名少女的真实名字剧情并未给出。我们姑且就这样称呼Arcaea世界和现实世界中的她们。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/arcaea_story_cg/Story_E-2_epilogue_cg.jpg"
                      
                ></p>
<p>现实世界中的光是一名自闭、冷漠的少女。她的房间常被昏暗笼罩、房门紧锁。她的父母对她关爱有加，但她心里感受不到，<b>她感受不到来自自己与他人的情感，她的世界一直是虚无的。</b><del class="mask">这似乎是典型的抑郁症状。</del>长时间的虚无摧毁了她的心智，她开始自暴自弃。</p>

  <div class="note p-4 mb-4 rounded-small red">
    <p>为什么她不能消失？ 为什么她不能走向虚无？ 为什么她会拥有这些想法？
为什么她的脑海会浮现这个？
为什么她不能消失……？她将指甲刺入她的小腿。她张大双眼凝视，呼吸急促。她希望可以逃离这一切。</p>
<p>白发少女是一个神。白发少女有麻烦了。</p>
<p><i>——E-2（完美之愿）</i></p>

  </div>
<p>没错，光是一个神。但她自己并不了解这个事实，她总是抱怨自己为什么要诞生在这个世界上，这个世界不能带给她丝毫快乐。于是她许下了一个愿望，希望自己能受到这个愿望的庇护。而这个愿望成真了：</p>
<p><b>“我要某个能让我快乐的地方。”</b></p>
<p>这个世界有一个无意义的名字：<b>Arcaea</b>。</p>
<p>Arcaea世界是一个类似概念的存在，它能够跨越无穷的时间和现实的维度，延伸到无数地方。<del class="mask">怎么有点像圆环之理（bushi）</del>这个世界可以感知到现实世界中死前具有执念的灵魂，选中它，通过读取它的记忆复制一个形象，置于自己的世界。这个形象（复制体）可以永久地存在于这个世界。而原先那个死者的灵魂则离开这里。</p>
<p>看起来这是一个美好的世界——它可以为逝者提供一个温暖的归宿。但事实上，这些灵魂不具备自我，它们就像只能存在于镜子一般，是一个回忆构成的假象。Arcaea就像一个沉浸于回忆之中的牢笼。<b>这是一个无意义的世界。</b></p>
<p>而且遗憾的是，这个世界并不能拯救它的造物主——光。</p>
<p>光并没有死。她的灵魂仍然固定在现实世界中，但Arcaea不具备思考的能力，它只会尽其所能强行复制那个灵魂。因此，光来到了Arcaea。</p>

  <div class="note p-4 mb-4 rounded-small red">
    <p>虽然她许下愿望时还活着，但她仍然强烈感到"死亡"的感觉。</p>
<p>对此她完全没有想法；事实上，如果她试过，她就不会如此搞不清楚状况。她只想从那里为自己得到一些东西。这是有可能的，真的，如果她知道那些被Arcaea
之网抓住的命运， 她就会发现自己做了一件很棒的事。</p>
<p><i>——E-2（完美之愿）</i></p>

  </div>
<p>回到现实，光在一瞬间感受到了“死亡”，可能就是暗指这一瞬间她的灵魂被复制进了Arcaea。但她并没有情感，因此这点微不足道的感觉对她来说根本不算什么，她继续浑浑噩噩、毫无意义地生活着……</p>
<p>然而她的灵魂实在是过于沉重，所以即使是她所创造的Arcaea世界，也并未能够将她的灵魂完全复制下来，只能形成一个不存在任何记忆的残体，也就是玩家们自一开始便无比熟悉的
<b>光（Hikari）</b>。</p>
<h3 id="对立命运悲惨的天才少女">对立：命运悲惨的天才少女</h3>
<p>现实世界中的“对立”没有亲人和依靠——她无家可归。双亲、监护人、同期的信任<u>塑形者</u>，还有那些总是看不起她的人民全部都过世了。一位神使正在摧毁她的家园，她自己也即将被毁灭。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/arcaea_story_cg/Story_E-1_epilogue_cg.jpg"
                      
                ></p>
<p>她不愿放弃希望——她年轻、学识渊博，是特别的天选之人。她思考着，也许还有极小的机会能够使时间倒流，或者她自己成为某种“神”。但她做不到——她现在拥有的一切只剩下手中的玻璃碎片。“只靠她的意志并不能从虚无中制造力量。人可以想像得到的任何意志力她都具备，但这没有任何意义。她明白这个真相后，开始哭泣。”</p>
<p>在生命的最后一刻，她被神使带走。</p>

  <div class="note p-4 mb-4 rounded-small blue">
    <p>当天使降临时，这名黑发少女始终低着头。天使靠近她时，祂举起了祂的手。</p>
<p>没多久，她就被带走了。</p>
<p>这个孩子的名字已被忘却。</p>
<p>而她死亡的原因……远远超出她的理解。</p>
<p>没有人会记得她的存在。</p>
<p>但当她死亡时，另一个愿望带她离去。</p>
<p><i>——E-2（完美之愿）</i></p>

  </div>
<p>不过，她得到了一个“想要离开这个世界”的愿望，因此她的灵魂被Arcaea感知到了——它要复制对立的灵魂。但此刻对立精神的痛苦使得她的灵魂强度比肩于光。在Arcaea完成复制、企图摆脱对立的灵魂时，它却无能为力了，Arcaea已经无法再左右她的存在。对立的灵魂见证了被复制的<b>对立（Tairitsu）</b>的诞生，她甚至见证了自己的一生。</p>
<p>两名少女，来到了Arcaea。</p>
<h2 id="苏醒">苏醒</h2>
<h3 id="光无止境的快乐">光：无止境的快乐？</h3>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/arcaea_story_cg/Story_1-1_cg.jpg"
                      
                ></p>
<p>光在Arcaea世界中苏醒。</p>
<p>她像一个懵懂的孩子对这个世界充满了好奇，眼前的一切都令她无比惊喜。<b>“想要某个能够带来快乐的地方”</b>。Arcaea记住了她的愿望，无数携带美好回忆的碎片围绕在她的身边。</p>

  <div class="note p-4 mb-4 rounded-small red">
    <p>现在留给她的，有六个问题：何人、何事、何处、何时、何故与何情。
在这些疑问的包围下，她没有问出任何一个，也不想得到任何答案。Arcaea的光芒已经使她心满意足。
这是她与这个新世界的邂逅。</p>
<p><i>——1-1</i></p>

  </div>
<p>在接下来漫长的时间，它不断收集着美好的Arcaea，将它们投入自己铸就的那片人造天空。她从未体验过如此美妙的感受。但久而久之，她开始感到厌倦——无数次的重演已经麻痹了她的神经，身边的一切似乎已经变得令人不适。但继续沉浸其中似乎并不困难。</p>
<details class="red" data-header-exclude><summary><i class="fa-solid fa-chevron-right"></i>Zero Hikari线 </summary>
              <div class='content'>
              <p>她的思绪逐渐放空，她已经无法意识到自己做了什么，或者正在做什么。她的理智正一点点离她而去，只有美好的记忆存在于她的脑海之中。</p><p>在Arcaea的操纵之下，她已经无法意识到自己的存在，或者说，是她自己一步一步将自己引入了一个精心策划的陷阱。</p><p>“之后，一名女孩仰望着空无一物的苍天。她的思想终止了——与她的故事一起。”</p><p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/arcaea_story_cg/Story_1-ZR_cg.jpg"
                      
                ></p>
              </div>
            </details>
<p>然而此时出现异象。一片鲜红的、特殊的碎片划破了光的人造天空，使雾霾消散后落入了光的手中，碎片中的回忆，是<b>她自己的</b>、是她自苏醒以来如何与碎片起舞、如何用碎片取悦自己、如何一步一步地，给自己设下为了快乐而过度放纵的陷阱的回忆。她终于意识到，自己可能已经几个世纪以来都未曾思考过——<b>幸福早已抛弃了她。</b></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/arcaea_story_cg/Story_1-8_cg.jpg"
                      
                ></p>
<p>她开始感受到悔恨，过多的美好事物使得她开始觉得反胃，而她过去竟然对此毫无察觉。她紧紧的握住了自己的Arcaea碎片，以至于她的双手渗出了鲜血，她不断质问自己过去曾经遗忘过的许多问题，她想要获得答案。</p>
<p>终于，她意识到了来自Arcaea世界的疑问，她下定决心，探寻Arcaea世界的真相。他站了起来，发现自己发生了变化。<del class="mask">骨折光的诞生</del></p>
<h3 id="对立痛苦与绝望从未远离">对立：痛苦与绝望，从未远离</h3>
<p>自从对立在Arcaea的世界醒来，映射痛苦、悲惨回忆的玻璃碎片就一直跟着她，摆脱不掉。对立厌恶这些碎片，可无法摧毁它们。</p>

  <div class="note p-4 mb-4 rounded-small blue">
    <p>回忆。刻画着痛苦、背叛、嫉妒的回忆。</p>
<p>当她阻挡住眼前这片碎片时，其余的碎片也被影响了。它们就这么静止在空中，一动也不动。
她的脑袋左右晃动着。"这些只是……"</p>
<p>黑暗？它们只是纯粹的黑暗吗？但无论这些碎片在反射什么……她从中未见到一丝光芒。
哪怕是最小的火花，都会在一瞬间消失于她的视线。她紧咬嘴唇，毫不诙谐地微笑着。
"这算是什么低劣的玩笑？"她喃喃自语道，"这个世界只充满了痛苦……"</p>
<p>说出这番话后，就连她脸上的苦笑也消失了。</p>
<p><i>——2-2</i></p>

  </div>
<p>对立逐渐意识到，自己处于回忆组成的漩涡的中心，大部分是痛苦的回忆，愉快的回忆极其稀少，但确实存在。对立想尽早摆脱这一切，萌生了这样一个想法：不妨将这些痛苦回忆尽可能收集起来，然后集中摧毁。这个念头让她振奋了一些。尽管在很长一段时间里，对立一直被痛苦折磨着，但她为了希望、为了自己的信念，坚强地探索着Arcaea，收集了无数的苦难碎片（纷争碎片）。</p>
<p>对立发现了一个巨大的、盘旋延伸到天际的迷宫，那里充满了痛苦。她累了，但为了希望与信念，她还是信心满满地走向了迷宫，打算收集这里所有的苦难碎片。但她逐渐发现，自己被希望夹在中间，面前等待着她的只有无尽的痛苦。她逐渐对这个世界产生了自己理解的答案：<b>这个世界不存在任何意义。</b></p>
<details class="blue" data-header-exclude><summary><i class="fa-solid fa-chevron-right"></i>Axium Tairitsu线 </summary>
              <div class='content'>
              <p>从迷宫走出之后，对立认为自己已经坚强到足够承受任何的苦难，哪怕是零星的美妙回忆也不会动摇她的目标。她走进了一座罪孽的城堡，这里的每一堵墙都是由苦难砌成，而墙的每一面都布满了惨剧，每一个角落都由畏惧构成。</p><p>对这个世界纯粹的厌恶已经令她疯狂。这座城堡的中心有一个无比黑暗的事物——那是一段一个世界走向末日的回忆。她伸出了手，把那世界尽头收入了自己所搜集的无数回忆之中。这片存在颠覆了一切。伴随着那抹真诚的微笑与疲惫的笑声，她从天空中降落到了地面上。那座古老的塔楼在她的力量驱使下逐渐陨落，化为了一座废墟。——她与收集的痛苦回忆一同走向了毁灭。</p>
              </div>
            </details>
<p>无限的痛苦终究击垮了她。曾经的希望、目标、愉悦，此刻都离她而去。她的眼神转为一片黑暗，而她已经<b>与这些玻璃起了共鸣</b>。
围绕于她四周的回忆之壳开始崩裂。她就身处其中，站在那炫目的光芒前方。她已经没有任何情感了。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/arcaea_story_cg/Story_2-8_cg.jpg"
                      
                ></p>
<p>她不再激情地收集回忆。她近乎无意识地走在这世界之中。她自废墟之中找到了一把阳伞，一直带在了身边<del class="mask">（伞对立即病女诞生）</del>。她摧毁着又Arcaea组成的、承载着遥不可及的苍白世界的情景的乌鸦，她想要找到一个活物——供她摧残。</p>
<p>光即将成为她的目标。</p>
<h2 id="命运的相遇">命运的相遇</h2>
<p>在一处不起眼的废墟，光与对立相遇了——这对于两名少女来说都是一个意外。两人对此都露出了欣喜的笑容。只不过，光是因为也许眼前这名黑色的少女可以与自己结伴而行而感到高兴，而对立则是扭曲的狂喜与渴望，她可以折磨眼前这个白色的少女。</p>
<p>经过短暂的对话，她们各自表明自己的状态，光向对立提出合作的请求。</p>

  <div class="note p-4 mb-4 rounded-small purple">
    <p>她紧盯着阴霾中的少女。"如果我们两人都在这儿，"她开口道，身体前倾，“那你觉得我们能不能结伴同行？我们……我们也许能互帮互助，说不定还……”</p>
<p>她止住了话语。另一位少女正凝视着那空旷的，如画布一般的天空，脸上空洞的神色显得毫无感情。她看似并未聆听——但实际上，她已将每一个字刻入了脑海。</p>
<p>"说不定还……"被黑暗包裹的少女重复道。话语虚弱而又模糊……自从她于苦痛之中再生，她的灵魂便感觉如同一道阴暗而冷酷的深渊。然而，当她听到这个提议时，某种存在于她心中的事物仍然开始闪出微光——无比短暂，且极为微弱。只是，对现在的她而言，就算是如此细小的事情，也足够穿破自她再次苏醒过来便一直尝试扼杀她呼吸的失意面纱。</p>
<p><i>——V-2</i></p>

  </div>
<p>两名少女进行了漫长的交谈，从自我到Arcaea世界，从过去到现在。这场谈话并不轻松。最终她们得出结论：<b>她们在一个无意义的世界里渴求着一丝意义。</b>对立坦言自己的内心充满了肮脏污秽的血液，但光认为对立拯救了自己，对立是善良且坚强的。</p>
<p>然而，对立明白自己对光的情绪只有蔑视，她唯一的渴望就是用小刀刺穿光的身体。但对立的内心也受到了来自光的感化。</p>

  <div class="note p-4 mb-4 rounded-small blue">
    <p>那番话语并不正确，她根本没有拯救自己。只是……也许她的确不是单纯寻找着能供她摧残的对象。也许她只是在等待一个能够给予她最后一线希望的奇迹发生。优柔寡断的光实在无法直接赋予她安慰，</p>
<p>但这女孩的存在本身与她那毫无敌意的心灵却始终暗示着一件事：她，可能就是那一道才诞生不久的，最后的光芒。</p>
<p><i>——V-3</i></p>

  </div>
<p>就在双方即将展开合作时，一片异常的残片飞到二人中间，并向对立展示了一个景象，它彻底击碎了对立与光合作的一切希望——光杀了对立。</p>

  <div class="note p-4 mb-4 rounded-small purple">
    <p>那些玻璃毫无偏差地映照出了她自己的身体被一根参差的玻璃长柱一穿而过的影像。那道创伤仿佛要在炙热，苍白的烈焰中将她的衣服与整个身躯撕裂。</p>
<p>空虚荒芜的Arcaea大地，从她的身前和身后延伸到无边无际的地平线。带着缠绕双肩的那两股刺眼的炙热火焰，抬起手轻抚着长柱的，是那位身披白衣，使她倍感熟悉的少女——尽管在这个角度看不到她的表情。</p>
<p>她，是此时此刻正站在自己面前的少女。那名才与她相遇不久的女孩。</p>
<p>这绝不是回忆：这景象预言着未来将会发生的一切。</p>
<p><i>——V-5</i></p>

  </div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/arcaea_story_cg/Story_V-5.jpg"
                      
                ></p>
<p>对立迅速退回自己原本的立场，最后的希望终于变成了绝望，她的心在这一瞬间死去了。与此同时，光犯了一个天大的错误：她伸手去拿了那片红色的玻璃，那片在她即将迷失时给予她慰藉的玻璃。</p>

  <div class="note p-4 mb-4 rounded-small black">
    <p>那一刹那，对立在没有任何预警的情况下靠近了光，准备彻底夺走她的性命。</p>
<p><i>——V-5</i></p>

  </div>
<h2 id="无限纷争死亡与复生">无限纷争，死亡与复生</h2>
<p>战斗情节的文字相对具体一些，我们在这里只做简要描述。</p>
<p>面对骤然间充满危险的对立，光的内心产生了巨大的恐慌。但很快，光意识到自己不能一直这样畏缩不前。尽管对立招招都下死手，光只是尽力地防卫自身，并未曾放弃寻找“和解”的可能性。</p>
<p>对立质问光到底是什么，是不是这个世界创造出来的恶魔，是不是只是这些碎片的同类，专程来猎杀对立的人。但事实上，两名少女也不知道自己究竟是什么。没有得到答案的对立则认为，</p>
<p>“既然能够找上我，那你也一定不是什么好东西。”</p>
<p>对立对这个世界彻底绝望了。她汇聚了大量的纷争碎片，不断向光发起攻击。光强烈的生存愿望促使她能够指挥一定数量的光芒碎片，二人的战斗进入短暂的相持阶段。二人的冲突已经升级为了光芒侧与纷争侧的死斗，升级为了这个空洞的世界的战争。</p>
<p>在光向对立投去的碎片中，有一枚淡紫色点缀的，外形极度歪曲的异象碎片，映入对立的眼帘。尽管只是一瞬间，但对立瞬间知晓了有关这世界的一切。</p>

  <div class="note p-4 mb-4 rounded-small black">
    <p>转瞬之间，快到仅仅是碎片表面的反光与视网膜相撞——感受到自己的颅内就像被光芒所充溢般，一眨眼的功夫便近乎通晓了有关这世界的一切：所有曾经几时存在——且必定存在的事物。一眨眼的功夫，她的脑海中便已然开朗。</p>
<p>她们的名字。她们的过去。这个世界存在的目的。……甚至是关乎其他世界的真相，属于其他旅行者的终点，结局、序言、完美详尽的因果：一切的一切。以及真理。全部的事物所指向的真理，便是——</p>
<p>她的身前，光短暂地止住了步伐。她察觉到了面前那名对手态度的明显转变。的确有什么变化产生。恐惧。</p>
<p>所以，真理就是如此。我已知晓真理。</p>
<p>对立早已目睹“现实”被禁锢的真理。而只需明白这一真理，她便会拥有力量。但若两者兼具，通晓万事……通晓万事，又有什么用？</p>
<p>本已凝固的思绪，如同被再次强行乱搅一番。那股盘踞于她胸腔内的无尽苦涩逐渐一路蔓延而上，沾染了自己的舌根，钻入牙缝之中。她的嘴唇扭曲得好似一抹忧郁而感性的微笑。忧郁而感性，却毫无疑问地，怪诞地——快乐。</p>
<p>狂笑吧，少女。呼唤狂风暴雨吧。此处的道路尽收人类所能拥有的最恶回忆。而存在于终点的——始终都——只会是终点。</p>
<p>抵达终站的同时，她们两者之间的一人，必须死。</p>
<p><i>——VS-6</i></p>

  </div>
<p>世界的真相赋予了对立无与伦比的力量，对立下定决心要杀掉光，毁灭这个愚蠢的世界。<b>风暴对立<del class="mask">（猫对立）</del>诞生了。</b></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/arcaea_story_cg/Story_VS-7.jpg"
                      
                ></p>
<p>战斗失去了悬念，或者说，这场较量已经变成了对立对光的碾压。光终于看到了淹没对立的、来自纷争侧的回忆：刻画着痛苦、背叛、嫉妒的回忆。她终于体会到了对立的痛苦：自己心中的情感如何一步步走向毁灭。她开始冷静下来分析战场的局势，却发现自己绝无胜算。她在心里呐喊着、祈祷着奇迹的出现——</p>
<p>——然后，异象突现。<del class="mask">此处对应Black
Fate曲包的最终隐藏曲《Arcahv》，非常震撼。</del></p>
<p>大地崩裂，天空陨落，时间静止了。这一瞬间，光恢复了以前的神性，变得冷漠、空洞，对任何事物毫不在乎。<del class="mask">宿命光（妻寄光）诞生了。</del>整个Arcaea世界又站在了光的这一边，光得到了创世神的力量。</p>
<p>她用碎片组成的牢笼封锁了对立，并说对立并不需要做到如此地步——这场战斗的一切对她来说毫无意义。但在对立看来，这句话是多么的讽刺。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/arcaea_story_cg/Story_F-2_cg.jpg"
                      
                ></p>
<p>光依旧不愿意杀掉对立，她想，“等时间恢复之时，只要把她推得远远的就不可能再打了吧？”只要能停止战斗，就不会再有谁因此丧命。她开始思考这种想法的可行性。这应该行得通。希望犹存，则应该有其存在的意义。</p>
<p>但她很快发现自己错了——对立如野兽一般再次向光扑来。</p>

  <div class="note p-4 mb-4 rounded-small black">
    <p>她叫来了周围能找来的全部玻璃碎片，并将它们送往空中，任凭那些碎片闪烁而反射着周围的景象。</p>
<p>就这样，她很快便找到了光的身影。随后，她开始撼动着脚下的大地。世界的核心，连带着地壳都开始变得扭曲，只剩下光站在地上做着无声的抵抗。她能感觉到对立深深的执念。那是要夺走这一切的执念，无论地点，无论手段，她心意已决。</p>
<p>哈，这就是所谓的希望吗。她笑出声。什么“希望”，早就不复存在。</p>
<p>阻隔在她们视线之间的一切全部灰飞烟灭，甚至她们自己也已经分不清是谁下的手。教堂的阴影下，破败的大门前，她们就这样面对面看着彼此。</p>
<p>光脸上露出一丝轻蔑的微笑，她再一次告诉对立：“我说你啊……你并不需要做到这种地步。”那并不是黑色少女想听到的话。</p>
<p><i>——F-2</i></p>

  </div>
<p>事实上，光这里的留情并非出自善良，而是彻底的冷漠：她并不在乎对立的生死，这场战斗从头到尾都毫无意义，她只是想停下这场争斗。所以她才会对对立说出“你不需要做到这种地步”。但这只会更加强化了对立杀掉光的念头。此刻两个人都已经陷入了疯狂。</p>
<h2 id="见证风暴终焉">见证，风暴终焉</h2>
<p>对立可以控制纷争与光芒的碎片。她用一切碎片砸向光，将天空撕裂，用天空砸向光，用整个世界砸向光。而光也可以抵挡这些攻击并予以回击。世界的核心在崩塌。对立突然趁光不备，用碎片缠住并封锁了光的行动。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/arcaea_story_cg/Story_F-5_cg.jpg"
                      
                ></p>
<p>对立明确地告诉光：她将杀掉光，杀掉这个世界。</p>
<p>而在这一刹那，无数碎片在光的手中汇聚成了一把巨剑。光挣脱了束缚，手握剑柄站了起来。对立扑向了光，向光的喉咙攻去——</p>
<p>——但对立还是犹豫了。</p>
<p>就在这一瞬间，对立的手温柔地抚在光的脸上，而光的剑穿透了对立的身躯。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/arcaea_story_cg/Story_Testify1_cg.jpg"
                      
                ></p>

  <div class="note p-4 mb-4 rounded-small pink">
    <p>就在她把剑刺穿对方的身躯时，剑刃便吞噬了对方的生命，她的鲜血与一切都被那道玻璃全然吞没。紧接着，那道玻璃也开始碎裂消散。短短一瞬，她的生命便失去了活力，而仅存的身躯也随之倒下。</p>
<p>光下意识抓住对立触碰着她脸颊的手。然而，对方的生命却在极速消逝。不过寥寥数秒，眼前的少女，便只剩下了一具冰冷的身体。</p>
<p>当玻璃制成的剑身瓦解消散之时，一丝温度传遍了光的指尖可是她的另一只手，却已察觉不到对立的一丝气力。</p>
<p>那名少女的双脚着地，而她的身体则被光打湿而温暖的手托着。如今的她已阖上了双眼，她眉头紧锁……但也渐渐失去了光泽。这并非一场安详的告别，可是她的生命就这样画上了句号。</p>
<p>光睁大双眼，感受着自己心脏的跳动。直到现在，她才彻底明白这一切。</p>
<p><i>——F-6</i></p>

  </div>
<p>对立死了，死的并不安详。此刻，光的情绪逐渐回到了她的内心。她开始感到后悔、恐惧、痛苦，她开始憎恨自己的自私，憎恨自己。</p>

  <div class="note p-4 mb-4 rounded-small white">
    <p>这就是Arcaea试图带给她的命运，它们不会去试图反抗它们的造物主，甚至会主动满足造物主的愿望。然而，它们也会尽可能的保证Arcaea世界的存在，这是它们的本能。所以，灵魂强大的光与对立，她们的相遇本身就是一个错误；所以，Arcaea世界创造了碎片的监视者，让她吞噬一切会瓦解Arcaea存在本身的异常；所以，命运纠正了她们相遇的错误……</p>
<p>——这一切都导致了对立的死亡。</p>
<p>这仅仅只是因为，她们中的一人，必须死。造物主在反抗她忠诚的造物，这是多么讽刺的一件事啊。</p>
<p>Arcaea们为它们的造物主谱写了最后的乐章——《Last》。在无形之中，它们告诉她：“现在，请您接受我们为您带来的命运——</p>
<p>“在这个世界里继承神位吧。”</p>
<p><i>——摘自专栏：<a class="link" 
 href="https://www.bilibili.com/opus/683108200712503298" >[自整理][小更新]Arcaea主线剧情第一幕全整理<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></i></p>

  </div>
<p>对立死后，灵魂到达了虚空，“对立”也在那里。复制体与本体终究还是见面了。通过“对立”，对立得知其实“对立”一直都在观察这个世界。对立通过观察，看到了光正因自己的死而痛苦、内心受创。对立与“对立”都认为光已经不是“光”了，她有了感情，有了爱，她比“光”更强大。对立也承认她愿意和光道歉，但她还是憎恨“光”，因为“光”，她必须再体验一次痛苦的人生，而“光”却还活着，她和其他少女却死了。对立认为光和她一样，都是无端受害的傻鬼魂罢了。最后，对立通过虚空传话，让光振作起来，不要因为自己的死而难过，自己接受这样的命运。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/arcaea_story_cg/Story_F-7_cg.jpg"
                      
                ></p>

  <div class="note p-4 mb-4 rounded-small white">
    <p>“……是啊。……光……我真的很抱歉。我不后悔所做的一切，但……我刚才心中的那股恨意，其实……并不是冲着你来的，而是……另外一个你……她现在还在……某个地方，至今依然……还活着……
我还是……不能原谅她。但你……我希望你明白……你比她更加强大。光，正是因为如此……我知道你一定还会再站起来。”</p>
<p>“……对不起……我选择了死亡。很抱歉我把一切都抛之脑后。……但即便一切都是徒劳……我也很幸运地获得过重来一次的机会。所以没关系……我接受这样的命运。”</p>
<p>“我希望她知……知道……我不想要……自己在这个世界……唯一留下的足迹……是个可悲……愚蠢的结局。……如果你听得见我说的话……光……我想告诉你……真的……请你一定……要记住……</p>
<p>“我接受这样的人生。”</p>
<p><i>——F-7</i></p>

  </div>
<h2 id="无声的答案">无声的答案</h2>
<h3 id="结局一拒绝命运的安排">结局一：拒绝命运的安排</h3>
<p>对立死了。光感受到这个世界似乎正在从压力中释放。Arcaea进入光的内心，向她低语，让她接受Arcaea的一切。但光无法停止对自己杀害了对立这一事实的憎恶。她不希望任何人为此而死去，她决意要改变现状，为此她愿意付出一切代价，哪怕自己会因此死去，哪怕是这个世界会走向毁灭。</p>
<p>光抛弃了Arcaea，为了拯救对立，为了改变这一切。</p>
<p>（其实我认为光在这里的想法已经可以用【爱】来解释了。这不光是磕cp，而是真正的爱。原本的光没有任何情感，但现在的她已经有能力感受欣喜、希望、悲伤、憎恶……还有爱。Arcaea是无情感的她为自己打造的乐园，而当她能够切身感受到情感的时候，Arcaea于她已经不重要了。因此这意味着她抛弃了Arcaea，这个世界在未来会走向消逝。）</p>
<p>尽管仍然身负重伤，尽管世界因光的举动而倾覆，光依旧坚定地协助对立的复活。“对立”和对立在光的召唤下从虚无重返Arcaea。光得到了“对立”的第一灵魂，和对立破碎的第二灵魂的残片，将对立复活，改写了对立死亡的命运。</p>

  <div class="note p-4 mb-4 rounded-small pink">
    <p>她扭曲了世界的核心，这样做也将导致堕落之神的重生。就这样最后，曾经绝对的规则被改写了。光发出坚定且沉静的命令后，新的死亡便牢牢刺入至这个核心之中。</p>
<p>在光芒和暗影巨大的脉冲之下，Arcaea 开始迈向灭亡。</p>
<p>创造存在的愿望被推翻了。天空在头上迅速移动，而现实的余光从四面八方倾泻而下至她身上。光将这打造出的灵魂推入至浮在半空中极度美艳的对立的身体时，她的汗珠滴至眉间，但同时她也推动了整个世界——</p>
<p>她引导着大地的生命。</p>
<p>她抛弃了Arcaea。</p>
<p><i>——E-1（最终之梦）</i></p>

  </div>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/arcaea_story_cg/Story_Last1_epilogue_cg.jpg"
                      
                ></p>
<p>关于对立的回忆碎片也出现在了光的身旁，光在这些碎片中，看到了那个曾为拯救自己、为改变世界而饱受折磨的熟悉身影。她将这些碎片融入了新的生命中。对立曾经感受的痛苦，同时大部分也被遗忘了。对立复活了，但Arcaea世界的核心因此被改变，从而到处受损。</p>
<p>但这一切已经不再重要。对立牵着光的手向前走去。光芒侧的残片不在亲近光，纷争侧的残片亦不再缠着对立。她们此刻都完成了对自身的补完。尽管她们都明白这个世界会走向灭亡，但眼下她们只在乎彼此。</p>
<p>她们在灰色的世界启程。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/arcaea_story_cg/Story_Last2_epilogue_cg.jpg"
                      
                ></p>

  <div class="note p-4 mb-4 rounded-small purple">
    <p>如果你已选择生命，那便是选择了活下去。活在这个世界。见证这个世界。体验它，并真切地接受这最后的每个当下。有了这样的体悟，她选择去牢牢把握。</p>
<p>她睁开双眼，并且呼吸着空气。前方蜿蜒的未知、身旁的少女、没见过的脸庞、以及远方未知的地方……</p>
<p>她把这些放在心中最重要的位置。</p>
<p>她牵着对立的手。</p>
<p>因为她们将会继续前进。</p>
<p><i>——E-1（最终之梦）</i></p>

  </div>
<h3 id="结局二接受arcaea的一切">结局二：接受Arcaea的一切</h3>
<p>光继续作为这个世界的创世神，冷漠地注视着世间的一切。她抛弃了对立。</p>
<p>这是一个纯白的Arcaea世界，一个没有纷争、痛苦的美丽新世界。这里的一切都可以没有痛苦地活着、无忧无虑地活着。</p>
<p>但，也仅是活着。这个世界没有意义，这个世界的生命没有意义。</p>
<p>光的愿望达成了，她会在这里得到虚假的、永恒的、似有若无的快乐。</p>

  <div class="note p-4 mb-4 rounded-small white">
    <p>因为在这里，没有看不到的记忆，没有感觉不到的情感。这就是光芒照耀，且授予的“一切”。</p>
<p>为了永远的快乐，为了永远的平安。与你可能已经抛弃的任何生命不同，这，就是她所爱。这，就是Arcaea————迷失的生命不会受到偏袒，也不会受到责备。</p>
<p>因此，就像这样，命运的齿轮在这里继续运转……</p>
<p>……而远方不会再有等候着的命运。</p>
<p><i>——E-2（完美之愿）</i></p>

  </div>
]]></content>
      <categories>
        <category>杂七杂八</category>
      </categories>
      <tags>
        <tag>Arcaea</tag>
      </tags>
  </entry>
  <entry>
    <title>注意力机制解析</title>
    <url>/2025/02/19/AttentionAnalysis/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script>
  <div class="note-large blue">
    <div class="notel-title rounded-t-lg p-3 font-bold text-lg flex flex-row gap-2 items-center">
      <p>原论文指路</p>

    </div>
    <div class="notel-content">
      <p><a class="link"   href="https://arxiv.org/abs/1706.03762" >Attention is All You
Need<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>

    </div>
  </div>
<h2 id="背景">背景</h2>
<p>注意力机制早在2014年便被首次用于计算机视觉领域，试图理解神经网络进行预测时正在观察的位置。2015年注意力机制开始用于NLP领域，后于2017年被加入Transformer网络中用于语言建模。Transformers解决了RNN存在的长程依赖、梯度消失和梯度爆炸、所需训练开销和无法并行计算等问题，取代了RNN在NLP领域的统治地位，成为该领域最受欢迎的技术。</p>
<h2 id="词嵌入-embedding">词嵌入 (embedding)</h2>
<p>对于自然语言文本，计算机难以直接使用，因此在NLP中第一步都是将自然语言的单词转化为等长的向量，这个过程叫做<b>嵌入</b>。向量的每个维度都有其潜在的含义，只不过在具体实践中难以对每个维度的含义做具体解释。</p>
<p>词嵌入并无普遍标准，同一个词的嵌入也会因为任务、神经网络、训练阶段的不同而不同。初始嵌入为随机值，在训练期间会不断调整从而最小化神经网络的误差。</p>
<p>举个例子，我们要将这句话输进计算机做处理：</p>
<p><centering>I will come and teach you how to do this
tomorrow.</centering></p>
<p>句子被输入计算机时，程序将该字符串分为若干个token <span
class="math inline">\(t\)</span>，每个token生成一个词嵌入<span
class="math inline">\(a\)</span>。但此时这些词嵌入不包含上下文信息，即对程序来说，这些词嵌入组合相当于一个无序地装着多个单词的词袋，包含的信息十分有限。</p>
<p>而当我们分析句中单词的语义时会发现单词间的关联程度并不和它们之间的距离直接相关，例如will和tomorrow的关联程度明显比其与come的关联程度更高。因此<b>词语之间的关联程度需要根据上下文的语境决定</b>。接下来我们试图调整tokens的词嵌入，使其包含上下文信息。</p>
<h2 id="缩放点积注意力的推导">缩放点积注意力的推导</h2>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/attention/selfattn_1.png"
                      
                ></p>
<p>如图，<span
class="math inline">\(a^i\)</span>是不含上下文信息的词嵌入（这里以NLP的过程为例，事实上注意力机制还可以用于图像处理等，<span
class="math inline">\(a^i\)</span>可为初始输入或来自某个模型的输出），输出的结果<span
class="math inline">\(b^i\)</span>与所有词嵌入都有关。当我们了解<span
class="math inline">\(b^1\)</span>向量如何产生之后，其余向量的产生过程都可以很容易得到。产生<span
class="math inline">\(b^1\)</span>向量的首要步骤是找到<span
class="math inline">\(a^1\)</span>与其他向量的关联程度（也称注意力分数）。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/attention/selfattn_2.png"
                      
                ></p>
<p>对于求<span
class="math inline">\(a^i,a^j\)</span>之间的注意力分数<span
class="math inline">\(\alpha_{i,j}\)</span>，最常用的方法是求出<span
class="math inline">\(a^i\)</span>的查询（query）向量 <span
class="math display">\[
q^i=W^qa^i
\]</span> 求出<span class="math inline">\(a^j\)</span>的键值（key）向量
<span class="math display">\[
k^j=W^ka^j
\]</span> 则注意力分数为查询向量和键值向量的点积 <span
class="math display">\[
\alpha_{i,j}=q^i\cdot k^j
\]</span></p>
<p>这里求<span
class="math inline">\(a^1\)</span>与其他嵌入向量的关联度，求出其查询向量<span
class="math inline">\(q^1\)</span>之后与所有嵌入向量的键值向量<span
class="math inline">\(k^i(i=1,2,3,4)\)</span>做点积，最后对求出的关联度向量组作softmax归一化。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/attention/selfattn_3.png"
                      
                ></p>
<p>这个步骤可以简单理解为：在搜索引擎中输入的内容为<span
class="math inline">\(q\)</span>，搜索到的结果展示了各种信息的键值<span
class="math inline">\(k\)</span>，可以通过键值得到信息的内容（值，value）<span
class="math inline">\(v\)</span>本身。而关联度<span
class="math inline">\(\alpha\)</span>展示了这些信息与我们输入的内容的相关性有多大，这个值越大说明这个键值对应的内容和我输入的查询内容相关程度越高。</p>

  <div class="note p-4 mb-4 rounded-small blue">
    <p>该步骤的激活函数并非必须为softmax，使用其他激活函数（如RELU，GELU等）也可，并且可能达到更好的效果。</p>

  </div>
<p>得到<span
class="math inline">\(a^1\)</span>与自身及其他几个嵌入向量的注意力分数之后，将这些分数与其对应向量的值向量相乘然后求和，即可得到添加了上下文信息的嵌入<span
class="math inline">\(b^1\)</span>。值向量可通过下式求得： <span
class="math display">\[
v^i=W^va^i
\]</span></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/attention/selfattn_4.png"
                      
                ></p>
<p>其余<span
class="math inline">\(b\)</span>向量的产生过程同理。值得注意的是，这个过程并不需要依序产生，所有<span
class="math inline">\(b\)</span>向量可以通过一组矩阵运算同时产生。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/attention/selfattn_5.png"
                      
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/attention/selfattn_6.png"
                      
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/attention/selfattn_7.png"
                      
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/attention/selfattn_8.png"
                      
                ></p>
<p>使用向量形式可以非常简洁地表述上述过程。假设： - <b>查询矩阵</b><span
class="math inline">\(Q\in\mathbb{R}^{m\times d_k}\)</span>(<span
class="math inline">\(m\)</span>表示查询的个数，<span
class="math inline">\(d_k\)</span>是查询向量的维度) - <b>键矩阵</b><span
class="math inline">\(K\in\mathbb{R}^{n\times d_k}\)</span>(<span
class="math inline">\(n\)</span>表示键的个数) - <b>值矩阵</b><span
class="math inline">\(V\in\mathbb{R}^{n\times d_v}\)</span></p>
<p>每个查询<span class="math inline">\(q^i\)</span>和每个键<span
class="math inline">\(k^j\)</span>之间的相似度用点积计算（如式<span
class="math inline">\((3)\)</span>），则所有查询和所有键的点积可以用矩阵表示：
<span class="math display">\[
A=QK^T
\]</span></p>
<p>其中<span class="math inline">\(A\in\mathbb{R}^{m\times
n}\)</span>是所有查询和所有键的相似度矩阵。接着采用softmax对<span
class="math inline">\(A\)</span>进行归一化处理（对矩阵的每一行进行归一化）：
<span class="math display">\[
A^\prime = \mathrm{softmax}(A)
\]</span></p>
<p>最终注意力的输出值是值<span
class="math inline">\(V\)</span>的加权求和： <span
class="math display">\[
o_i = \sum_{j=1}^n{\alpha^\prime_{ij}v_j}
\]</span></p>
<p>即 <span class="math display">\[
O=AV
\]</span> 其中<span class="math inline">\(O\in\mathbb{R}^{m\times
d_v}\)</span>是最终的注意力输出矩阵。</p>
<p>值得注意的是，作者在<a class="link" 
 href="https://arxiv.org/abs/1706.03762" >原论文<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>中提出了<b>缩放因子</b>：
<span class="math display">\[
A=\frac{QK^T}{\sqrt{d_k}}
\]</span></p>
<p>其原因是：点积值的大小随着<span
class="math inline">\(d_k\)</span>增大而增大。如果<span
class="math inline">\(d_k\)</span>很大，<span
class="math inline">\(QK^T\)</span>的数值会很大，导致Softmax计算时指数项变大，使得梯度消失或过于集中于某些键值，确保注意力分布合理。</p>
<p>最终我们得到了完整的注意力机制公式： <span class="math display">\[
\mathrm{Attention}(Q,K,V)=\mathrm{softmax}\Big(\frac{QK^T}{\sqrt{d}}\Big)V
\]</span></p>
<p><strong>整个过程只有矩阵<span
class="math inline">\(W^Q,W^K,W^V\)</span>是需要训练的。</strong></p>

  <div class="note p-4 mb-4 rounded-small blue">
    <p>在机器翻译或文本生成的任务中，通常需要预测下一个单词出现的概率，这类任务要求注意力只能放在下一个词，不能放在更往后的词上。简而言之，<strong>注意力矩阵不能有非平凡的超对角线分量</strong>。这时我们可以通过添加<strong>掩码矩阵</strong><span
class="math inline">\(M\)</span>来修正注意力，消除神经网络对未来的了解。即
<span class="math display">\[
\mathrm{Attention}(Q,K,V)=\mathrm{softmax}\Big(\frac{QK^T}{\sqrt{d}}+M\Big)V
\]</span></p>
<p>其中， <span class="math display">\[
\begin{aligned}
    M&amp;=\left( m_{i,j} \right) _{i,j=0}^{n}\\
    m_{i,j}&amp;=\begin{cases}
    0&amp;      i\ge j\\
    -\infty&amp;        i&lt;j\\
\end{cases}\\
\end{aligned}
\]</span></p>

  </div>
<p>利用神经网络结构表示注意力机制如下图所示：</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/attention/selfattn_nn.png"
                      
                ></p>

  <div class="note-large blue">
    <div class="notel-title rounded-t-lg p-3 font-bold text-lg flex flex-row gap-2 items-center">
      <p>如何更好地理解注意力机制中的Q,K,V？</p>

    </div>
    <div class="notel-content">
      <ul>
<li><a class="link" 
 href="https://www.zhihu.com/question/298810062/answer/2274132657" >iynil的回答
- 知乎<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link" 
 href="https://www.zhihu.com/question/298810062/answer/86505956036" >司马懿的回答
- 知乎<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link" 
 href="https://www.zhihu.com/question/298810062/answer/1828080188" >陀飞轮的回答
- 知乎<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
</ul>

    </div>
  </div>
<h2 id="多头注意力机制">多头注意力机制</h2>
<p>有时，只用一个注意力头可能无法很好捕捉多个词在语境上复杂的关联。因此，可以添加更多线性层作为键、查询和值。这些线性层在每轮并行训练，彼此权重独立，每层都各提供一个输出，从而各算出独立的权重。每一层被称为一个“头”。可以有任意数量<span
class="math inline">\(h\)</span>个线性层，提供<span
class="math inline">\(h\)</span>个注意力输出，然后将它们连接在一起。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/attention/multihead.png"
                      
                ></p>
<p>仿照上述的向量表示方法，多头注意力可以表示为 <span
class="math display">\[
\begin{aligned}\mathrm{head}_i&amp;=\text{Attention}(QW_i^Q,KW_i^K,VW_i^V)\\
\text{MultiHead}&amp;=\text{Concat}(\text{head}_1,\text{head}_2,\ldots,\text{head}_k)W^O\end{aligned}
\]</span></p>
<p>其中<span
class="math inline">\(QW_i^Q,KW_i^K,VW_i^V\)</span>是不同头的参数矩阵。通过多个头学习不同的注意力模式，最终拼接后投影到输出空间。多头注意力能够提高模型的表达能力，并增强不同语义层次的表示。</p>
<figure>
<figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/attention/multihead_nn.png"
                     
alt="多头注意力的神经网络结构表示" 
                ><figcaption>多头注意力的神经网络结构表示</figcaption></figure>
<figcaption aria-hidden="true">多头注意力的神经网络结构表示</figcaption>
</figure>
<h2 id="缩放点积注意力的pytorch实现">缩放点积注意力的Pytorch实现</h2>
<p>使用类<code>ScaledDotProductAttention</code>实现该注意力机制的模型：</p>
<div class="code-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ScaledDotProductAttention</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, d_k</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;设置key和query的维度&quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">super</span>(ScaledDotProductAttention, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.d_k = d_k</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, Q: torch.Tensor, K: torch.Tensor, V: torch.Tensor, mask=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="comment"># 计算Q和K的点积并缩放</span></span><br><span class="line">        scores = torch.matmul(Q, K.transpose(-<span class="number">2</span>, -<span class="number">1</span>) / torch.sqrt(torch.tensor(<span class="variable language_">self</span>.d_k)))</span><br><span class="line">        <span class="comment"># 如果有掩码，对无效部分取负无穷使得softmax后归一化权重趋近于0</span></span><br><span class="line">        <span class="keyword">if</span> mask:</span><br><span class="line">            scores = scores.masked_fill(mask==<span class="number">0</span>, <span class="built_in">float</span>(<span class="string">&#x27;-inf&#x27;</span>))</span><br><span class="line">        <span class="comment"># 使用softmax归一化计算注意力权重</span></span><br><span class="line">        attention_weights = torch.softmax(scores, dim=-<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 计算最终的注意力输出</span></span><br><span class="line">        output = torch.matmul(attention_weights, V)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> output, attention_weights</span><br></pre></td></tr></table></figure></div>
<p>接下来设置参数并尝试运行：</p>
<div class="code-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line">batch_size, n_heads, seq_len, d_k, d_v = <span class="number">1</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">3</span></span><br><span class="line">Q = torch.rand(batch_size, n_heads, seq_len, d_k)</span><br><span class="line">K = torch.rand(batch_size, n_heads, seq_len, d_k)</span><br><span class="line">V = torch.rand(batch_size, n_heads, seq_len, d_v)</span><br><span class="line">attention = ScaledDotProductAttention(d_k)</span><br><span class="line">output, attn_weights = attention(Q, K, V)</span><br><span class="line"><span class="built_in">print</span>(output.shape)  <span class="comment"># (batch_size, n_heads, seq_len, d_v)</span></span><br><span class="line"><span class="built_in">print</span>(attn_weights.shape)  <span class="comment"># (batch_size, n_heads, seq_len, d_k)</span></span><br></pre></td></tr></table></figure></div>
<p>对于其中各个参数和输出结果含义的解释： -
<code>batch_size</code>可理解为句子的数量（一次处理多少个句子） -
<code>n_heads</code>代表注意力头的数量 -
<code>seq_len</code>代表一个句子中包含多少个词元（tokens） -
<code>d_k</code>设置了query和key的维度 -
<code>d_v</code>设置了value的维度 -
<code>output</code>表示在输入的序列中，每个词元的value根据其他词元的相关性加权之后的结果，作为每个位置的最终表示
-
<code>attn_weights</code>是注意力分配给每个位置的权重，决定了查询<code>i</code>在计算输出时，从键<code>j</code>的值<code>V[j]</code>获取信息的程度</p>
<p>输出结果： <div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">torch.Size([1, 1, 5, 3])</span><br><span class="line">torch.Size([1, 1, 5, 5])</span><br></pre></td></tr></table></figure></div></p>

  <div class="note-large blue">
    <div class="notel-title rounded-t-lg p-3 font-bold text-lg flex flex-row gap-2 items-center">
      <p>参考信息</p>

    </div>
    <div class="notel-content">
      <p><a class="link" 
 href="https://www.bilibili.com/video/BV1xM4m1m7vA?p=6" >【强烈推荐】零基础入门【大模型、多模态】CLIP
！-哔哩哔哩<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" 
 href="https://blog.csdn.net/jarodyv/article/details/130867562" >【万字长文】深度解析
Transformer
和注意力机制（含完整代码实现）_transformer架构注意力机制-CSDN博客<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>

    </div>
  </div>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>学习笔记：扩散模型算法介绍</title>
    <url>/2025/02/06/DiffusionModel/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script>
  <div class="note p-4 mb-4 rounded-small yellow">
    <p>本文原写于2024年8月16日。</p>

  </div>

  <div class="note p-4 mb-4 rounded-small blue">
    <p>论文：<a class="link"   href="https://arxiv.org/abs/2006.11239" >Denoising Diffusion
Probabilistic Models<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a> 模型实现代码：<a class="link" 
 href="https://github.com/hojonathanho/diffusion" >tensorflow
(official)<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a> / <a class="link" 
 href="https://github.com/lucidrains/denoising-diffusion-pytorch" >pytorch<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>

  </div>
<h2 id="原理">原理</h2>
<p>扩散模型可实现从噪声（采样自简单分布，如高斯分布）到数据样本的转换，分为两个步骤：</p>
<ul>
<li><b>固定的</b>前向扩散过程<span
class="math inline">\(q\)</span>：逐步向图片添加噪声直至得到一张纯噪声图像；</li>
<li><b>可训练的</b>去噪过程<span
class="math inline">\(p\)</span>：训练神经网络从纯噪声图像中去噪，得到一张真正的图片。</li>
</ul>
<figure>
<figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/ddpm/fig2.png"
                      alt="扩散模型原理" 
                ><figcaption>扩散模型原理</figcaption></figure>
<figcaption aria-hidden="true">扩散模型原理</figcaption>
</figure>
<p>该过程是一个<b>马尔可夫过程</b>，因为计算<span
class="math inline">\(\mathbf x_t\)</span>只需要用到<span
class="math inline">\(\mathbf
x_{t-1}\)</span>，即当前时刻的状态仅由上一时刻的状态决定。</p>
<p>正向过程中，向原图像<span class="math inline">\(\mathbf
x_0\)</span>中不断混入高斯噪声，经过<span
class="math inline">\(T\)</span>次加噪，图像<span
class="math inline">\(\mathbf
x_T\)</span>为符合标准高斯分布的纯噪声图像。网络的学习目标是学会<span
class="math inline">\(T\)</span>个去噪操作，将<span
class="math inline">\(\mathbf x_T\)</span>还原为<span
class="math inline">\(\mathbf
x_0\)</span>，每步去噪操作刚好抵消掉前面对应步骤的加噪操作。</p>
<h2 id="前向与反向过程">前向与反向过程</h2>
<h3 id="前向过程">前向过程</h3>
<p>设来自某训练集的图像<span class="math inline">\(\mathbf
x_0\)</span>会被添加<span class="math inline">\(T\)</span>次噪声，<span
class="math inline">\(\mathbf x_T\)</span>为最终生成的噪声图像，<span
class="math inline">\(\mathbf x_t\)</span>是这一时刻生成的图像，<span
class="math inline">\(\mathbf
x_{t-1}\)</span>是上一时刻生成的图像。我们通常将正态分布设置为这个形式：
<span class="math display">\[
\mathbf{x}_t\sim\mathcal{N}(\sqrt{1-\beta_t}\mathbf{x}_{t-1},\beta_t\mathbf{I})
\]</span></p>
<p><span class="math inline">\(\mathbf
x_t\)</span>可以通过一个服从标准正态分布的样本<span
class="math inline">\(\epsilon_{t-1}\)</span>算出： <span
class="math display">\[
\mathbf{x}_t=\sqrt{1-\beta_t}\mathbf{x}_{t-1}+\sqrt{\beta_t}\epsilon_{t-1};\quad\epsilon_{t-1}\sim\mathcal{N}(0,\mathbf{I})
\]</span></p>
<p><span
class="math inline">\(\epsilon_t(t=1,2,\dots,T-1)\)</span>是一组服从正态分布<span
class="math inline">\(\mathcal{N}(0,\mathbf{I})\)</span>的独立样本。</p>

  <div class="note p-4 mb-4 rounded-small blue">
    <p>这里<span
class="math inline">\(\beta_t\)</span>不是常量，而是一个随时间<span
class="math inline">\(t\)</span>变化的变量，一般要越来越大，表示在给图像加噪的过程中，噪声的添加进度越来越快。将思维逆转过来，考虑反向去噪过程，一开始对纯噪声图像去噪较多，当图像越接近原图像时，去噪会越来越慢。</p>
<p>原论文中随着<span class="math inline">\(t\)</span>的增大，<span
class="math inline">\(\beta_t\)</span>从1e-4到2e-2线性增长。</p>

  </div>
<p>令<span class="math inline">\(\alpha_t=1-\beta_t\)</span>，<span
class="math inline">\(\bar{\alpha_t}=\prod_{s=1}^t{\alpha_s}\)</span>，上式可化为
<span class="math display">\[
\mathbf{x}_t=\sqrt{\alpha_t}\mathbf{x}_{t-1}+\sqrt{1-\alpha_t}\epsilon_{t}
\]</span></p>
<p>接着向前递推，可做如下推导： <span class="math display">\[
\begin{aligned}
    q\left( \mathbf{x}_t|\mathbf{x}_{t-1} \right) &amp;=\sqrt{\alpha
_t}\mathbf{x}_{t-1}+\sqrt{1-\alpha _t}\epsilon _{t}\\
    &amp;=\sqrt{\alpha _t}\left( \sqrt{\alpha
_{t-1}}\mathbf{x}_{t-2}+\sqrt{1-\alpha _{t-1}}\epsilon _{t-1} \right)
+\sqrt{1-\alpha _t}\epsilon _{t}\\
    &amp;=\sqrt{\alpha _t\alpha _{t-1}}\mathbf{x}_{t-2}+\sqrt{\alpha
_t-\alpha _t\alpha _{t-1}}\epsilon _{t-1}+\sqrt{1-\alpha _t}\epsilon
_{t}\\
    &amp;=\sqrt{\alpha _t\alpha _{t-1}}\mathbf{x}_{t-2}+\sqrt{1-\alpha
_t\alpha _{t-1}}\epsilon \left( \text{正态分布相加还是正态分布}
\right)\\
    \vdots\\
    &amp;=\sqrt{\bar{\alpha}_t}\mathbf{x}_0+\sqrt{1-\bar{\alpha}_t}\epsilon\\
    q\left( \mathbf{x}_t|\mathbf{x}_0 \right) &amp;=\mathcal{N} \left(
\mathbf{x}_t;\sqrt{\bar{\alpha}_t}\mathbf{x}_0,\left( 1-\bar{\alpha}_t
\right) \mathbf{I} \right)\\
\end{aligned}
\]</span></p>
<p>如此我们就可以直接从<span
class="math inline">\(\mathbf{x}_0\)</span>推导出<span
class="math inline">\(\mathbf{x}_t\)</span>。</p>
<h3 id="反向过程">反向过程</h3>
<p>该过程我们希望能倒过来取消每一步的加噪操作，使一幅纯噪声图像<span
class="math inline">\(\mathbf{x}_T\)</span>变回数据集中的图像<span
class="math inline">\(\mathbf{x}_0\)</span>，利用这个过程，我们可以把任意一个从标准正态分布采样的噪声图像变成一幅和训练数据相近的图像，从而达到图像生成的目的。</p>
<p>数学上有：当<span
class="math inline">\(\beta_t\)</span>足够小时，每一步的加噪逆操作仍然满足正态分布
<span class="math display">\[
\mathbf{x}_{t-1}\sim\mathcal{N}(\tilde{\mu}_t,\tilde{\beta}_t\mathbf{I})
\]</span></p>
<p>为了描述去噪操作，神经网络的任务就是根据当前时刻<span
class="math inline">\(t\)</span>、当前图像<span
class="math inline">\(\mathbf{x}_t\)</span>拟合当前加噪逆操作的正态分布，即拟合当前的均值<span
class="math inline">\(\tilde{\mu}_t\)</span>和方差<span
class="math inline">\(\tilde{\beta}_t\)</span>。事实上，由于加噪的操作是固定的，因此理论上去噪的操作（即加噪的逆操作）也是固定的，但该操作极难从理论上求得，只能用神经网络去尽量拟合。</p>
<p>虽然我们无法得到逆转过程的概率分布<span class="math inline">\(q\left(
\mathbf{x}_{t-1}|\mathbf{x}_t \right)\)</span>，但如果知道<span
class="math inline">\(\mathbf
x_0\)</span>，则可以直接由贝叶斯公式计算出<span
class="math inline">\(q\left( \mathbf{x}_{t-1}|\mathbf{x}_t ,\mathbf
x_0\right)\)</span>： <span class="math display">\[
q(\mathbf{x}_{t-1}|\mathbf{x}_t,\mathbf{x}_0)=q(\mathbf{x}_t|\mathbf{x}_{t-1},\mathbf{x}_0)\frac{q(\mathbf{x}_{t-1}|\mathbf{x}_0)}{q(\mathbf{x}_t|\mathbf{x}_0)}
\]</span></p>
<p>等式左边（其中均值和方差是待求项）： <span class="math display">\[
q(\mathbf{x}_{t-1}|\mathbf{x}_t,\mathbf{x}_0)=\mathcal{N}(\mathbf{x}_{t-1};\tilde{\mu}_t,\tilde{\beta}_t\mathbf{I})
\]</span></p>
<p>等式右边： <span class="math display">\[
\begin{aligned}
    q(\mathbf{x}_t|\mathbf{x}_{t-1},\mathbf{x}_0)&amp;=\mathcal{N}
(\mathbf{x}_t;\sqrt{1-\beta _t}\mathbf{x}_{t-1},\beta _t\mathbf{I})\\
    q(\mathbf{x}_t|\mathbf{x}_0)&amp;=\mathcal{N}
(\mathbf{x}_t;\sqrt{\bar{\alpha}_t}\mathbf{x}_0,(1-\bar{\alpha}_t)\mathbf{I})\\
    q(\mathbf{x}_{t-1}|\mathbf{x}_0)&amp;=\mathcal{N}
(\mathbf{x}_{t-1};\sqrt{\bar{\alpha}_{t-1}}\mathbf{x}_0,(1-\bar{\alpha}_{t-1})\mathbf{I})\\
\end{aligned}
\]</span></p>
<p>等式右边全部已知，代入可得给定<span class="math inline">\(\mathbf
x_0\)</span>时的去噪分布。</p>
<p>经过化简可得分布均值与方差： <span class="math display">\[
\begin{aligned}
\tilde{\mu}_t&amp;=\frac1{\sqrt{\alpha_t}}\left(\mathbf{x}_t-\frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}}\epsilon_{t}\right)\\
\tilde{\beta}_t&amp;=\frac{1-\bar{\alpha}_{t-1}}{1-\bar{\alpha}_t}\cdot\beta_t
\end{aligned}
\]</span> 其中<span
class="math inline">\(\epsilon_{t}\)</span>来自式(3)。观察上式可知，方差<span
class="math inline">\(\tilde{\beta}_t\)</span>是一个常量，与输入<span
class="math inline">\(\mathbf
x_0\)</span>无关，训练去噪网络时仅需要拟合均值即可。再次观察目标均值公式，式中唯一不确定的值只有<span
class="math inline">\(\epsilon_{t}\)</span>。因此，<strong>直接让神经网络预测一个噪声<span
class="math inline">\(\epsilon_\theta(\mathbf
x_t,t)\)</span>让它和生成<span class="math inline">\(\mathbf
x_t\)</span>的噪声<span
class="math inline">\(\epsilon_t\)</span>的均方误差最小即可</strong>。对于一轮训练，误差函数可写成
<span class="math display">\[
L=||\epsilon_t-\epsilon_\theta(\mathbf{x}_t,t)||^2
\]</span></p>
<h2 id="训练算法与采样算法">训练算法与采样算法</h2>
<h3 id="训练算法">训练算法</h3>
<figure>
<figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/ddpm/training_pcd.png"
                      alt="训练算法伪代码" 
                ><figcaption>训练算法伪代码</figcaption></figure>
<figcaption aria-hidden="true">训练算法伪代码</figcaption>
</figure>
<p>逐行分析算法含义： 2. 从训练集中取出一个数据<span
class="math inline">\(\mathbf x_0\)</span> 3. 随机从<span
class="math inline">\(1,2,\dots,T\)</span>中取出一个时刻训练（虽然要求神经网络拟合<span
class="math inline">\(T\)</span>个正态分布，但实际训练时，不用一轮预测<span
class="math inline">\(T\)</span>个结果，只需要随机预测<span
class="math inline">\(T\)</span>个时刻中某一个时刻的结果就行） 4.
随机生成一个噪声<span class="math inline">\(\epsilon\)</span> 5. 将<span
class="math inline">\(\mathbf
x_t,t\)</span>传给神经网络，通过梯度下降预测随机噪声<span
class="math inline">\(\epsilon_\theta(\mathbf{x}_t,t)\)</span> 6.
训练到收敛位置（时间较长，通常设<span
class="math inline">\(T=1000\)</span>）</p>
<h3 id="采样测试算法">采样（测试）算法</h3>
<figure>
<figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/ddpm/sampling_pcd.png"
                      alt="采样算法伪代码" 
                ><figcaption>采样算法伪代码</figcaption></figure>
<figcaption aria-hidden="true">采样算法伪代码</figcaption>
</figure>
<ol type="1">
<li>从标准高斯分布采样一个噪声图像</li>
<li>循环迭代</li>
<li>如果时间步不为1，从高斯分布采样一个噪声<span
class="math inline">\(z\)</span>，否则<span
class="math inline">\(z=0\)</span></li>
<li>计算每个时间步<span class="math inline">\(t\)</span>的噪声图（<span
class="math inline">\(\epsilon_\theta(\mathbf
x_t,t)\)</span>由训练步骤获得）</li>
</ol>
<p>以上是关于扩散模型的粗略解读。部分推导未在本文列出，除非研究目标是改进扩散模型本身，学习时了解该模型整体思想和主要原理即可。</p>

  <div class="note-large blue">
    <div class="notel-title rounded-t-lg p-3 font-bold text-lg flex flex-row gap-2 items-center">
      <p>主要参考</p>

    </div>
    <div class="notel-content">
      <p><a class="link"   href="https://segmentfault.com/a/1190000043744225" >人工智能 -
扩散模型(Diffusion Model)详解：直观理解、数学原理、PyTorch 实现 -
个人文章 - SegmentFault 思否<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a> <a class="link" 
 href="https://blog.csdn.net/tobefans/article/details/129728036" >【深度学习模型】扩散模型(Diffusion
Model)基本原理及代码讲解-CSDN博客<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>

    </div>
  </div>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>hexo博客添加评论系统</title>
    <url>/2025/02/04/hexo%E5%8D%9A%E5%AE%A2%E6%B7%BB%E5%8A%A0%E8%AF%84%E8%AE%BA%E7%B3%BB%E7%BB%9F/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>在Hexo框架下的博客有很多种实现评论系统的方式。我这里采用了Giscus实现评论系统，这是利用<a class="link" 
 href="https://docs.github.com/en/discussions" >GitHub
Discussions<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>实现的评论系统，优点包括但不限于： -
开源、无广告、永久免费 -
无需自建数据库（数据储存在项目仓库的Discussions中） -
用户通过GitHub账户登录，简化注册流程，也增强了评论者的身份可信度、便于评论的及时回复与管理
- 支持自定义主题样式、评论排序、过滤等功能 -
配置简单，几分钟就能搞定</p>
<h3 id="安装">安装</h3>
<p>进入在GitHub账户中对Giscus的<a class="link" 
 href="https://github.com/apps/giscus" >安装界面<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>点击install进行安装。</p>
<figure>
<figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/giscus_install.png"
                     
alt="安装成功后的界面长这样" 
                ><figcaption>安装成功后的界面长这样</figcaption></figure>
<figcaption aria-hidden="true">安装成功后的界面长这样</figcaption>
</figure>
<h3 id="官网配置"><a class="link"   href="https://giscus.app/zh-CN" >官网<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>配置</h3>
<p>选择一个GitHub仓库用于储存评论数据，<u>可以是博客项目仓库，也可以是专门用于储存评论数据的仓库</u>。但要确保仓库满足3个条件：</p>
<ol type="1">
<li>该仓库是<strong>公开的</strong>，否则访客将无法查看评论信息；</li>
<li>giscus app
已安装，否则访客将无法评论和回应（上一步已完成这一条件）；</li>
<li>Discussions 功能<strong>已在你的仓库中启用</strong>。
进入对应的仓库，点击右上角的
<code>Settings</code>，往下翻到<code>Features</code>，勾选<code>Discussions</code>。</li>
</ol>
<figure>
<figure class="image-caption"><img src="/images/posts/giscus_repo.png"
alt="输入仓库（用户名/仓库名）后，系统会提示你该仓库是否满足所有条件" /><figcaption>输入仓库（用户名/仓库名）后，系统会提示你该仓库是否满足所有条件</figcaption></figure>
<figcaption
aria-hidden="true">输入仓库（用户名/仓库名）后，系统会提示你该仓库是否满足所有条件</figcaption>
</figure>
<blockquote>
<p>有个小细节，我逐字母输入这个空的时候明明该仓库符合所有条件它还是会显示不可以使用，但我直接复制粘贴仓库地址时它就显示可以使用了。不知道算不算一个bug</p>
</blockquote>
<p>后面有一些个性化设置，比如： - 【页面 &lt;-&gt; Discussion映射关系】
这个决定你用于存储评论数据的仓库中Discussion如何分类显示，以及giscus如何筛选仓库Discussion中该页面的信息显示在网页上。如果使用<code>pathname</code>而你的博客标题是中文的话，Discussion界面会显示一串很长的码，不易分辨来自哪篇帖子。<strong>所以这里我选择了<code>title</code>，这样Discussion标题里的中文是可以正常显示的。</strong>
- 【Discussion分类】
建议选择<code>Announcements</code>，并勾选下面的“只搜索该分类中的discussion”
- 【特性】
建议勾选“启用主帖子上的反应（可以给博客文章贴表情）”“将评论框放在评论上方”和“懒加载评论（评论的加载将延迟到用户滚动到评论容器附近，有助于博客界面的快速加载，是一种前端显示的优化手段）”
- 【主题】 建议勾选“用户偏好的色彩方案”，这个随意</p>
<h3 id="启用giscus">启用giscus</h3>
<p>完成上述设置之后，下面会自动生成对应的javascript代码。比如：</p>
<div class="code-container" data-rel="Js"><figure class="iseeu highlight js"><table><tr><td class="code"><pre><span class="line">&lt;script src=<span class="string">&quot;https://giscus.app/client.js&quot;</span></span><br><span class="line">        data-repo=<span class="string">&quot;jachinzhang1/jachinzhang1.github.io&quot;</span></span><br><span class="line">        data-repo-id=<span class="string">&quot;R_kgDONy_q0w&quot;</span></span><br><span class="line">        data-category=<span class="string">&quot;Announcements&quot;</span></span><br><span class="line">        data-category-id=<span class="string">&quot;DIC_kwDONy_q084Cmo0P&quot;</span></span><br><span class="line">        data-mapping=<span class="string">&quot;title&quot;</span></span><br><span class="line">        data-strict=<span class="string">&quot;0&quot;</span></span><br><span class="line">        data-reactions-enabled=<span class="string">&quot;1&quot;</span></span><br><span class="line">        data-emit-metadata=<span class="string">&quot;0&quot;</span></span><br><span class="line">        data-input-position=<span class="string">&quot;top&quot;</span></span><br><span class="line">        data-theme=<span class="string">&quot;preferred_color_scheme&quot;</span></span><br><span class="line">        data-lang=<span class="string">&quot;zh-CN&quot;</span></span><br><span class="line">        data-loading=<span class="string">&quot;lazy&quot;</span></span><br><span class="line">        crossorigin=<span class="string">&quot;anonymous&quot;</span></span><br><span class="line">        <span class="keyword">async</span>&gt;</span><br><span class="line">&lt;/script&gt;</span><br></pre></td></tr></table></figure></div>
<p>如何应用于博客上的方式应该是因博客主题而异的，可以参考主题的使用文档（大多数可能是需要在<strong>对应主题</strong>的配置yml文件中设置的）。</p>
<p>完成这些配置之后重新生成网页文件，应该就可以看到评论系统了。访客通过GitHub账号登录即可评论。来自本地服务器预览和域名访问的评论都会实时在仓库的Discussions中显示，并会通过邮件提醒仓库的所有者。<del class="mask">所以拒绝恶意刷屏从你我做起</del></p>
<p>欢迎你们来评论呀！</p>
]]></content>
      <categories>
        <category>站务管理</category>
      </categories>
      <tags>
        <tag>经验分享</tag>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>hexo渲染数学公式问题解决</title>
    <url>/2025/02/05/hexo%E6%B8%B2%E6%9F%93%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h3 id="问题">问题</h3>
<p>在使用Hexo建立博客的时候，我发现数学公式是无法直接在网页上渲染出来的。本博客使用的Redefine主题提供了<a class="link" 
 href="https://redefine-docs.ohevan.com/zh/plugins/mathjax" >MathJax插件的安装和启用方法<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>，但最后发现只有行内公式和部分行间公式被成功渲染了。（此事在<a
href="/2025/02/03/博客建立经验分享/#其他的细节杂项（坑）">博客建立记录帖</a>中亦有记载）</p>
<p>后来检查发现，出现这种问题的原因很有可能是markdown中下划线表示斜体，这与其在LaTex中表示下划线的语义发生了冲突。</p>
<h3 id="解决">解决</h3>
<blockquote>
<p>主要参考：<a class="link" 
 href="https://stardustorr.github.io/2024/11/09/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/Hexo%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F%E6%B8%B2%E6%9F%93%E5%A4%B1%E8%B4%A5%E7%9A%84%E8%A7%A3%E5%86%B3/" >Hexo中数学公式渲染失败的解决
- Stardustor's Blog<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
</blockquote>
<p>网上对此提出的解决办法是：将原本的<code>hexo-renderer-marked</code>引擎更换为<code>hexo-renderer-pandoc</code>（原先的引擎并不支持MathJax）。</p>

  <div class="note-large red">
    <div class="notel-title rounded-t-lg p-3 font-bold text-lg flex flex-row gap-2 items-center">
      <p>提醒</p>

    </div>
    <div class="notel-content">
      <p>在安装<code>hexo-renderer-pandoc</code>引擎之前，<strong>需要先在电脑上安装pandoc</strong>。可以前往<a class="link" 
 href="https://github.com/jgm/pandoc/releases/tag/3.6.2" >pandoc仓库发布页面<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>下载安装包。对于Windows操作系统，建议下载msi文件，直接无脑点下一步完成安装即可。</p>
<p>在cmd命令行输入<code>pandoc --version</code>，若出现版本号则说明安装成功。</p>
<figure>
<figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/pandoc_version.png"
                     
alt="pandoc安装成功的命令行" 
                ><figcaption>pandoc安装成功的命令行</figcaption></figure>
<figcaption aria-hidden="true">pandoc安装成功的命令行</figcaption>
</figure>
<p>如果不提前安装pandoc，之后在<code>hexo clean</code>或<code>hexo generate</code>处会报错<code>[ERROR][hexo-renderer-pandoc] pandoc exited with code null.</code>。</p>

    </div>
  </div>
<p>在站点根目录下运行命令：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">npm uninstall hexo-renderer-marked --save</span><br><span class="line">npm install hexo-renderer-pandoc --save</span><br></pre></td></tr></table></figure></div>
<p>然后重新生成博客：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">hexo clean</span><br><span class="line">hexo generate</span><br><span class="line">hexo server</span><br></pre></td></tr></table></figure></div>

  <div class="note p-4 mb-4 rounded-small blue 提醒">
    <p>对于需要渲染数学公式的文章，需要在文章头部添加<code>mathjax: true</code>。</p>

  </div>
<p>此时，数学公式应该能够正常渲染了。下面放几个复杂度不同的公式测试一下：</p>
<ul>
<li><p>二次方程求根公式 <span class="math display">\[
x = \frac{-b \pm \sqrt{b^2 - 4ac}}{2a}
\]</span></p></li>
<li><p>欧拉公式 <span class="math display">\[
e^{i\pi} + 1 = 0
\]</span></p></li>
<li><p>矩阵公式 <span class="math display">\[
\left( \begin{matrix}
  1&amp;      2&amp;      3\\
  4&amp;      5&amp;      6\\
  7&amp;      8&amp;      9\\
\end{matrix} \right) \cdot \left( \begin{array}{c}
  x\\
  y\\
  z\\
\end{array} \right) =\left( \begin{array}{c}
  6\\
  15\\
  24\\
\end{array} \right)
\]</span></p></li>
<li><p>多行方程 <span class="math display">\[
\begin{align}
f(x) &amp;= \int_{-\infty}^\infty \hat{f}(\xi) e^{2\pi i \xi x} \, d\xi
\\
\hat{f}(\xi) &amp;= \int_{-\infty}^\infty f(x) e^{-2\pi i \xi x} \, dx
\end{align}
\]</span></p></li>
<li><p>交换图表（需amsmath宏包） <span class="math display">\[
\begin{equation}
\begin{CD}
A @&gt;f&gt;&gt; B \\
@V g VV @VV h V \\
C @&gt;&gt;k&gt; D
\end{CD}
\end{equation}
\]</span></p></li>
<li><p>极限 <span class="math display">\[
\lim_{n \to \infty} \left( \sum_{k=1}^n \frac{1}{k} - \ln n \right) =
\gamma
\]</span></p></li>
<li><p>量子力学符号 <span class="math display">\[
\hat{H} \psi = E \psi \quad \text{where} \quad \hat{H} =
-\frac{\hbar^2}{2m} \nabla^2 + V(\mathbf{r})
\]</span></p></li>
<li><p>概率论公式 <span class="math display">\[
P(A \mid B) = \frac{P(B \mid A) P(A)}{P(B)}
\]</span></p></li>
<li><p>复杂公式 <span class="math display">\[
\begin{aligned}
  q\left( \mathbf{x}_t|\mathbf{x}_{t-1} \right) &amp;=\sqrt{\alpha
_t}\mathbf{x}_{t-1}+\sqrt{1-\alpha _t}\epsilon _{t}\\
  &amp;=\sqrt{\alpha _t}\left( \sqrt{\alpha
_{t-1}}\mathbf{x}_{t-2}+\sqrt{1-\alpha _{t-1}}\epsilon _{t-1} \right)
+\sqrt{1-\alpha _t}\epsilon _{t}\\
  &amp;=\sqrt{\alpha _t\alpha _{t-1}}\mathbf{x}_{t-2}+\sqrt{\alpha
_t-\alpha _t\alpha _{t-1}}\epsilon _{t-1}+\sqrt{1-\alpha _t}\epsilon
_{t}\\
  &amp;=\sqrt{\alpha _t\alpha _{t-1}}\mathbf{x}_{t-2}+\sqrt{1-\alpha
_t\alpha _{t-1}}\epsilon\\
  \vdots\\
  &amp;=\sqrt{\bar{\alpha}_t}\mathbf{x}_0+\sqrt{1-\bar{\alpha}_t}\epsilon\\
  q\left( \mathbf{x}_t|\mathbf{x}_0 \right) &amp;=\mathcal{N} \left(
\mathbf{x}_t;\sqrt{\bar{\alpha}_t}\mathbf{x}_0,\left( 1-\bar{\alpha}_t
\right) \mathbf{I} \right)\\
\end{aligned}
\]</span></p></li>
</ul>
<h3 id="弯路">弯路</h3>
<p>网上对于如何解决这个问题的方法有很多，其中还有一种主流的方法是将渲染引擎更换为<code>hexo-renderer-kramed</code>，并且还需要进入项目根目录下该引擎的源代码进行修改以解决语义冲突，并修改配置文件，很麻烦。我先参考的就是这个思路。</p>
<blockquote>
<p>主要参考：<a class="link" 
 href="https://blog.csdn.net/qq_44846324/article/details/114582328" >这次彻底解决在Hexo中渲染MathJax数学公式出现的问题！！！
- CSDN<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p>不推荐食用，比较麻烦。<del class="mask">话说你这也没解决啊喂！</del></p>
</blockquote>

  <div class="note p-4 mb-4 rounded-small blue 提醒">
    <p><code>hexo-renderer-kramed</code>引擎在<code>hexo-renderer-marked</code>渲染引擎的基础上修改了一些bug（“kram”这个名字目测是把“mark”倒过来拼写得到的），支持了MathJax。我没有把这个引擎卸载，现在看来暂时没什么问题，不会和pandoc渲染引擎冲突。</p>

  </div>
<p>并且更加令人绝望的是，一通操作过后，行内公式的渲染还是跟之前一样没什么问题，而行间公式不仅渲染不出来，甚至直接不在网页上显示了。我将配置文件改回来之后安装了pandoc渲染引擎才可以正常渲染，算是勉强解决了问题吧。</p>
<p>有时候可能会出现大部分公式渲染正确，部分公式出错的情况，可以尝试多渲染几次。</p>
]]></content>
      <categories>
        <category>站务管理</category>
      </categories>
      <tags>
        <tag>经验分享</tag>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>Arcaea故事模式第1章剧情原文</title>
    <url>/2025/02/06/ArcaeaStoryChapter1/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script>
  <div class="note-large yellow">
    <div class="notel-title rounded-t-lg p-3 font-bold text-lg flex flex-row gap-2 items-center">
      <p>主要参考</p>

    </div>
    <div class="notel-content">
      <ul>
<li><a class="link" 
 href="https://zh.moegirl.org.cn/Arcaea/%E6%95%85%E4%BA%8B%E6%A8%A1%E5%BC%8F%E5%89%A7%E6%83%85#.E4.B8.BB.E7.BA.BF.E5.89.A7.E6.83.85" >Arcaea/故事模式剧情
- 萌娘百科<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link" 
 href="https://arcwiki.mcd.blue/%E6%95%85%E4%BA%8B%E6%A8%A1%E5%BC%8F%E5%89%A7%E6%83%85%E8%AF%A6%E8%A1%A8_(%E7%A7%BB%E5%8A%A8%E7%89%88)#0-1" >故事模式剧情详表
(移动版) - Arcaea中文维基<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
</ul>

    </div>
  </div>

  <div class="note p-4 mb-4 rounded-small blue">
    <p>这部分剧情的<b>解读</b>见此博客：<a
href="/2025/02/07/ArcCh1Interpretation">Arcaea第1章主线剧情解读</a></p>

  </div>
<h2 id="序章">0-序章</h2>
<details class="yellow" data-header-exclude><summary><i class="fa-solid fa-chevron-right"></i>0-1 </summary>
              <div class='content'>
              <p>随后，她们坠入了前所未有的甜美梦乡。</p><p>……</p><p>无数故事迎来终点，又有无数故事如歌谣般继续流转。但其中，永远有那么一些歌谣无人翻阅，无人吟唱……它们与时代一同尘封在了无声的记忆中。 记忆……永不偏颇的存在——无论美好还是破碎，归属一人还是千人，都恰如其分地在时间的长河中留下烙印。纯良也好，悲惨也罢，一些事纵然会令无数人惊叹，但就算无人问津也无妨，记忆会捕捉一切。</p><p>而那些无人问津的过去最终会褪色、淡去，成为以太。</p><p>那些被遗忘的自然不再重要，不是吗？有什么必要记住失势和苦痛？有什么必要记住已逝的美好？它们都已成为往事。</p><p>寻求答案固然重要，只是……</p><p>时间的年轮并不会为你的思考而停下脚步。</p><p>在你思考的时候，做出回答的时候，时间之书在不停地书写，其中的档案在不停地增加……</p><p>于某个瞬间，某个地点，回忆的档案开始将它们织成丝线，而于万千丝线之中：</p><p>命运的丝线牵引着的，是两位少女的灵魂。</p><p>这通透无色的丝线闪闪发光，未曾受到过伤害，理想地恰如其分：</p><p>只因它们是关于光明和纷争的丝线。</p>
              </div>
            </details>
<details class="yellow" data-header-exclude><summary><i class="fa-solid fa-chevron-right"></i>0-2 </summary>
              <div class='content'>
              <p>一家咖啡馆内，一名年轻女孩倚着窗坐着，四下静寂：早在开门营业之前她便来到这里。她的杯中升起热腾腾的蒸汽，模糊了她身旁的玻璃……这是一个寒冷的早晨。</p><p>捕捉，记录。</p><p>孤身一人，男人拔出了腰间的佩剑。他面前的村庄早已化作一片火海，他身后放火点燃村庄的劫犯仰天狞笑着。知道自己必死无疑，男人转身，举起了剑——</p><p>缝织，交错。</p><p>有着奇形怪状的耳朵的朋友们在元素论课上哄堂大笑——一位同学利用光亮与火焰合成了一幅动画，让大家在一起重温了另一位朋友的糗事……</p><p>凝结，定格。</p><p>除此之外，还有很多很多东西被归档，被定格。世世代代人，千千万万事……</p><p>无数回忆的碎片划过永昼的日空。</p><p>如斑驳的风，破碎的雨，于空中悬吊。</p><p>陈旧的念想与过去的时光遵循着无名的法则流动——或许这“舞蹈”毫无意义：有时，它们甚至完全静止。它们或动或静，飘忽不定，但无论如何，玻璃即是唯一可定义此处的存在。</p><p>云则是天空中唯一的存在：绵软软的云层之上，光束倾泻着，填满一切缝隙，不予阴影现身的机会。有时，它迸发出的力量是令人惊奇的——那么明亮，那么刺眼，像一抹豪横的笑。</p><p>而脚下的无垠大地则往往是空洞的，有些地方布满一排排的建筑，其中零星散落着几桩歪斜的石碑：在时间的长河中，它们一直如此。</p><p>无色的石碑一如无色的大地，为何它们伫立于此？</p><p>那是因为，这是片属于记忆的土地。这个理由足够了，不是吗？</p><p>这片大地接纳了你流下的泪水，见证了你和她携手同行的日子……</p><p>你一定还记得吧。</p><p>不过，即使你不再记得，这些堡垒高垣也并不能帮你回忆过去。</p><p>这些建筑，这一切的一切，都无法作证——从来便没有什么诗与远方。当然，这一切的确是有意义的，但也仅仅是有意义而已，并没有什么更深层次的东西了。</p><p>它们存在的目的，仅仅是存在本身。</p><p>初级、简单的存在，用以满足你最原始的思考和感受需求。</p>
              </div>
            </details>
<details class="yellow" data-header-exclude><summary><i class="fa-solid fa-chevron-right"></i>0-3 </summary>
              <div class='content'>
              <p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/arcaea_story_cg/Story_0-3_cg.jpg"
                      
                ></p><p>新的故事已经开篇：又一个故事，两个女孩的故事，如何活下去的故事。</p><p>没人能教会你如何去好好生活，只有生活本身可以。</p><p>有时，它是那么美好； 有时，它又是那么令人战栗。</p><p>这是两个女孩共享的情感和经历。</p><p>你是否曾为万物的美丽而流泪？</p><p>毫无疑问你已在为这世间的一切不平而哭泣了。</p><p>当你再度睁开眼面对这一切，你是否还会在乎？还是只是满足于苟且活着？</p><p>这个世界又是否会允许你感到满足？</p><p>想要感到开心并不是罪过。</p><p>空中漂浮着的记忆碎片，有美好的，也有悲怮的，分别落于两位女孩的身旁……</p><p>新的故事即将开篇，你们的丝线在未来将如何交织？</p><p>周围都是你的倒影，你的头顶，你的身旁——</p><p>无数条世界线的倒影，倒映着的不是可能性，而是确定性——它们都是实实在在发生过的过去。</p><p>站好了，好好地看看它们。然后问自己：</p><p>你想以什么样的姿态活着？</p><p>远处传来一声巨响，它的回声不绝于耳。随后，万物归于沉寂。</p><p>随后，她们坠入了前所未有的甜美梦乡。</p><p>沉静而又安详——一个女孩倚在墙边，另一个女孩靠在废墟的塔楼之下。</p><p>好吧，现在她们睡得没那么安稳了。</p><p>罕见地，白发女孩倚着的断墙上落下了几点阴影，斜洒在她身上。</p><p>黑发女孩则完全暴露在光亮之中，它们肆意摊开于女孩的裙摆上……</p><p>随后，她们睁开了眼。</p><p>……</p><p>你知道吗？此段记忆，此篇关于光明与纷争的故事……</p><p>……以一粒装满了感情的种子被埋进土中为始。</p><p>然后，在被珍视和被唾弃的回忆的共同滋养下开始生根发芽。</p><p>再然后，它便茁壮成长，执拗地想去到更高的地方，一如这执拗的时间。</p><p>随着她们醒来，命运的齿轮也开始转动——一个被祝福的女孩的的命运和一个被诅咒的女孩的命运开始编织。</p><p>随后，一切便又遗忘于历史的长河之中。</p>
              </div>
            </details>
<h2 id="光">1-光</h2>
<details class="red" data-header-exclude><summary><i class="fa-solid fa-chevron-right"></i>1-1 </summary>
              <div class='content'>
              <p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/arcaea_story_cg/Story_1-1_cg.jpg"
                      
                ></p><p>恢复意识的她，发现自己苏醒于这个飞舞着玻璃蝴蝶的地方。"多么令人愉快啊，"她想，"这些美妙的图案居然能在空中移动呢。牵引着它们的丝线在哪里？"</p><p>她蹲了下来，整了整裙子，环顾四周才发现这附近没有任何丝线。那些事物，也并不是蝴蝶——玻璃碎片，不依靠任何外力便飞舞于空中。"太美妙了！"她自心底赞叹道。</p><p>这些玻璃反射出了另一个纯洁的世界。她从中看见海洋、城市、火焰、光芒；美好的景象目不暇接。她抬起了自己的手，试图去抓住它们，开心地笑了出来。</p><p>她并不知道这些玻璃碎片有个名字：Arcaea。实际上，名字对这些过于美好的事物来说并不重要。她触碰、旋转、观察它们；她靠这样来娱乐自己。这已经足够了，难道不是吗？</p><p>现在留给她的，有六个问题：何人、何事、何处、何时、何故与何情。在这些疑问的包围下，她没有问出任何一个，也不想得到任何答案。Arcaea的光芒已经使她心满意足。这是她与这个新世界的邂逅。</p>
              </div>
            </details>
<details class="red" data-header-exclude><summary><i class="fa-solid fa-chevron-right"></i>1-2 </summary>
              <div class='content'>
              <p>但是，疑问还是不可避免地来临了。</p><p>少女立于玻璃碎片的螺旋中，沉思着："但说实话，它们究竟是什么呢？"传送门入口？窗户？抑或是……回忆？</p><p>最后的猜测，"回忆"，使她一怔。"它们是回忆，"她失声说道。就在这一刻，那股疑惑消失殆尽。</p><p>因为某种原因，这个地方充满了回忆。谁的回忆？又是什么回忆？她心中不能肯定。但她已经停止了疑问。</p><p>因为某种原因，那些玻璃跟随着她。虽然她无法抓住它们，但碎片仍然与她形影不离。一时兴起的她，决定要开始收集它们。</p><p>一片一片收集。 没有任何理由。</p>
              </div>
            </details>
<details class="red" data-header-exclude><summary><i class="fa-solid fa-chevron-right"></i>1-3 </summary>
              <div class='content'>
              <p>没有时钟的情况下，她根本不清楚多少时日已经过去了。同时，新的思绪正逐渐浮现于她的脑海中。</p><p>玻璃碎片中，蕴含着美好的事物——她对此深信不疑。仔细一想，回忆会随着时间的流动不断改变，但却与过去有着最亲密的联系。它可以苦涩，也可以甘甜，但她认为这两者都十分迷人。</p><p>如今，她可以瞧见自己所能见到的回忆——来自于别的场所与人们——并且因它们的美而感到心旷神怡。Arcaea们闪烁着，散发着完美的光芒，在这破碎的世界里显得格格不入。原本这些事物就容易博得人们的喜爱，而蕴藏其中的回忆着实使它们更惹人心爱了。</p><p>她哼唱着，双手飞扬，一边踩着破碎的小道。她带上了任何可能属于这整个世界的回忆，跟在一条发光的溪流之后。这些属于一个既丑陋，又美丽的世界的回忆……</p><p>"多么好啊……"她叹息着，微笑着，陷入了宁静。这一切，看上去都太过于美好了。在这里，不需要担心任何事物。这美好而又简简单单的世界，只需要令人感到愉快就足够了。没错，无需多求。</p>
              </div>
            </details>
<details class="red" data-header-exclude><summary><i class="fa-solid fa-chevron-right"></i>1-4 </summary>
              <div class='content'>
              <p>这是道使人愉快的风景线。长久以来，她行走于这荒芜却又美丽的世界，赞扬着她所找到的新鲜事物。</p><p>长久以来，她带领那些玻璃碎片一同旅行，以至于天空已经变为一面弯曲的镜子，反射出了她所能见到的最遥远的光芒，整体望上去就像要触碰到天际。这绝妙的穹顶闪着光，从未离开过她的头顶。随着她只被华丽而又美好的事物环绕，此处成为了无尽的极乐世界。</p><p>她走下那段曾经通向一座庄园的螺旋阶梯。只可惜周围的墙皆已坍塌，而回忆取代了墙体。所有的事物都比从前更加美好：她从那儿跃向前方，撞得回忆飞散开来；她沉浸于闪闪发光的Arcaea——在被她找寻到后，它们便飘起并融入了她头顶那片人造天空。她感到无比欢欣，高兴地笑了。一朵花、一个吻、一段爱情、一次降生——她的眼前飞过了那一次又一次生命组成的玻璃海洋，而它们也接连隐于了其余碎片的光辉之中。她早已见过这些映像无数次，但仍丝毫不会感到疲倦。</p><p>她凝视着上方的墙体。当碎片都融入在一起后，它们变得更加生机勃勃。她微笑着，享受着这满意的感觉——在她继续开始漫游前。同时，就和以往一样，她没有留心这样做会给她带来何种后果……</p>
              </div>
            </details>
<details class="red" data-header-exclude><summary><i class="fa-solid fa-chevron-right"></i>1-5 </summary>
              <div class='content'>
              <p>物极必反——人们坚信这是真理。她可能并不知晓这一点，抑或是对此毫不在乎。</p><p>少女如今穿行于一间看似老旧大礼堂的地方。仿佛是一种超自然力量所造成，这里的辉煌景象被完美地劈成了两半，昔日的庄严感也早已黯淡乏味，在这声音的坟墓中同样飘流着回忆：舞蹈、演出、希望、胜利。</p><p>她的嘴抽搐着。是因为这些事物现已变得单调无趣，还是另有其因？她抬起了手，而Arcaea们靠近了她，温柔地飘舞在她的手掌之上、指尖之中。她茫然地注视着它们。她已经是第几次见到那退役乐队的送别欢呼了？她已经是第几次见到两兄弟间的拥抱了？她见到了太多次爱的形式——过于平凡，就像是这片被忘却的陈旧世界中的日常标准。她让这些回忆远离她，下定决心不再去想这些事。</p><p>它们升了起来，飞入她仍在收集的那些回忆之中。她如今正望向它们的终点。比起她刚开始收集的时候，那地方早已明亮不少。它看上去每天都在变得更耀眼夺目……</p><p>究竟已经过去了多少天？她畏缩着，脸上扭出一丝怪相。她随即把自己的坏脸色一扫而空。</p><p>也许她只是需要更多——任何遗失的部分都将会被找到。她冷静下来，开始继续前行。她并不想自己被一个事实所干扰——无论她怎么做，那些跟随着她的Arcaea都不愿离去。</p>
              </div>
            </details>
<details class="red" data-header-exclude><summary><i class="fa-solid fa-chevron-right"></i>1-ZR </summary>
              <div class='content'>
              <p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/arcaea_story_cg/Story_1-ZR_cg.jpg"
                      
                ></p><p>"天堂"其实也是地狱的一种。</p><p>事实上，虚度光阴和自我放纵是对热情的诅咒。接连不断地汲取愉快的事物，将会无止境地麻痹感官，使得"快乐"变得无比朦胧，暗淡，甚至完全失去原本的目的。如今万物再无目的。她从未拥有过目的。</p><p>天空炫目到接近空白。</p><p>她也许正四处徘徊，也可能正站在原地；她对此无法确认，而这也无关紧要。这片她创造的天空的确引起了她的注意，但她却无法辨别其中涵括的回忆。这已是一片充满压迫感的不透明雾霾，散发着令人窒息的空虚感。她正一点一滴地丧失自我。</p><p>而在失去自我时，她始终对这渐渐渗入的瓦解之力感到麻木。虽然她早已不记得，但是招待她步入这座让人感到愉快，却又让人窒息的牢笼之人，正是她自己。现在，她甚至失去了为自己担忧的自由。天空变得越来越明亮，少女的心智也不断流逝。在这仅剩的时间里，她仰望上方，好像等待着什么。明亮——无比耀眼——散发无尽幸福的极彩色苍天：灿烂夺目的回忆淹没了她。</p><p>她的思绪终被清空。</p><p>并且，毫无意义地，光芒褪去了。</p><p>毫无意义地，时间流逝了。</p><p>之后，一名女孩仰望着空无一物的苍天。她的思想终止了——与她的故事一起。</p>
              </div>
            </details>
<details class="red" data-header-exclude><summary><i class="fa-solid fa-chevron-right"></i>1-7 </summary>
              <div class='content'>
              <p>少女跪坐在地上，微抬着下巴。她那粗糙而又极具渗透力的创造物，不久便会将她吞噬进自身的光芒，诱使她忘却一切。它跃动于她头顶上方，散发着光芒，温柔却又难以忍受。她未多想，任凭那东西渐渐夺走她的全部自我。</p><p>而在那浩瀚虚无之中，她的双目捕捉到了什么事物。</p><p>仅仅是那特异之处便打破少女的麻木感，少女的目光也开始在那物体上摇摆：一片有些特殊的玻璃，只是有抹鲜红，却着实引人注目。不知是现实或只是大脑产生的幻觉，周遭原本晦暗的天空显得越来越清楚。她认为，天空变得容易看清了。她认为——她才意识到自己已经几个世纪没有思考过。</p><p>这座如今正剧烈颤动的天堂已歪曲变形，一道巨大的裂痕更是从中划过，一切都围绕着一段崭新的回忆扭曲起来：一片本不该存在的回忆。它从那一切中破空而出，也破坏了整片天空。少女所创造的穹顶坠落下来，猛烈却又显得平稳，从中散落的星点光辉布满了整片空气。这壮观华丽的景象原应使她目瞪口呆，但她仍惦记着片刻前刚刚诞生，正向她飘来的那一片玻璃——被喜悦回忆中令人恐惧的混沌所缠绕的那一片玻璃。</p><p>那事物本身也是象征喜悦的回忆：那是早已被她遗忘的，关于她自己的回忆。</p><p>"什么时候——我真的——？"</p><p>声带太久未被使用，少女的话语声变得破碎不堪。</p><p>在她的掌心之间，那诞生自虚无的奇异碎片旋转起来，而从中她见到了自己刚刚苏醒过来的时候，与成群的玻璃起舞，游荡于这片镜面世界，无比欢欣。泪水有如泉涌。她心中明白，幸福在很久之前便抛弃了她。</p>
              </div>
            </details>
<details class="red" data-header-exclude><summary><i class="fa-solid fa-chevron-right"></i>1-8 </summary>
              <div class='content'>
              <p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/arcaea_story_cg/Story_1-8_cg.jpg"
                      
                ></p><p>晶莹闪亮的玻璃碎片犹如不均匀的雨滴般落下，如同以往的任何时刻，倒映着那些死去的世界。位于万物中心的少女全神贯注地盯着那片反射了何种新事物的碎片——仍旧存在的那片世界。</p><p>泪水从眼角滑落，她却尚未了解原由。在拾回心智的过程中，她饱受折磨——她失去了曾经她所拥有的一切，而那些事物如今正纷纷跌落在她的身旁。但同时，她也为失去了自己的热情而痛苦。那些倒映的回忆展现出一段更美好，却放纵愚昧的时间，而她也正是在那时走入了她自己布下的陷阱。哪怕她知道那样将会带来何种结局——这些得过且过，引领她步步迈向麻木的旅途经历——她还会只是为了一时的快乐而重蹈覆辙吗？</p><p>玻璃中的鲜红呼应着她衣服上的鲜红，而她紧紧抓住那片碎片，使得鲜红也浮现于她的手心。随着那温暖的液体流过荧光的表面，过去与今时双双模糊。她终能再次感受情感——可这股情感却比她从前所感受到的一切都更为强烈。她感受到了足以压垮她内心的悔恨。在这些时间里，她近乎骄傲自满地四处游荡，心中漫无目的。她搜集着Arcaea，享受着它们，却从未思考过哪怕最小的原因。她害自己成为备受苦恼所折磨且总感世事乏味的快乐主义者，亲手将自己锁死在这人造的炫目监狱中。</p><p>然而面对"为什么"的疑问，这里从来就没有过答案。只是取悦自己？也并非如此。她跌倒于双膝，怀抱着她胸前的回忆哽咽、啜泣、痛哭，心中明白自己已经犯了弥天大错。浴于美妙的爱情与绚丽的生命过久的她，已经对这些事物感到反胃，而这残酷的事实让她悲痛不已。</p><p>少女沉浸在悲伤之中不断哭泣，尽可能地思考着方才发生的一切，与它们所象征的意味。</p>
              </div>
            </details>
<details class="red" data-header-exclude><summary><i class="fa-solid fa-chevron-right"></i>1-9 </summary>
              <div class='content'>
              <p>死寂。</p><p>少些蕴含曾经的碎片落下来，间歇性打破了沉寂，但女孩的悲痛已经平复下来。她早已不再直率地哭泣，仅仅是静坐在那些闪闪发光的玻璃之中，脸颊尚留有泪痕，双手的鲜血也已干涸。 恐惧、担忧与悔恨都已结束，她现在必须向前看了。</p><p>她因误入歧途而做出一切。事实上，她从来没有真正地被哪怕任何事物引导过。凭借着"更多的愉快事物只会让一切变得更好"的念头，她用美好回忆填充了整片天空，不曾意识将成堆的神秘碎片集中于一处会带来怎样的危险。她这才意识到这些东西会威胁她的全部，将她吞噬。</p><p>如果她想要奋力前行，她必须需要一个理由作为动力。她需一五一十地回答那些曾几时被她遗忘的老问题。这个世界有着怎样的意义？为什么她会在此处？为什么在温柔的回忆被她吸引时，那些她曾瞥见有苦难闪现的碎片却会拒绝她？她到底是谁？</p><p>少女的双眼再度有了光泽，依靠那颤抖的双腿直立起来。在她这样做的时候，围绕着她的Arcaea忽然移动起来。她好奇地注视着它们，试着高举她的手。它们跟随着她的手飘舞而起，而她陷入沉思。她察觉到这与从前不太一样，但她自身也有些地方变化了。</p><p>Arcaea不再主动接近她，而她也不再放任自己被束缚于牢笼中。因为手上沾满了血，她用手背抹去自己的泪水，让这些将她引领至这条崭新路途的碎片们跟随于她的身后。她会让那一切成为一段回忆，而她也将重新面对这陌生的世界。无论是好是坏，她将找寻到一切的谜底。</p><p>她如此发誓，矢志不渝。</p>
              </div>
            </details>
<h2 id="对立">2-对立</h2>
<details class="blue" data-header-exclude><summary><i class="fa-solid fa-chevron-right"></i>2-1 </summary>
              <div class='content'>
              <p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/arcaea_story_cg/Story_2-1_cg.jpg"
                      
                ></p><p>她醒来在一座损毁的塔楼中。飘浮着的玻璃碎片是她第一个注意到的事物。它们引领她前往了室外——那纯白的世界。</p><p>纯白色、大片的纯白色，以及更多的玻璃碎片。它们看上去正在被她吸引而来，而被激起了好奇心的她开始观察这些碎片。</p><p>就像透过火车车窗看外头稍纵即逝的景色一般，她瞧见了阴雨的景象。下一次是艳阳。再下一次是死亡。她厌恶地远离了这些碎片。</p><p>虽然总是紧随着她，可这些碎片总能在少女试图捏碎它们时躲开。少女心中的厌恶渐渐地化为为愤怒，而她迫使自己把注意力转移到那灰白色的天空。然而，在她仰望天空之际，原先脸上的情绪荡然无存。她的嘴微微张开来，却因过于惊讶而说不出半句话来。</p><p>玻璃在高空中搅动着、闪烁着、旋转着。这看着就像是场玻璃碎片的暴风雨。</p><p>她后悔把注意力转移到天空上。但碎片们已经发现了她，渐渐降落下来，要与她打个招呼。</p>
              </div>
            </details>
<details class="blue" data-header-exclude><summary><i class="fa-solid fa-chevron-right"></i>2-2 </summary>
              <div class='content'>
              <p>那是一股难以用语言形容的压迫感。巨量的碎片组成了飓风般的激流。它们并不会割伤她，也未反射她的面庞。它们在她面前犹如强风般推动着她，却又突然转过弯，仿佛被更强的风暴所侵袭一般。她稳稳地伫立在原地，注视着这一切。</p><p>注视着……回忆？……属于一个污秽世界的回忆。"这是……！？"她伸出了手，"这些……！"</p><p>回忆。刻画着痛苦、背叛、嫉妒的回忆。</p><p>当她阻挡住眼前这片碎片时，其余的碎片也被影响了。它们就这么静止在空中，一动也不动。她的脑袋左右晃动着。"这些只是……"</p><p>黑暗？它们只是纯粹的黑暗吗？但无论这些碎片在反射什么……她从中未见到一丝光芒。哪怕是最小的火花，都会在一瞬间消失于她的视线。她紧咬嘴唇，毫不诙谐地微笑着。"这算是什么低劣的玩笑？"她喃喃自语道，"这个世界只充满了痛苦……"</p><p>说出这番话后，就连她脸上的苦笑也消失了。</p>
              </div>
            </details>
<details class="blue" data-header-exclude><summary><i class="fa-solid fa-chevron-right"></i>2-3 </summary>
              <div class='content'>
              <p>没有时钟的情况下，她根本不清楚自己已经观察这些回忆多久了，但她深信这段时间已经很长。</p><p>那么一刻，她试着去搜寻哪怕一丝愉快的回忆，只是确认它们是否存在。它们的确在那儿，数量稀少，而那众多的痛苦回忆却从未放弃追捕她。此时，她已经对这令人生厌的地方产生几分了解。</p><p>她现在正身处于玻璃组成的巨大旋涡的正中央，而它们则像一宇宙般展现在她的面前。少女的心中推断出两种可能性：这些玻璃碎片们映射出的世界——或者说多个世界——中，只存在黑暗的事物；或者被保留于此的，只有可怖事物的回忆……不论如何，她都想尽快摆脱这一切。</p><p>可忽然之间，她的心中有什么事物发生了变化。如今，直视这些回忆使她感到舒心。她收集了那样的回忆——看上去，十分愉快。</p><p>"如果我能摆脱这些垃圾，或使它们所象征的那些场所变得更加美好……"那些充满混乱甚至光芒的场所。 这将使她感到高兴。</p>
              </div>
            </details>
<details class="blue" data-header-exclude><summary><i class="fa-solid fa-chevron-right"></i>2-4 </summary>
              <div class='content'>
              <p>时间已经过了很久，而少女的信念坚定了许多。</p><p>从开始行动以来，她已经探索了大部分这玻璃与镜子的世界，沿途也收集了不计其数的碎片。像是一条永无尽头的围巾一般，它们围在她的脖子四周，在她的身后延伸出一条极长的线路。如今，她驻足于一座残旧的塔楼上头，面露微笑往外眺望着。来自各处的恐怖回忆在她身后汹涌地扭曲着。</p><p>她现在正紧盯着那一直吸引着她注意力的地方，但她甚至从不想往那里踏出半步。那是片拥有疯狂几何形状的巨大迷宫，缓缓延伸到遥远的天际。没错，那儿依然只有更多的玻璃。没错，她可以站在这里感受到那迷宫中涌动着的污秽。虽然尚不清楚自己该怎么做，但她决心摆脱这些跟随她的令人厌恶的碎片。在结局来临前，她仍然会收集它们。她对把所有肮脏事物聚集于一处感到十分欣慰。离清除所有碎片的日子会因此来得更加容易。这个迷宫异常地险恶，而她因此来到这里，信心满满地想要收集其中所有的碎片。</p><p>围绕那迷宫的是闪闪发光的美好回忆，如同一片不断变化的海洋。当她步入迷宫时，那片海洋退向两边，仅有少数碎片加入了她身后的行列。然而，在边行走边分散那些美好回忆的碎片时，她犹豫了。自己被希望夹在中间，面前等待着她的却只有绝望。 她紧咬着自己的嘴唇……而她的心也动摇了。</p>
              </div>
            </details>
<details class="blue" data-header-exclude><summary><i class="fa-solid fa-chevron-right"></i>2-5 </summary>
              <div class='content'>
              <p>在过去的某一刻——绝对——这一切都曾更加美好。</p><p>少女不记得任何事。在苏醒于这个世界后，她也只见到了属于其他事物的回忆。因此，她已经假设了各种答案，尽管她只思考了数秒。她敢保证这儿的玻璃碎片，乃至这一整个世界，都没有任何确实的价值。污秽与恐惧、眼泪与伤痛、微笑与死亡——全都不值一提。</p><p>但在过去的某一刻，这一切绝对都曾更加美好。简单的规则，往往会是真理：影子的诞生起源于光明。影子如今正于她背后匿伏，而光明正包围着她。</p><p>当踏入这欢乐而又纯净的浪潮时，她心中未有足以扭转她决心的杂念。她将注意力完全置于眼前的邪恶，以至于她已经忘却了纯粹的善良。事实上，这在她心中翻腾起了小小的波浪。她不堪重负。每一次朝那盘陀状迷宫迈出步子的时候，她会瞥见余光中闪烁着的希望，随即停下脚步，质疑心中一切。然而，她有一个自己不愿面对且承认的，隐藏于光明与混乱之中的答案。她不想去思考那个答案。她绝不允许自己想到它。而在她真的做出觉悟之前，她已经站在了那不可思议之迷宫的入口处。</p><p>一时的冲动，促使她将手伸向那些美好的碎片。碎片之中是花田的回忆，而那些回忆在她的身边组成了花环。她并不知晓原因，而脑中那些所谓的原因，实际上也帮不了她任何忙。</p>
              </div>
            </details>
<details class="blue" data-header-exclude><summary><i class="fa-solid fa-chevron-right"></i>2-D </summary>
              <div class='content'>
              <p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/arcaea_story_cg/Story_2-D_cg.jpg"
                      
                ></p><p>她并不知晓自己曾拥有一个名字。如果她知道自己的名字，或许就不会选择走进这扭曲的黑色迷宫。那可能会是个意义深重的名字，而这只会使得她的疑问愈发强烈。但她并不知晓答案。所以少女紧咬牙关，重新坚定了自己的信念。先前的光芒不会使她动摇；先前的花环不会使她动摇。她步入这昏暗的结构中，准备将这里撕裂。</p><p>每一堵墙都是由苦难砌成，而墙的每一面都布满了惨剧，每一个角落都由畏惧构成。这是一座罪孽的城堡。简单来说，这儿的一切都显得无比荒谬，怪诞无稽。</p><p>少女的脸上再度绽放笑容。仅此而已。攀越于此、奔跑于此，那纯粹的厌恶已经使她疯狂。她的想法并没有错。玻璃只该被打碎。镜子只该被砸毁。当她兴高采烈地撕碎大片的迷宫，将走道翻入半空时，脸上的笑容扭曲了起来。她畏缩了；她的脑内绝对有什么不对劲的地方。在这片迷宫的中心，有着"什么事物"，比任何她曾见到的回忆都邪恶。她可以感受到那样事物——那事物如今与她十分接近，正呼喊着她。她的热情已经干涸，而她的脚步也逐渐放慢。下一刻，她看见了那片散发邪恶气息的玻璃碎片在空中旋转着，其中含括的是一个世界走向灭亡的回忆。</p><p>一只手搭在脸上的她，朝着那镜像世界望去。她依然记得她身下那片充满欢乐与幸福的海洋，与那如今环绕在她身边的花圈。她已经掀掉了迷宫的顶端一角，而墙壁也纷纷开始崩塌。阴暗的玻璃在她身边缓缓坠落，而远方的美好回忆则闪耀着明亮的光芒。</p><p>她透过指缝观看着那世界末日之景。她咽了口口水，靠着那股不知名的勇气，将手从自己的脸上移开。她伸出了手，把那世界尽头收入了自己所搜集的无数回忆之中。这片存在颠覆了一切，她也进而感受到心中那份货真价实的，如浪潮般的狂喜。无论之后的回忆有多么可怕，与此种记忆相比都算不上一缕羽毛。她确定自己已经变得足够强大，而她理所当然地想立刻把一切都摧毁。就这样，伴随着那抹真诚的微笑与疲惫的笑声，她从天空中降落到了地面上。那座古老的塔楼在她的力量驱使下逐渐陨落，化为了一座废墟。而她则怀抱着英雄般的信念，坚定不移地迈步向前。</p>
              </div>
            </details>
<details class="blue" data-header-exclude><summary><i class="fa-solid fa-chevron-right"></i>2-7 </summary>
              <div class='content'>
              <p>可能她需要为自己的情况感到担忧，因为她的心忽然剧痛起来。</p><p>她后退了一步，手捂着嘴，眼中是一片迷茫。她如今正站在一座更加巨大而充满苦痛的，如塔楼一般的迷宫中。但她只是一个扑腾跪倒下去。而在触及地面之前，地板结构土崩瓦解，先她一步向下坠落起来。</p><p>映射后悔时日的那些回忆如同披风包裹着她，而属于塔楼的回忆由一阵缓慢的雨点化作了一场倾盆大雨。她与这迷宫好似石块一般下落着。本应该因极快的下坠速度而感到恐惧的她，却被混乱支配了思绪。</p><p>她落入了一片由来自其他世界的欢乐回忆所组成的海洋之中。她与那崩坏的迷宫所带来的浪潮巨大无比。玻璃以既丑陋又美丽的形式相撞推挤。她跪坐在这场风暴的中心。她心中困惑的来源是她所承受的伤痛。她的一切都承受着伤痛。她的心脏仿佛随时会炸裂开来。她所收集的回忆形成的披风化作一团古怪的球体，包覆着她。洁白的世界消失于她的视野，只留下那些惨痛而邪恶的事物。她冒着汗，怀着猛烈起伏的情绪，颤抖着朝那些玻璃看去，深沉地朝着Arcaea看去。这下，她意识到自己的心正在碎裂。</p><p>她的理性正在碎裂。</p><p>先前目睹的那世界尽头的回忆，缓缓地映入了她的视野。</p>
              </div>
            </details>
<details class="blue" data-header-exclude><summary><i class="fa-solid fa-chevron-right"></i>2-8 </summary>
              <div class='content'>
              <p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/arcaea_story_cg/Story_2-8_cg.jpg"
                      
                ></p><p>少女在踏入这纯白色的荒废世界中时，曾有着多样的情感。在大部分时间，她所感受到的是愤怒之情，但她已经可以把那愤怒转变为一种离奇的希望。的确，她并没有任何有效的计划。实际上，她向前走的动力只是因为她相信路程的尽头会有什么美好的事物。她曾经满怀希望。她曾确信这些混沌会引领她前往光明。她曾确信那些她所经受的折磨、所面临的恐惧，都可以被打败。</p><p>是的，她曾经感情丰富。她如此强烈地坚信着自己的想法，以至于在她发现一切——事实上——都没有任何目的之后……她感到饱受折磨。</p><p>最悲惨的命运，莫过于曾拥有希望，却眼睁睁地看着它们破灭。少女跪坐在一个诡异的死亡之圈内，眼看着世界逐渐走向末路。这是她第一次感受到被称为悲伤的情感，并且这种情感很快就化作了绝望。Arcaea的世界根本是个毫无意义的世界。这里只保存了各个世界走向灭亡的画面。这里没有任何物质，只有反射出的影像。哪怕是她有时会在路上搜寻到的关于光明与愉快的回忆，都仅仅是源于过去。就像是白昼过后终是黑夜，它们渐渐地导致了这一刻她眼前的世界末日。她的眼中泪水盈眶。</p><p>自从苏醒之后，她感受到了太多事物。她曾经感受到欢乐。欢乐离她而去。</p><p>她曾经感受到畏惧。畏惧离她而去。</p><p>愤怒离她而去。</p><p>希望离她而去。</p><p>就是悲伤与绝望，如今也离她而去。</p><p>她的眼神转为一片黑暗，而她已经与这些玻璃起了共鸣。围绕于她四周的回忆之壳开始崩裂。她就身处其中，站在那炫目的光芒前方。她已经没有任何情感了。</p>
              </div>
            </details>
<details class="blue" data-header-exclude><summary><i class="fa-solid fa-chevron-right"></i>2-9 </summary>
              <div class='content'>
              <p>宛如受石油污染的海洋，那受诅咒的迷宫记忆，与少女吸引而来的回忆碎片一齐摔落下来，与那些抚慰着她的碎片纠缠在了一起。它们大多都搅成了灰色的糊块，有些则像长钉一样从地面猛地窜起。她像个雕像一样站在原地，缓慢地注视着每一片碎片，仅仅是……在计算它们的数量。就算有些尖利的碎片险些在弹起时刺到她的眼睛，她依然只是继续数了下去。</p><p>终于，她抬起了一根手指，与从她面前飞过的碎片打了个招呼。就在一念之间，那些碎片聚集在一起，化作了一只脆弱的蝴蝶。她命令蝴蝶飞向高空，去反射那纯白的世界。而当它归来并告诉了她自己的所见之物时——就在一念之间——她慢慢地撕裂了蝴蝶的翅膀，并使蝴蝶化作了虚无。接着，她走向了那腐败的海洋，让那些仍在她路径上伫立的，那些所有象征着遗失时刻的梁柱，全数爆发、碎裂。……</p><p>时光逝去，她变了。</p><p>她不再激情地收集回忆。她近乎无意识地走在这世界之中。她知晓了更多关于这个世界与她自己的事——只是不再抱有任何雄心壮志。</p><p>如今，她正在一个破旧坍塌的建筑旁行走着，旋转着她某天在废墟中找到的太阳伞。静悄悄地，一只玻璃组成的生物倒映着痛苦，从天空中向她滑翔过来。这看上去就像是个闪闪发光的粗糙乌鸦，而她认为这只不过是个工具罢了。自塔楼倒塌的那天，她就和混乱满盈的Arcaea融为了一体，甚至已经能够随心所欲地操控它们。它通过自身的方式与她细细低语，诉说着对少女而言遥不可及的苍白世界中的情况。她对那物体怒目而视，使它爆裂开来，化为空气。她也继续行走起来。</p><p>她的乌鸦给她捎来的信息使她愈发厌恶。这个世界就是个空壳子——它们向来只会不断重复这个主旨。她知道，她不会找到其他人。</p><p>但她想要那么做。她需要那么做。但这并不是为了让谁与她分担一下她残酷的命运。</p><p>她想把所有的挫败感都发泄到一个活物上。她想要找到一个人来供她摧残。</p>
              </div>
            </details>
<h2 id="v-相遇">V-相遇</h2>
<details class="purple" data-header-exclude><summary><i class="fa-solid fa-chevron-right"></i>V-1 </summary>
              <div class='content'>
              <p>这座废墟与其他废墟都呈现出相同的景象，但被光芒环抱的少女仍然在路过时注意到它，走进了其中。</p><p>她开始疑惑这些废墟究竟是何物，以及它们为何存在于此——疑惑她一直以来游荡的这个世界是否也存在过往，亦或者这些被严重破坏的风景线只因巧合存在。</p><p>她认为自己必须思考此事，而不是屈服于愚昧的极乐。若她想要得到一个理由，这可能也会帮助她进一步了解这个世界。或许这里……是另一个世界的对立面？</p><p>她曾于Arcaea中目睹过类似的景象，但这也使她质疑这个世界的某处存不存在尚未成为废墟、依然耸立的高塔与建筑。也许她只是还没找寻到它们……</p><p>这座废墟看起来曾经庞大而金碧辉煌。这必然曾是一个美丽的地方，吸引着大量的人前来，她这样想。如此光彩的过去若存在，那真的十分遗憾。</p><p>如今那儿只有她一个人——移动于排排长凳与破损的烛台之中。</p><p>如今那儿只有她一个人——接着她眨了下眼，猛然发现这里实际上还有一个人。</p><p>还有一个人，静静地站在她的左方，那一堵损毁的墙壁前。</p><p>曾经的她，会开心地微笑起来，毫无防备地亲近对方。而现在，她困惑地盯着那被阴影笼罩的女孩，但却未必没有怀着那让她无法抑制地颤抖的欣喜之情。</p><p>回忆的景象之外，于这个世界之中，就在她的眼前——有一名人类。一直以来她都是独自一人，而现在这里出现了另一个人：一个活生生的，有着呼吸的人。</p><p>另一位少女并没有注意到她，只是手握阳伞继续熟睡。她那黑暗的身影显得与这闪闪发亮的世界格格不入。这突兀的景象使她以为自己正处于梦境中，又或者瞧见了另一段苏醒的回忆。</p><p>她张开嘴说话，而另一名少女也恢复意识，睁开了双眼。</p><p>象征着被遗忘的悲伤与邪恶事物的她睁开了双眼，眼前是这早已改变的，一身雪白衣裳的少女。</p><p>让身披光芒的少女感到舒心的那阵阵呼吸声很快就停止了；那背负黑暗的少女眯起眼睛，嘴唇微张，似乎有着疑问。但她最后只是倒吸了一口气，眉头上扬，将伞柄握得更紧了。</p><p>一股难以控制的扭曲狂喜由她心中一涌而出，但凌驾之上的是空前的渴望。这份情感显现于她的面庞，而象征混沌的少女向那象征光明的少女献出了一抹真诚、无法抑制的微笑。</p>
              </div>
            </details>
<details class="purple" data-header-exclude><summary><i class="fa-solid fa-chevron-right"></i>V-2 </summary>
              <div class='content'>
              <p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/arcaea_story_cg/Story_V-1.jpg"
                      
                ></p><p>在这座既没有墙壁，又不存在屋顶，只能靠着仅剩骨架的长椅与白色的蜡烛辨别出场所的教堂之中，身着黑衣的少女伫立于那幸存的老旧大门旁，凝视着片刻前才遇到的另一人。</p><p>一切都很单纯：长久以来，她的情绪都处于低谷，直到自己的面前终于出现了一个货真价实，有血有肉的人。她并没有感到过于激动。她甚至心如止水。于她脸庞上浮现的那抹微笑仅仅是道敷衍却无法制止的谎言。那段谎言对身着白衣的少女打招呼道，"很高兴见到你。"毫无意义。</p><p>少女用干涸的话语声问道："你叫什么名字？"也许在曾经，她也如此意识到自己已经太久没有开口说过话。</p><p>"我的……名字？我……我不清楚，"散发光芒的少女如此回应，"你呢？啊——我是指，记得你自己的……名字……"</p><p>她并没有给予回答。"这件事……"是她走神望向那华丽的墙壁时所说的一切。</p><p>纯白色的少女不禁露出了烦闷的表情。这……成为了一场怪异的相会。尽管黑衣少女并不知晓，但白衣少女与她一样，心中未流淌着任何热情。如同火苗忽然沐浴于寒风，她那不断黯淡的希望正在摇曳闪烁。现在，她变得不太舒服，心中焦虑而警戒。一丝轻薄却无可撼动，且不合时令的气氛穿梭于二人之间。对她而言，发生在这个世界的这场相遇本身便是个单纯的……"错误"。这些总是存在于四周，如今已散布于破碎的地面之上的玻璃，也正体现出了这种违和之感。</p><p>正常情况下，这些碎片会朝她们无法抑制地一拥而上："快乐"涌向白衣少女，而"悲痛"则是朝向黑衣少女。这一刻，每一片碎片都仅仅是停滞于空中。或许有半百片镜面静悄悄地悬浮与少女们的身旁，捕捉着她们四周大约一半的虚无景象。当白衣少女试着呼唤它们时，它们甚至都不会摇晃一下。面前的一切使她感到心神不宁：幸福与恐惧并肩存在，一同闪烁，也皆无动作。唯独那片她能够亲手握紧——那片曾经使她重获自由的碎片——自始至终对她锲而不舍。</p><p>她紧盯着阴霾中的少女。"如果我们两人都在这儿，"她开口道，身体前倾，"那你觉得我们能不能结伴同行？我们……我们也许能互帮互助，说不定还……"</p><p>她止住了话语。另一位少女正凝视着那空旷的，如画布一般的天空，脸上空洞的神色显得毫无感情。她看似并未聆听——但实际上，她已将每一个字刻入了脑海。</p><p>"说不定还……"被黑暗包裹的少女重复道。话语虚弱而又模糊……自从她于苦痛之中再生，她的灵魂便感觉如同一道阴暗而冷酷的深渊。然而，当她听到这个提议时，某种存在于她心中的事物仍然开始闪出微光——无比短暂，且极为微弱。只是，对现在的她而言，就算是如此细小的事情，也足够穿破自她再次苏醒过来便一直尝试扼杀她呼吸的失意面纱。</p><p>而少女残余的过去：那个首先苏醒于这片世界的对立，仍然违抗着这段象征"结局"的未来——抵抗着彻底放弃的想法。她想要得到第二次机会。</p><p>但她并非诚心的答案还不足以激发面前那个女孩的信心。她们的相遇始终被小心翼翼的氛围所笼罩。才恢复感官不久的光早已发现Arcaea的世界远超过了漂亮所能形容的范畴——当然，也远不够被形容为安全。</p><p>尽管如此，两位少女仍会开口交谈，期望局面会向某个更好的方向发展。</p>
              </div>
            </details>
<details class="purple" data-header-exclude><summary><i class="fa-solid fa-chevron-right"></i>V-3 </summary>
              <div class='content'>
              <p>她们的交谈持续着。</p><p>"要是我们能够用名字相互称呼，事情的确会好很多呢，"对立用沙哑的声音说道。她的双目再次开始失去象征生命的光辉。</p><p>另一位少女——光——留意到这一事后，不禁略感不适。"是呢。我并不是很愿意去思考这种事：身在这个遍布回忆的世界的我们，脑海中却没有任何记忆，"她承认道。</p><p>此时此刻，她们正坐在同一张长凳之上，尽管相距甚远。她们来到了这曾为第一排座椅的地方，而前方的几个台阶则连接着一面宽大空旷的平台。白衣少女无精打采地注视着她的新朋友，眼中满是担忧。而黑衣少女则是扫视着面前那宽敞的空间、那片天空，以及那些浮夸而又死气沉沉的建筑结构——但这么做的她，其实似乎对那些事物没抱有任何兴趣。</p><p>正在仰望天空之际，她突发奇想地说起话。"这玻璃……你知道它们叫什么吗？"</p><p>"呃？喔……总之，虽然不太清楚原因，但我知道它们叫作‘Arcaea’。""和我一样，"对立如此回答，当今正朝光的方向看去，"所以，我们两个究竟哪里不同？"</p><p>光露出一抹遗憾的微笑。"我不知道哎，"她如此说道，"除了我们外表上的不同。"</p><p>"那我们试着弄清楚吧。你在这些玻璃中见到的都是什么样的回忆？"</p><p>"基本只有令人愉快的那些。"</p><p>对立叹了口气。"那我们就是截然相反的……"她苦涩地回话道，低头瞧向她的双脚，"那可以假设一下我们是唯二漫游于此的人。如果真是这样，那我们的相反特征可真是非同寻常的要素。"</p><p>"你在Arcaea之中看不到愉快的回忆吗？"光疑问，身子稍微靠向与她交谈的这位伙伴，"嗯，对不起……"</p><p>"……总之，事情就是如此，"另一位少女说道。一时间，她们陷入沉默，直到对立首先打破沉静，"但根据你之前说的话……我猜，你所见的那些快乐的回忆也没有带给你多愉快的经历吧。怎样？我猜得对吗？"</p><p>对这番猜测，光点了点头："我并不是想说自己的经历从苏醒以来便一直那么糟糕，但……你知道吗，曾经我收集了足够多的碎片，以至于它们足以覆盖整片天空。当我那样做了之后时，那片崭新的天空几乎将我杀死……我能感觉到那时天空散发的光芒缓慢地侵蚀了我的心智……说实话，那件事情的确是我自作自受。"</p><p>少女们坚信自己该向对方阐述真相。</p><p>在光讲述完自己沉浸于光芒之中的那场天真烂漫而危险重重的旅程后，对立冷冷地叙述了她于黑暗的龙卷中那几番悲惨的挣扎。她们从某些方面而言，的确截然不同。但两人之间某个必然存在的共同点，此刻已变得十分显著：于一个无意义的世界中渴求着一丝意义。她们所处的世界也许十分美好，但其中的残酷性质却毋庸置疑。</p><p>光已重振决心，但在不久前，她"本身的存在"就逐渐被这古怪而又冷清的地方所威胁。而对立，却保持着伤痕累累的模样：残暴与愤怒充盈的欲望，如同海啸般连绵不断地涌出她的身体。尽管在这场谈话的过程中，她已尽全力试图保持友善的模样，源于胸腔的每一口疾喘却不是轻而易举就能掩饰住的。眼前这个有血有肉的人，对她而言简直是完美的施虐对象。那身着白衣的少女，一定早已注意到这位黑衣少女总是间隙性地用颤栗的双手将伞柄握得更紧。</p><p>这场谈话一点都不轻松——她们彼此都深知这一点。</p><p>但她们将全力进行抗争。</p><p>"我只是觉得我……我真的很希望遇见另一个人，"对立言为心声，"甚至该说……也许是在几天前，这曾是我心中唯一的期盼。只是，自从我踏出了那漆黑的外壳，我便意识到，要自己坚守如此单纯的愿望……真的太艰难了。我只是单纯不知道该怎么振作自己……当我内心未感到空虚的时候，其中涌现的却只有肮脏而扭曲的血液。都是些恶心又残破不堪的事物……"她注视着光，"就算到此刻，我心中仍在思考自己究竟多么想要伤害你。"</p><p>"没关系的……"另一位女孩说道，"如果我有过与你同样的经历，或许真的会感同身受。只是呢，我不认为你对某一件事实的认知是正确的。我不认为你的心就像你说的那样破碎不堪。"</p><p>对立与她四目相对，仿佛在问这怎么可能。</p><p>"看吧——你退缩了哦，"光用心地分析着，"就算在现在也一样。这让我知道，就算经历过那么多的事情，你仍然是个十分善良的人——始终如此。你很坚强……"从座椅上忽然站起的她，脸上挂起一抹微笑，"你比我要坚强太多，"她道，不自觉地抬头瞥了一眼那明澈的天空。</p><p>"我被外界力量所拯救，"她继续说着，又一次与对立视线交汇，"而你却拯救了你自己。"</p><p>闪烁于黑暗少女心中的微光逐渐淡作虚弱的光芒，随之而来的是钻心的疼痛。这明明不是事实，她想到。这一切经历并不是如此简单，她陷入沉思。她失败了，而过去的她早就与那迷宫一同土崩瓦解。自那以后，她便失去了一切情感——就算情感再次于她心中燃起，所谓的情感却仅仅包含着蔑视。甚至在与这女孩相遇之时，她唯一的渴望便是用小刀刺穿这女孩的身体。</p><p>那番话语并不正确，她根本没有拯救自己。只是……也许她的确不是单纯寻找着能供她摧残的对象。也许她只是在等待一个能够给予她最后一线希望的奇迹发生。优柔寡断的光实在无法直接赋予她安慰，但这女孩的存在本身与她那毫无敌意的心灵却始终暗示着一件事：她，可能就是那一道才诞生不久的，最后的光芒。</p><p>让对立内心最为痛苦的，还数那种纯真的自我意识。</p><p>她的身躯瘫软下来。光立刻注意到这一细节，并赶紧凑过去，心中希望自己能帮上忙。只是她的行为仍然是如此犹豫不决——这也注定着她完全无法接触到另一位少女。她仅仅是站在对立跟前，半抬着双臂，而黑衣少女在片刻后便靠自己的力量重新站了起来。光的双臂滑落至腰间，随着她的身体不自觉地后退一步。在二人的四周，玻璃碎片们伴随着她们的动作而摇摆，而其中的某一片却突然散发起与其他碎片略微不同的光晕。它的倒影中，存在着某样熟悉的事物，却不符合任何现实逻辑。</p><p>这显然是从未有人见过的景象：</p><p>一道转瞬即逝的邪念闪光，其中蕴含的却是这整片世界中最为诡秘的反常规记忆。</p>
              </div>
            </details>
<details class="purple" data-header-exclude><summary><i class="fa-solid fa-chevron-right"></i>V-4 </summary>
              <div class='content'>
              <p>她们两人各站一方。对立单手捂住胸口，手指因连续疾喘所带来的煎熬而加倍施力。她重新振作了起来，而这一切都得归功于那位白衣女孩。光赠予了她珍贵的最后一次安慰。这一切并未注定走向结局。在这纯白又刺眼的地狱之中，还存在最后一条能够使她逃离一切梦魇的道路。</p><p>尽管虚弱无力，但在深吁出一口气之际，一抹真诚的微笑仍是显现于她的脸庞。"让我们一起做件有意义的事吧，"她敞开心扉道，"让我们搞清楚这愚蠢而又荒谬的世界究竟是怎么一回事。"</p><p>"这世界也——也没有多愚蠢啦，"光温和地反驳道，略微用力地微笑着。她并不全心全意地喜欢这另一位少女，但至少能确认一件事：虽然表面上看不出来，但这女生绝对不是一个邪恶的人——更是似乎……截然相反。而单单这一个事实，便足以成为与她结伴而行的最佳理由。总而言之，一个"好"人……这种话绝对不会被她用来形容自己。但就在她这样想着的时候，对立的心情变化了。"是什么让你说出那种话的？"不断喘着粗气的她如此问道，尽管问题本身听上去更像是在责备。她的双瞳空洞无光，冰冷的视线直射对面。"你应该比我更了解这种事：这个地方可以在女生因鲁莽使自己被愉悦的事物包围时彻底摧毁这女生的心智。"她站得笔直，边平息着自己的呼吸边宁定着视线，</p><p>她那坚定的信念使得另一位少女失落了片刻，但光却不再是一个对任何事物都漠不关心的女孩。她拾起星点的自信，挺直身子，阐述了她的观点。</p><p>"我们依然活着，"她说，"而如果这世界让我们活下去，那它就绝不是最为糟糕的地方。</p><p>"哈啊……？"另一位少女眼含凌厉，"你错了……如果一个世界允许生命的存在，却只是用无尽的污秽与梦魇去荼毒生灵，那这个世界根本就是不公平的。"</p><p>"好……好吧。也许的确不是那样，可是……"</p><p>"可是？！"对立质问道。</p><p>"但那样的目光也太短浅了！你究竟想要做什么事？"</p><p>"毁灭一切。这世界，这些玻璃……我要毁灭所有东西。我会找出正确的方法。这想法十分合理，不是吗？"她依照事实诉说着，"我想你一定会与这想法产生共鸣。除了被当成一座过于宽敞的监狱，这世界对你而言还能是什么地方？"</p><p>"毁灭这世界……？就算……就算你办得到，这也只会让一切走向终点啊！我们直到目前为止，能确定真实存在的世界也仅此而已！如果我们以某种方式毁灭了它，那我们难道不是会把自己也摧毁吗？难道你会……难道你宁可死在这里？为什么……这种想法简直太过分了！"</p><p>"不，不会有关系的，"对立冷漠地说道。</p><p>并没有预料到这种回答的光立刻沉默了下来。对立的话语太过于骇人，而包含的更是只有悲伤……</p><p>在光沉默之际，对立继续起了她的质问："你有任何别的想法？或者其他计划？"</p><p>"不……我没有。我只是想要和……和你一起找一个办法，"另一位少女这样承认道话语声中流淌着清晰的消沉。</p><p>在方才一番振作后，对立其实就已经认识到了这一点。这使她暂停了质问。要责骂这位新认识的同伴实在是太过容易了。她知道自己的行为举止蛮横无理。理所当然，不久前才搜寻到一线崭新希望的她，更是能十分容易地察觉自己在这之前是多么冷血。只是，在面对另一个人心中的希望时，她却选择去摧毁那希望。说实话，她难道还不够狭隘？在过去，她脑海中类似的信念使她不仅永远无法体会到满足与平静，更是离解决眼前的问题愈来愈远。不，她的任性只会带领她走向一条污秽而黯淡的荆棘之路。心中怀揣这样的思想，她终于扑灭了心中那注定爆燃的烈焰。若她想要牵起这女孩的手……她就必须同时承担这女孩用双手竭力保护着的希望之光。</p><p>"对……对不起，"她完全抛开了自己过激的感情，低下头真挚地道了歉，"我……其实也有一样的想法。我也想与你一起找出一些新办法。"</p><p>早前因对立的话语而被削弱的自信，如今又被光重拾回心中。她对自己的新朋友说："没关系的。毕竟，你的确经历过一段我不了解的时光呢。"</p><p>只不过，燃烧于对立心中的正义之火刚刚才恰到好处。</p><p>最终，那道烈火也只持续了一瞬间，就像是闪烁的火光一般——但却足以惹恼沉眠于那些碎片之中的某一片玻璃。</p><p>它就这样苏醒过来——并且自主性地朝着二人的所在处飘去，不引起她们的一丝注意。</p><p>"不要失去希望，"缠绕光芒的少女说道，"无论多么糟糕的事情，都有好转的那一刻。"</p><p>不断闪烁着渐变的色彩，那片碎片径直闯入两人中间。它同时引起了她们的注意——但它却只向着那位身着一袭黑衣的少女呈现碎片所蕴藏的记忆。</p>
              </div>
            </details>
<details class="purple" data-header-exclude><summary><i class="fa-solid fa-chevron-right"></i>V-5 </summary>
              <div class='content'>
              <p>结局。</p><p>被阴影纠缠的少女，目光穿过那扇破碎的窗户，投射到另一段时光之中。微笑，回到了她的脸上。</p><p>她可真是个无可救药的傻子。 不，不是那白衣少女。 是她自己。</p><p>那片玻璃中的影像并不是回忆。</p><p>当然，这并不现实。 她所看见的是未来——那个她理应期待万分的未来，那个白痴，愚蠢的梦想家。</p><p>那些玻璃毫无偏差地映照出了她自己的身体被一根参差的玻璃长柱一穿而过的影像。那道创伤仿佛要在炙热，苍白的烈焰中将她的衣服与整个身躯撕裂。</p><p>空虚荒芜的Arcaea大地，从她的身前和身后延伸到无边无际的地平线。带着缠绕双肩的那两股刺眼的炙热火焰，抬起手轻抚着长柱的，是那位身披白衣，使她倍感熟悉的少女——尽管在这个角度看不到她的表情。</p><p>她，是此时此刻正站在自己面前的少女。 那名才与她相遇不久的女孩。这绝不是回忆：这景象预言着未来将会发生的一切。</p><p>面对此景，对立退回了自己的立场，并对峙起那段她原先计划彻底无视的真相。</p><p>她已无所谓自己有没有心怀信念。她已不会在这世界中找到任何对她有利的事物。</p><p>最后一丝希望也终被墨染，淹没在绝望之中，最终被彻底遗忘。</p><p>还有什么事会发生？ 她还期望着什么？ 愚蠢。令人厌烦。盲目的愚蠢。</p><p>令人厌烦的努力。 令人厌烦的回忆。 令人厌烦的存在。</p><p>令人厌烦，糟糕得不可理喻——使她作呕。对这一切感到作呕，对她自己感到作呕，对这永无止境的嘲讽游戏中所存在的一切事物感到作呕。</p><p>奇迹？别开玩笑了……</p><p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/arcaea_story_cg/Story_V-5.jpg"
                      
                ></p><p>她早已对自己说过。这个世界是地狱。她是从种种显示这世界已经死透了的事物得知的：在这世界之中，即便天使也终会堕落，而后苏醒为恶魔。</p><p>在光芒中的少女就是这样。在这被诅咒的终末展开中，就算是她心中原先微不足道的小洞也被残暴地刨开，并迅速扩大——荒废，并在刹那间彻底腐朽，只留下一道冰冷的无底深渊。</p><p>正当蕴藏其中的黑暗席卷并吞噬少女，尝试扼杀她的思绪之时，她清晰地看见了光。</p><p>她看见光的视线投向那片碎片——捕捉到她眼中存在的恐慌与那明澈的认知。</p><p>这女孩已经知道了。 而现在，她已无法直视来自对面的视线。一言不发，哪怕一切尽在眼底。</p><p>你此刻感到紧张吗？是否心情不安？毫不掩饰。 不可原谅。</p><p>那股愤怒扭曲成厌恶与憎恨，如同滚滚黑云般显现于她的双眼之中。</p><p>邪恶的背叛者；邪恶，邪恶的地方。 她紧紧抓着她的阳伞，越过碎片注视着伫立于原地的光。</p><p>仿佛冻结在原地——当然，因为她病态的意图已经被识破了。这可真是令人发笑。</p><p>对立的双眼微闭。 她抹除了那女孩尝试在她心中种下的一切情感之芽。</p><p>结局到来的那一刻，她的心智终于被掏空了。而这一刻起，她终于弄清自己应该做些什么。</p><p>只是，这是面单向的镜子——其中蕴藏的厌恶与冷淡也是相同。光对这片不同寻常的碎片之中所蕴含的内容完全无从知晓。</p><p>当对立的脸上失去越来越多的血色，丝毫未意识到情势的走向——光仅能在困惑中观察着一切。</p><p>一股突如其来的危机感扩散至身体的每一个角落。尽管她并不理解原由，她却能感受到危机就在眼前。事实上，匍匐于大地的暗影如今已翻腾而起，毁灭着它所接触的一切光芒。</p><p>黑暗向着她逼近，而她的呼吸变得愈发急促。她不禁朝着后方退了一步。她几乎无法相信眼前正在发生的事情。她根本不想去相信。</p><p>即使她已于那片耀眼的天空所带来的痛苦折磨中幸存下来，某种可怕的事物再次毫无理由地显现于她的面前。</p><p>尽管，她仍旧存活了下来。而她终究意识到，生存并不是件能够妥协的事情。</p><p>心中怀着这样的想法，光犯下了一个天大的错误。</p><p>她伸手去拿了那片玻璃——那片在她彻底迷失于低谷时，给予她慰藉与方向的玻璃。</p><p>就在她将它提至胸前时， 对立头颈后方的头发也飞扬起来。</p><p>恐惧猛烈地冲击着她的全身。伴随着那永远不愿再次遭遇不幸的决意，<b>那一刹那，对立在没有任何预警的情况下靠近了光，准备彻底夺走她的性命。</b></p>
              </div>
            </details>
<h2 id="vs-纷争">VS-纷争</h2>
<details class="black" data-header-exclude><summary><i class="fa-solid fa-chevron-right"></i>VS-1 </summary>
              <div class='content'>
              <p>光。 对立。</p><p>假设她们知晓对方的名字，甚至仅仅是清楚自己本人的姓名——若真如此，二人自始至今的感受也会发生改变吗？"光"与"对立"……存在于这片光怪陆离的世界之中，此般崇高的称呼……若真如此，她们是否又会静下心来思考蕴藏于自己姓名的深层含义——也会走上截然不同的道路吗？</p><p>抑或者无论发生何种分歧、矛盾，无论曾经做出哪些抉择，在何时得到幸运的眷顾——随之产生偏移的世界线，却终将收束至二人此刻的水火不容？</p><p>光并不会知晓确切的答案。她直至如今都不知道自己的名字。而在这相同的前提下，对立却命中注定被自己的知识所诅咒。她心中早已清楚，二人间的这场针锋相对，无论如何都会来临。</p><p>不可能会产生任何改变。原本一切就不会发生改变。白衣少女与黑衣少女，绝不可能和睦相处。</p><p>这一切必然因果，最终只会导致——</p><p>"呃啊！"</p><p>当面前那位宿敌将刀刃划向她时，光随之发出一声惊叫。她立刻举起手，而玻璃碎片也随之互相冲击。碎片悬停于空中，闪闪发亮——丝毫没有受到损伤。而透过自身碎片所倒映的景象，光终于窥见了自己那张因恐慌与痛苦而变得煞白的脸庞。</p><p>一次流露真情实意的交流——却造成了这场令人心碎的冲突。</p><p>对面那女孩的力量实在是太强了——光被冲击得缩起身子，反射般地朝后一退。她的皮肤此刻已经冰凉。 她这才察觉到自己近乎无法呼吸。</p><p>少女充满敌意的视线已经无限接近自己。望向那杀意的瞳孔，光意识到那股近乎将自己心脏撕裂的恐惧并不来源于那女孩的袭击。根本不是那样……并不是因为对立的刀刃已经逼迫得越来越近，转眼便要切入自己绷紧的喉咙，而自己却几乎无法做出任何反抗。根本不是那样。</p><p>光的汗水从掌心溢出，滞留于自己胸腔中的空气完全无法逃逸——自己会感到恐惧——完全是因为面前这个不久之前还令自己感到怜惜的不幸之人，此刻却截然变脸，彻底蜕变为另一番模样。</p><p>那女孩早已不是能够与她平心静气交谈的伙伴。现在的她根本不能被称为人类。她的目光是如此决然无情，就连下颚都纹丝不动。她那拼尽全力攥紧的手指，早已染上一整片鲜红。</p><p>她仅仅是一头由漆黑包裹的凶残野兽……一道由恶意堕化而成的黑影。</p>
              </div>
            </details>
<details class="black" data-header-exclude><summary><i class="fa-solid fa-chevron-right"></i>VS-2 </summary>
              <div class='content'>
              <p>让这一切和平终结。 找寻能够妥协的台阶。不能变得软弱。不能变得畏缩不前。</p><p>光稳稳地抓住了这丝信念。她反击了。</p><p>她们早已自无数的回忆中目睹并体会过战争所会带来的痛苦。只可惜，那些无关二人性命的记忆，归根究底无法与此刻这场货真价实的战斗相提并论。</p><p>二人临场打造的刀刃，冷酷无情地相互撞击。对立的攻击只得形容为果决而精准，其中是满溢的恶毒。而光的一系列行动只是透露着一种绝望的韵味。哪怕步伐只是遭受毫厘的闪失，对方的致命攻击便足以夺走自己的性命。而她却仅仅是在防卫自身；她没有做出任何多余的举动。若是能够不施展蛮力解决这一切，她早会刻不容缓地完成使命。</p><p>悬挂于空中的吊灯与数排长椅——这座教堂遗址之中散乱的标志性物体，成为了二人混战时的阻碍。而她们则行动于这条走道之上。对立朝着光的脚部疾冲而去。尽管如此，光却没有躲闪，却是举起那片曾给予她救赎的碎片，随时准备招架即将到来的上斩。只是斩击并未如期而至——晃眼间，闪现在眼前的竟是那把漆黑的阳伞：随着刺耳的破空声，残忍地捅向她的防线。</p><p>"唔嗝、呃啊……！"痛到喘不过气。整只手仿佛烈火灼烧般疼痛。小拇指——她坚信自己的小拇指一定是被折弯了。异象残片瞬间便滑落出脱力的手掌。意识到自己变得手无寸铁，疼痛折磨下的她迅疾地选择朝后方闪避。</p><p>就连光自己都吃了一惊——自己居然能如此平稳地脚跟落地。并未迟疑，趁此再次朝后方跃去，裙摆随着移动轨迹飞舞空中，这才察觉自己在千钧一发之际躲开了对面的另一招。几乎是贴着自己站立的长椅挥过，命悬一线。这一场纷争，真的无法仅靠语言平息吗？</p><p>即使心中这种想法切合实际——此时的她也找不出半个合适的词语。纵然她已经清楚该说些什么——届时的她也根本没有任何的发言权。纵使她在此刻受到神明眷顾，获得了这两项理想的先前条件：既与对手保持了足够的距离，又拥有充足的时间去准备发言——</p><p>一把崭新利刃，不知是从何处射来——</p><p>迅速地抵达了她的脸颊——</p><p>就这样，将她的脸部割伤。</p>
              </div>
            </details>
<details class="black" data-header-exclude><summary><i class="fa-solid fa-chevron-right"></i>VS-3 </summary>
              <div class='content'>
              <p>光的呼吸节奏被再次打断。她下意识地飞速将手搭在了左脸前方。移开手心，却只瞧见那抹沾染手指，玷污掌心的色彩。很不幸——她已经对种颜色十分熟悉。又一次……如同彼时那般，浑身冰冷。</p><p>朝后方摔落而去的间隙，她紧紧地环抱住自己，试图硬生生地止住双臂剧烈的颤抖。她咽下了嘴中聚积的唾液。</p><p>再接着，用那几近失去音量的话语声，哀求道： "住手……"</p><p>尔后，仅是稍微响亮了些许： "请住手……"</p><p>又一片尖锐无比的碎玻璃好似离弦之箭一般急射而来。光随之躲闪——尽管留给自己的反应时间并不超过一秒。碎片眼看就要成功刺入她的上臂。幸好最终只是擦臂而过。</p><p>她终归大喊道："请住手！！" "我知道你的计划。"</p><p>光的动作戛然而止。片刻间，对立便着陆在距离光有足足五排远的长椅之上。</p><p>"你究竟是什么？这世界创造出来的恶魔？"对立质问道。</p><p>"什么？！"</p><p>"你根本只是那些碎片的同类。是从荒芜之地而来，专程前来猎杀我的吧？"</p><p>"我……不是！"光吼道。</p><p>"你自己也不清楚自己到底是什么……"对立喃喃自语道。</p><p>就在此时，光忽然注意到——那女孩的身前身后，已经如蜂群般聚集了相当数量的Arcaea。光对此格外留了心眼。届时，对立仍旧用那沉痛的话语继续低语着。"但……既然能够找上我。"她道，"那你也一定不是什么好东西。"</p><p>光回想起了面前那女孩曾述说的那段过往经历。她石化在了原地。她明白对立是什么意思。</p><p>"我才不是……那种……"她嘟哝道，语气中略带着防卫性。又一枚碎玻璃，如同出膛子弹般掠过她的耳旁。</p><p>她紧紧闭起了自己的双眼，任由眼泪被压迫得夺眶而出。</p><p>如果她的愿望是活下来……</p><p>……那无论如何，她都不能在这一刻放弃。</p><p>光的视线转向下方。一枚新的碎片响应着她的召唤，来到她手心之中。自己居然已经能够徒手接触到碎片——对于这种过于诡异的现象，她甚至未曾留意。</p><p>整一队列的碎片也跃动着加入了自己的身后。</p><p>她抬起了头。</p><p>正是如此——尽管渴望成为挚友，却又一次对峙起面前那位女孩。</p>
              </div>
            </details>
<details class="black" data-header-exclude><summary><i class="fa-solid fa-chevron-right"></i>VS-4 </summary>
              <div class='content'>
              <p>争执中的两人，不费吹灰之力地撞碎了钢制的大门，好似那仅仅是块木板。此刻的黑衣少女朝着白衣少女猛冲而去。那些记忆的碎片则好似一片混沌般飞舞缠绕着二人。</p><p>反抗——却从不主动攻击。尽管她已经诚心诚意地决定接受战斗，光的心中却始终存有一丝希望：这根本没有必要成为一场见血的纷争。虽然如此，就算她操控这些玻璃的技巧尚未娴熟；就算她没有分毫的战斗经验——她也绝不会让步。</p><p>玻璃仓促地在她身后拼凑成一面护盾，不断地精确阻截着对立所施放的长枪的迂回背刺。光此时的视线，远比玻璃碎片更加锐利。她保持机警地试图压制面前的暗之少女——并争取让这场战斗和平终结。通过武力。</p><p>遗憾的是，知之非难，行之不易。脱离了大教堂的空间限制后，此刻Arcaea的畸形山路对于对立而言只是更加方便她施展的空间。她的举止彻底不再被障碍物所拘束，碎片的斩击范围也随即进一步扩宽。最终，光发觉自己真正能做的也仅有全力守住最后的防线，保全自己的性命。</p><p>心跳过快。先前仅会从手心流出的汗液，如今早已渗透她的全身，造成一股恶寒。好似用隐形的小刀弹飞掷来的透明匕首，在自己的喉咙与对方的长矛亲密接触前，率先将一道碎片飞速射去。</p><p>一招对应一招，应对另一招，对应再一招。这使光认识到，战斗早已从混乱的暴力扭打升级至两方绝对势力的凶恶冲突。若是单纯较量蛮力的话，光毫无胜算。只是，支撑着她的还有智谋与信念。这足以让光勉强招架对立的攻击。</p><p>直面身前那洪水般决堤的情感源泉，光将担任那“对立”之侧。岩石或许会风化，但却不会碎裂。她会平息这一切争端。</p><p>她们此刻是平手状态。两方所各自钦定的Arcaea，此刻正由那光滑的表面散射出光球与剧烈的光线。</p><p>确实，她们始终不相上下……直到对立改变了目标。表面上正企图冲破对方防线，对立却悄无声息地将自己的碎片群重定向一番，送至了光的身体右侧。</p><p>这一举动造成的影响不可估量。在魔光闪烁般的爆炸中，光的单侧膝盖失去了平衡。紧随其后，对立阴险狡诈的目光随着手中的阳伞一同朝前方刺去。阳伞的尖端正指向那原本的目标部位：她对手的前额。</p><p>完全没有一丝踌躇。电光火石间的瞬息一刺。</p><p>光死死地闭上了双眼。对立皱紧了眉头。</p><p>冲击被中途制止了。并不是由于她们的任何一者。这第三股力量源自她们二人之间。</p><p>她们二人之间——是那片原先被逼出光的手掌心的异象碎片。尽管面对阳伞的全力突刺，也悬停于空中纹丝不动。光睁开双眼，难以置信地凝视着。</p><p>"唉！？"</p><p>"这是……"</p><p>对立举起了另一只手，顺势带起一片玻璃碎片的漩涡。</p><p>然而，光却同样未带迟疑，将手掌推向身前的异象碎片。紧接着，两人身旁的每一片自由碎片都猛烈摇晃了一瞬——由利刃组成的风雨接踵而至。</p>
              </div>
            </details>
<details class="black" data-header-exclude><summary><i class="fa-solid fa-chevron-right"></i>VS-5 </summary>
              <div class='content'>
              <p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/arcaea_story_cg/Story_V-10_cg.jpg"
                      
                ></p><p>序幕之刻，好似一场暴风。</p><p>如今这成百上千的坠落碎片均受到光的操控，却看似只是在毫无秩序地四下乱窜。尽管此刻已轮到光发号施令，她却显然还没有驾轻就熟。</p><p>对立的脸上明摆着忧愤。她暂时朝后撤退起来。此时的光，身形已经湮没于星罗棋布的锐利“记忆”之中。她正屏气凝神地蜷缩膝盖，试图集中施展自己这股全新全异的力量。</p><p>对立迅速勘测了周身地表的情形，仰头紧盯着高空中由光制造的暴风。她将一只手掌高举过头，心中思绪涌动。——若要战胜暴风，则需呼唤疾雨。</p><p>潜匿于地平线彼端的城市废墟与纯白山脉的玻璃碎片——数凌千计的玻璃碎片，皆数响应着对立的号召，降临了此处。相对于光手下桀骜不驯的群魔乱舞，对立的军队远远显得要更加井然有序，队列更是完美无瑕。</p><p>盘踞于纯黑之少女背后的碎片，纹理俨然是一朵巨大的玫瑰。宛若旋流般，玫瑰的花瓣被一片片地剥落而下，精确而迅速地切入那层层保卫着纯白之少女的飓风。光因而只能挺直身躯——尽管她的心中满溢着恐惧。她被迫以包含规律的弹幕加以回击。</p><p>弧光残影，千华缭乱。相距甚远的两人卷起这场雨横风狂的宿命之争。若是由数里之外加以眺望，此般景象正如对立所盼，好像两场风暴彼此间的激烈冲撞。风雨相争，创造电闪雷鸣，周身汹涌起伏的黯云有如一场华丽的爆炸般，于这场战斗中螺旋相缠。如同凶猛乖戾的自然力量，致使风云大乱。</p><p>在这银白渲染的波涛之下，两名女孩相互对峙。燃烧于她们心中的是熊熊炽焰。</p><p>凌空齐射的碎片也无法伤及对方分毫；二人在迅速躲闪攻击的同时也并未驻守原地，而是开始疾跑——疾跑于Arcaea的荒原之上，穿梭在玻璃汇聚而成的枪林弹雨之中，不时回避着因爆裂而产生的高速弹片。 碎玻璃对二人穷追不舍。碎玻璃将二人阻截于半路。碎玻璃不断尝试着刺入二人的双脚，这是二人试图将对方牢牢固死在原地。</p><p>狂怒：彻底失控的狂怒，混乱而又不失守序。二人的步伐、一举一动……逐渐变得近乎同步。规律而刻板地重复着规律而刻板的动作。</p><p>闪避。 开火。 重复。</p><p>在这无法言传，压倒性的绚彩狂华之中，二人再度势均力敌。</p><p>继此之后，战斗轮到对立占据上风。</p>
              </div>
            </details>
<details class="black" data-header-exclude><summary><i class="fa-solid fa-chevron-right"></i>VS-6 </summary>
              <div class='content'>
              <p>她在此处的旅途，无异于身临地狱。</p><p>自诞生以来便已然踏入地狱中心——或者说，自己也许根本就没得到过踏出第一步的机会吧？苏醒而来的她冒险踏入了外部的世界，但随之邂逅的苦痛与厄运好似暗潮般唐突地毁掉了她的旅途。之后，那两个灾祸的象征便紧紧地跟随着她。 简直是在开玩笑。</p><p>我可是个好女孩。她于心中自言自语。</p><p>这身漆黑的衣裙本就不该代表我的存在。这些黑暗的回忆始终折磨着我，可我又不是它们的同类。</p><p>我根本不是个“邪恶”之人。我只是个普通人，一个生于只存在邪恶的世界，因而饱受折磨的普通人。</p><p>荒谬无理。简直构成不了任何逻辑。一个残忍得可怕，从根本角度上而言的无情世界。一场永远无法苏醒的噩梦。</p><p>而属于我的结局，便是一场悲惨的死亡。</p><p>……</p><p>那样的事实，那样的想法，让泪水无数次在她的眼眶满溢。</p><p>现在，这一切已经结束了。不管是什么事，已经结束了。</p><p>将这一思绪怀藏于心之际，面前那名自己想要杀害的少女正将另一块玻璃送向自己。而就是在与那片玻璃擦肩而过时，她却忽然注意到了什么异常的画面。</p><p>正是数分钟前那种熟悉的，怪诞到让自己反胃的感觉。好比“现实”本身失去了正确性。仿佛绝对不可能发生的场景在眼前出现。</p><p>而那特异感知的源头，几乎紧贴着自己的脸颊。</p><p>她朝着右方看去。一枚由淡紫色点缀的，外形极度歪曲的异象碎片，映入眼帘。单单是眨眼之间的相会。</p><p>却足以回答一切。</p><p>如同她所预料的一般，这枚异常的碎片所包含的并不是普通的回忆——但完全超乎预料，碎片中出现了本绝不可能存在的答案。</p><p>转瞬之间，快到仅仅是碎片表面的反光与视网膜相撞——</p><p>——感受到自己的颅内就像被光芒所充溢般，一眨眼的功夫便近乎通晓了有关这世界的一切：所有曾经几时存在——且必定存在的事物。一眨眼的功夫，她的脑海中便已然开朗。</p><p>她们的名字。 她们的过去。 这个世界。 ——存在的目的。</p><p>她：“光”。</p><p>她：“对立”。</p><p>“爱托”与“红”……“咲弥”与“忘却”……</p><p>“露娜”，以及……名字；无法计数的名字。</p><p>甚至是关乎其他世界的真相，属于其他旅行者的终点，结局、序言、完美详尽的因果：一切的一切。</p><p>以及真理。全部的事物所指向的真理，便是——</p><p>她的身前，光短暂地止住了步伐。她察觉到了面前那名对手态度的明显转变。的确有什么变化产生。 恐惧。</p><p>所以，真理就是如此。我已知晓真理。</p><p>对立早已目睹“现实”被禁锢的真理。而只需明白这一真理，她便会拥有力量。但若两者兼具，通晓万事……通晓万事，又有什么用？</p><p>本已凝固的思绪，如同被再次强行乱搅一番。那股盘踞于她胸腔内的无尽苦涩逐渐一路蔓延而上，沾染了自己的舌根，钻入牙缝之中。她的嘴唇扭曲得好似一抹忧郁而感性的微笑。忧郁而感性，却毫无疑问地，怪诞地——快乐。</p><p>狂笑吧，少女。呼唤狂风暴雨吧。</p><p>此处的道路尽收人类所能拥有的最恶回忆。而存在于终点的——始终都——只会是终点。</p><p><b>抵达终站的同时，她们两者之间的一人，必须死。</b></p>
              </div>
            </details>
<details class="black" data-header-exclude><summary><i class="fa-solid fa-chevron-right"></i>VS-7 </summary>
              <div class='content'>
              <p>“战斗势均力敌”——这样的美梦破灭了。与此一同瓦解的，还有光那终于开始动摇的希望。</p><p>原本由光指引的风暴，毫无任何先兆地朝着对立的侧面刮去。阴影与光芒交错，层叠掩埋起那女孩的身姿。就此碎片缠绕身体之际，她的双眼忽地紧紧闭上——而就在片刻后，当双目再次睁开之际，那无数错杂的回忆，在她的背后形成了六只巨大的羽翼。</p><p>届时，她浑身散发着对整个自然界的公然蔑视，浮于上空，将尖锐的视线刺入光的瞳孔。</p><p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/arcaea_story_cg/Story_VS-7.jpg"
                      
                ></p><p>单单一个眼神便足以让光心知肚明，她基本已经失去了所有胜算。光曾经错以为面前那女孩是一头野兽；此刻，自己终于认清了那女孩的身份：高高在上，绝对无法触及的存在。</p><p>玻璃碎片在对立的背后升起，这场面好似一张巨型的帘幕：一扇清晰的，宏光闪烁的天窗。</p><p>位于下方的光，几乎没有任何东西可以用来抗衡即将到来的一切。至少，这就是她的第一感觉。但是……不……那纯黑的少女还未拥有一切。她可以在这里活下来。必定可以！那扇通往天国的窗户碎裂之际，光从中取下了二十枚记忆。</p><p>最初，只有寥寥几枚碎片朝着她飞驰而去。可是，它们却显得极为……迂缓。这让她卸下了重担。她开始在心中默念：“可能性必然存在。”就好像顷刻前目睹的那一幕仅仅是这种事情：一场表演。</p><p>如同彼时一样，光将自己稳固地防御起来，潜心贯注地抵挡着坠落而下的碎玻璃。她的目光不断左右横扫，时不时地确认着那群光芒万丈的碎片正处于什么方位。这让她拾回了充足的信心——她没有遗失任何事物。她默许一丝笑容出现在自己的脸上。</p><p>就算迎来最坏的局势，至少她可以从这里顺利逃走。至少这并不会是属于自己的终点。</p><p>于是，一片玻璃飞向了自己的胸口正中央。它的到来，只能被理解为试图向自己传递一则信息。它的飞行速度，比她曾见到的任何Arcaea都要快上数倍。正位于上方的另一名女孩，通过这片玻璃碎片，向她说道：“玩够了。”</p><p>“也不要浪费我的时间了。早点投降——然后死。”</p><p>那枚玻璃碎片从她的裙边穿透而过。而光，则望向了对立的双眼。那身着黑衣的女孩，此刻正微微笑着。她的脸上，再也见不到一丝忧愤的阴云。但那却是她毕生的记忆中，最恐怖的事物。</p><p>那一枚碎片并未接触到光的身体，而是摔落在地面上。</p><p>毁坏的天窗开始旋转起来，逐渐形成一柱倾斜的龙卷。它的血盆大口正准备将她的身体吞噬，割裂了布料与皮肤，但只做到这一步为止，便飞离她的肉体。这场面，显然阐释着另一则信息：在迎来结局之前，那纯黑的少女想要自己的敌人清楚一切从何而始。</p><p>恐惧席卷了她的每个细胞。玻璃组成的激流，以庞大的数量呼啸、切割着她的身体，就像被劲风牵扯般转动着身躯。她陷入了极度害怕的状态。好似一尊石像，她只是呆呆地站在原地，注视着一切。</p><p>她伫立在原地，注视着属于一个污秽世界的回忆。</p><p>刻画着痛苦、背叛、嫉妒的回忆。</p><p>殒命、暴虐、凋零。</p><p>黑暗。只是纯粹的黑暗。不论这些碎片究竟反射了何处的风景……她从中都近乎见不到一丝光芒。不论是多么渺小的火花，都会在转瞬间消逝。那女孩，也曾将这一画面这样描述给自己。</p><p>从苏醒以来，便一直蹂躏着她。那些污秽至极的倒影——此刻，她将用相同的事物去蹂躏另一个人。</p><p>玻璃碎片将光的衣袖从里侧勾起，刺入她的长裙。它们将她拉至上方——直到自己再也无法倚靠双足站立。</p><p>就像泪水已经盈眶般，那一股情感也满溢着自己的内心：在人们意识到自己即将死去时，便会来临的情感。这并不是畏惧。 “恐怖”这种词，毫无用以形容的权利。</p><p>心灰意冷？满怀希望？ 那种令她感到恐惧的，将自己拘束的感觉。</p><p>届时涌入她脑中的，是属于她本人的回忆。就好像她在试图寻找其中的某一段；一段显得出众的回忆——一段能够告知她，自己曾在过去遭遇过类似的噩运，并且成功将其克服——如此的回忆。从中，她能学到该怎样逃走。</p><p>并不存在。</p><p>黑色的风暴狂吼着侵袭着自己的躯体——不带一丝怜悯地切割着她。残虐，如此单纯的意图。不断地接近、接近……好似这意愿本身，就足以在她身上留下致命伤痕。</p><p>不可置信。</p><p>这样的场面，早已超脱了她从诞生至今所亲眼见证的任何事物；自己亲身经历的，抑或是属于其他人的。混杂着这种令人厌恶的，面对未知事物时才会出现的感觉，但又对静候着自己的事物心知肚明……</p><p>惊骇。 并不是畏惧。 这般惊骇的领悟。</p><p>这里不存在任何受她指挥的玻璃碎片。随便什么，不管什么都好——异象——奇迹。随便哪件事情发生了，都会是她的救命稻草。她就能趁机逃逸。她就能活下去。</p><p>若这般展开必然发生；此刻、此处，便是最佳时机。</p><p>下方的大地开始崩裂，看着就像世界本身也想要加入这场猎杀。 正是此刻。此刻！会有一枚碎片前来拯救她！</p><p>她真诚地祈祷着——全心全意地祷告，祈求世界的意愿，为帮助她而站到自己的身旁！</p><p>命运女神也好，幸运之轮也罢，无论是谁——纵然是捏造出一位“神明”，赐予她足以创造胜利的力量！</p><p>哀求着。期望着。紧紧握住那片曾经将你救赎的存在，再度贴在你那染血的胸前。拯救的象征。象征着灵魂的赎身……它将必然——！</p><p>又一片碎片穿透了她的身体，将那憎恶的火桩捅入了她的心脏。尽管它并未直接伤及她的心脏。但它所怀揣的讯息——那终末的讯息——已经做到了。从那残虐着她的女孩那里传来的，临终的讯息：简略，冷血。</p><p>“不。”</p><p>那闯入光的心脏，几乎将她置于死地的利刃，届时只向她呈现出这般回忆——熊熊燃烧，吞噬一切的烈火。</p><p>触手可及的死亡。她的心脏猛地悸动了一下，让她意识到自己仍然活着。</p><p>她的瞳孔缩小，如同墨点。</p><p>就像那映射烈火的记忆一般，她的身体仿佛被火焰灼烧。伴随着流淌于空气中的邪恶高温，灼烧着。 疼痛。痛苦。鲜血——</p><p>尝试将手伸向那可怕的伤口时，手中的救赎碎片也摔落下去。</p><p>接着，一枚锯齿状的碎片，从暴风雨中席卷过来，刺中了她的手背。</p><p>已经发不出任何声音了。</p><p>身体也被刺中了两次。如今，她就连呼吸也做不到了。</p><p>她的视线凝固于面前由不可思议的画面所组成的三重奏。</p><p>此般现实。如此地骇人而难以想象，但确实“如此”。</p><p>她的思维，也逐渐开始消逝。</p>
              </div>
            </details>
<details class="black" data-header-exclude><summary><i class="fa-solid fa-chevron-right"></i>VS-8 </summary>
              <div class='content'>
              <p>而此刻，就在彻底失去思考能力后，光的求生本能终于开始运作——那种古老，曾被遗忘的本能反应。</p><p>只是那些客观实用的求生本能，却被光悉数抛弃。它们最后也只是“开始运作”罢了。她依然感到恐惧。 几乎是只用一根小拇指，却仍牢牢扣住的希望。</p><p>几乎是莫名其妙地，她居然成功将十枚回忆召唤至自己身旁，把那些将她身体固定于半空中的细针状玻璃皆数撞开。</p><p>以如此不光彩的方式，摔落到扭曲崩裂的地面上，随后，她所选中的碎片们，围着她伤痕累累的身体绕起圈来。足够奇怪的是，她发现今朝的自己也同样微笑着。</p><p>她借助左臂将身子撑了起来。从对立的攻击中透露的敌意清晰可辨，可她过于享受摧残自己敌人的肉体， 以至于迟迟未下任何杀手。</p><p>哪怕是在此刻存留于光胸腔中的碎片，是那么靠近她那跳动的心脏，让她经受了那么耀眼，骇人，愤怒的烈焰——哪怕已经做到这一步，却仍未致命。</p><p>或许这并不是对立的初衷。 但不管怎么回事，光清楚自己仍然活着。</p><p>她虚弱地送出了一波攻势，却被上方正翱翔于空的那位女孩轻而易举地扑灭。光所听闻的古老回忆中，完全不存在像那女孩一般可怕的恶魔。</p><p>她是名副其实的女王，在这白昼的世界中统治着黑夜。那丝展露着狂喜的微笑，却空虚得毋庸置疑……</p><p>望见这幅景象后，光也终于能体会到相同的事物：自己心中的所有情感，是如何迈向毁灭的。</p><p>鲜明的现实只会让她变得愈发清醒，而不是使她更加畏缩，譬如她在几分钟前的心理状态——不，几秒前。她开始认知起当今形势中存在的每一件事实。</p><p>缓慢地——或者说，是在条件允许的情况下，尽可能缓慢地认知着事态。对立的攻势，在此期间从未停歇。</p><p>将身体左右挪移，用仅剩的回忆去保护自己肉体最脆弱的部位。同时，光观察着二人如今的战场。</p><p>面前的景象是如此残败不堪。现在的这里，比从前的任何时间都更像一片“荒原”。被撕裂的地面，处处都只留下残亘断瓦。这里简直是一座被严重轰炸过的城镇。环绕着她们二人的玻璃根本无法计数。对立所拥有的力量更是不可估量。</p><p>光的自身，太弱小了。并不只是指代自己控制玻璃碎片的能力——衣衫褴褛的她，浑身本就受满了伤。她早就没剩下多少耐力——光是疲劳便足以战胜她仅剩的神智。</p><p>也许她仍可能找到一场异象，但此刻只可假设她做不到。所以在这之后，她又得去寻找什么？她做不到。既然她做不到，那就不存在任何假设的必要。</p><p>于是？ 前进的道路都彻底毁了，你还怎么向前走？再者，你甚至……该向前走吗？</p><p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/arcaea_story_cg/Story_arcahv2_cg.jpg"
                      
                ></p><p>玻璃闪耀着光芒，冲击着她的双肩。 光凝视着玻璃反射的画面。所以，那个女孩现在和她一样，也能控制光芒了。那好……</p><p>她再度企图重新思考自己所观测到的一切。她明白自己可能会死在这里，但也可能不会。留给她的只有这两个可能性。知晓这一事实后，她发现自己逐渐认同了自己的命运。</p><p>这里确实可以是她生命的终点。</p><p>只需刹那间的功夫，这一切就都能落幕。而每当她祈求这不要变成事实的时候，她却做不了任何事。她只能重复这样的想法：“别无他路可走。”</p><p>在丢失了思维、希望与感官之后…… 意志是最后离开她的事物。</p><p>还没有。</p><p>还没有……</p><p>还没有……到屈服的时候。 不要……</p><p>当她将先前刺入手中的碎片狠狠拔出后，燃起的纯白火舌瞬间便吞噬了她的伤口，不禁使她一阵眼花目眩。她并未将手按压在自己的脖子上。</p><p>她显然会宁可活下去……但她并不会介意。她不会介意，毕竟奇迹发生的可能性是那么渺小。</p><p>光直立于刀刃的狂风之中。听从她指挥的碎片，近乎不存在。她已经无法再辨认出对立的脸。她所身处的区域已经骚动不堪。若想让视线穿透这些碎片，实在是过于艰难。</p><p>最终，就在试图缓慢穿过飞舞的玻璃时，她留意到风暴的某些部分正在整齐地逆旋。这样不自然的怪异现象，让她自心底怀疑这是不是上面那女孩的有意之举。</p><p>就像是正在跳帧的视频，她如此联想。尽管与自己曾遭遇的弹幕相比，这种现象并没有好坏上的区别。但它的确显得过于古怪了。</p><p>地面猛烈震荡起来。</p><p>感觉到这一迹象之时，她脱口而出一句“什……” 地面在……震动？就在这儿？</p><p>很有可能是地表将要再一次开裂。这个念头浮现的瞬间，光便用手掌挡住脸庞，顺势用手臂护住了胸前。但之后并没有任何事情发生，而她仍旧对这突发现象保持着十足的好奇心。</p><p>如果这不是上面那女孩的所作所为，那她也自然不会察觉到这件事——毕竟，现在的她仍在天上飞。</p><p>现在的这片刀刃风暴之中，只存在更多的碎片正以那粗糙死板的路径呼啸翻腾。她决定再将一队碎片掷入另外那名女孩的路径上。那些碎片——它们轻而易举地穿透了风暴的波浪，但却忽然发出诡异的强光，接着便崩坏消逝。</p><p>碎片本身并没有损毁……它们只是凭空消失，在原处留下了好似裂痕的空间。而就在她目睹这一迹象后——就在她意识到自己看到了什么东西的那一瞬间——所有的事物都陷入了静止状态。</p><p>在这顷刻间，那些本围绕着她盘旋的黑曜石玻璃也被牢牢牵制于原地。对她而言，这幅画面是那么美不胜收。</p><p>一抹截然不受自己意愿所控的微笑，令她的嘴角微微上扬。“多么令人愉快啊。”她这样低语道，咯咯地笑着。这里存在着某种极为美丽的事物：哪怕这里很快便会立起自己的坟墓。这真是奇异到令人……发笑。她的确笑出了声。她发出了如此真心诚意，却这般悲伤，这般干枯的笑声……</p><p>只是，就在周遭的场景逐渐回归正常，流动的时间也终于回到位于上方的那名女……位于……上方…… ……天空？</p><p>一道裂痕瞬间出现于天空之上。那裂缝急剧扩宽，逐渐刻画出宛若天堂般的轮廓。紧接着，那巨大的断层开始下坠。更令人感到离奇的是，数百张画面正在它的表面上流窜，接连扑闪着光辉。</p><p>整个世界都渐渐开始堕落为一片古怪的残骸。光在将这一幕尽收眼底之际，脸上的微笑也变得更加满足。暴风雨仍转动得极为缓慢。这幅画面——真的太梦幻了。</p><p>那片天空——那片货真价实的天空，绝非人造物体——正在坠落。忽然完全停止，接着再度坠落，好似一幅天文拼图的碎片正被某位醉酒的神明肆意移动着。</p><p>并且…… 注视着这幅景象…… 她的微笑开始逐渐逝去。</p><p>她的眼神变得冰冷，呼吸也逐渐变慢，因这种灾难性的画面而点亮的微弱激情，也终于熄灭——被客观思绪所完全替代。对于这场即将毁灭万物的灾难，她只传达出了单单一个词语。</p><p>语气中带着一丝微弱的赞扬，更多的却是空洞。她说道： “太美妙了”就好像这个词语存在任何意义。就好像那场崩塌存在任何意义。</p><p>就好像这世界存在任何意义。</p>
              </div>
            </details>
<h2 id="f-终焉">F-终焉</h2>
<details class="pink" data-header-exclude><summary><i class="fa-solid fa-chevron-right"></i>F-1 </summary>
              <div class='content'>
              <p>在那一瞬间，她能被人所记起。那样就足够了。</p><p>白色的火焰，在红色少女的身中熊熊燃起。其中的力量，足以让世界都为之臣服。她操控着这道火焰，让它们环绕着自己，同时开始思考事情为何会发展至如此地步。她的敌人此刻也停了下来。整场战斗迎来了短暂的沉寂。</p><p>然而这并没有结束，上方的天空，仍在显著地破裂着。</p><p>这一切，只是因为她触碰到了事情原有的模样：那一刻，当死亡的呼声充斥于脑海中时，她也没有因此而惧怕。</p><p>即便如此，“死亡”也不会是她想看到的结局。现在的她，依然拒绝向其屈服。在破碎的天际下方，虚无的山谷之中，白色少女身上不断流落着鲜血，然而那血滴却根本无法波及地面。远方，只剩下一座矗立的高塔，那是某个荒废教堂的钟楼。它横亘于天际与少女之间，如同一条醒目的分界线一般。</p><p>结局，就要来了，就如同我们曾看到的一样。</p><p>这就是宿命吗？</p><p>上方的天际之间，星光在不断闪烁着。而被撕裂的帷幕后方，黑暗也在不时涌动着。只是，她还察觉得到这些吗？她还会在乎这些吗？眼前的视界逐渐变得越来越迟钝，直到最后完全静止。当炽热的鲜血流尽，双瞳也失去了神色。</p><p>对立很清楚，那样的双眼，已经注定她将时日无多。她咽下一口口水，以此浸润着早已干裂的舌头与喉咙。然后她看向对方的双眼——少女一语不发，却依然坚定着誓要反抗的决心。</p><p>“空虚”充斥着光的内心。不过，这不是对立从少女无言的凝视中所看见的那种空虚，那并不是无力的空虚感。相反，有一股坚定的信念在其中蓄势待发，那是光永远不会被磨灭的信念：她要“活下去”——少女一语不发，却依然坚定着誓要活下去的决心。</p><p>对立疯狂地冲向对方。</p><p>整个世界都试图阻止着她前行。然而现在的她，如同脱缰的野兽般拒绝着阻止她脚步的一切。纵使这股力量不断撕扯着她的皮肤，她也绝不会停下。</p><p>黑色野兽的獠牙，此刻已经直直伸向了站在大地之上的白色野兽。而对方，也将头转了过来。</p><p>然而，就在对立接触大地的那一瞬间，整个世界就如同上下颠倒一般。掉落的玻璃刚发出嘈杂的声响，下一秒就立刻反向飞出。她的手臂甚至一时失去了知觉，但她咬牙坚持了下来。她勉强把膝盖伸直，却发现下方突然闪过一道光芒——那是一道白色的火焰，透过碎片之间向上猛然窜出。对立急忙向后退去。</p><p>眼前的一切，瞬间化为火海。</p><p>周遭的世界，再度天旋地转。</p><p>如此频繁的颠倒让对立感到浑身难受，但她很快就遏制住不适感并站稳步伐。</p><p>白色少女再一次悄无声息地靠近，而那道苍白的火焰犹如围巾般缠绕并灼烧着对立的肩膀。</p><p>对立不得不再次后退。</p><p>就这样，玻璃在世界的颠倒中不断上下起伏。四散的碎片，逐渐如棱镜般环绕着对立的身影。</p><p>她再次看向光的双眸。光并没有回以眼神，只是静静看着她所打造的这个牢笼。</p><p>接着，她低声说了些什么，但是……</p><p>……那并不是黑色少女想听到的话。</p><p>对立攥紧拳头打碎了这其中一块坚固的玻璃，并起手瞄准光的喉咙。光抬起头看向对方的那只手，而下一秒——</p><p>七彩的光芒透过破碎的玻璃喷涌而出， 连带着时间也停止了下来。</p>
              </div>
            </details>
<details class="pink" data-header-exclude><summary><i class="fa-solid fa-chevron-right"></i>F-2 </summary>
              <div class='content'>
              <p>这种情况先前肯定也发生过。</p><p>这种抗拒的方式，这种似曾相识的感觉——</p><p>光能感觉到周围的一切都在远离自己。</p><p>时光仍处于冰封之中，她的心情也低沉到了冰点。现在的她，只想让自己就此打住。这种想法不是因为光的本性有多么善良。</p><p>她只是不在乎罢了。这种刻进骨子里的冷漠，才是她一直以来的样子。她以前肯定也有过这种想法。</p><p>在她的内心深处，有两股思绪正在相互斗争。</p><p>——我无法这么做。</p><p>——我必须这么做。</p><p>这种围绕“应该”还是“不应该”的情感对抗正变得越来越强烈。</p><p>但她能感受到内心深处还有一丝火焰在微微颤动。显然，再激烈的斗争，也无法抹灭她内心真正的希望。</p><p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/arcaea_story_cg/Story_F-2_cg.jpg"
                      
                ></p><p>对立被定格在光的面前，她的面容与伸出的手因为愤怒而变得扭曲。周围的虹光，因为破碎而弥漫于空气之中。对立动弹不得，光亦是如此。</p><p>光内心的希望告诉她：“等时间恢复之时，只要把她推得远远的就不可能再打了吧？”只要能停止战斗，就不会再有谁因此丧命。她开始思考这种想法的可行性。</p><p>这应该行得通。希望犹存，则应该有其存在的意义。</p><p>时光再次流动了起来，而对立也在一瞬间被推往远处教堂的大门之后。她呼唤碎片撕裂了门栏上的铰链，然后一股脑将门上的一根铁杆抓了下来。</p><p>她很快就明白了对面那头野兽当下的意图。</p><p>她叫来了周围能找来的全部玻璃碎片，并将它们送往空中，任凭那些碎片闪烁而反射着周围的景象。</p><p>就这样，她很快便找到了光的身影。随后，她开始撼动着脚下的大地。世界的核心，连带着地壳都开始变得扭曲，只剩下光站在地上做着无声的抵抗。</p><p>她能感觉到对立深深的执念。那是要夺走这一切的执念，无论地点，无论手段，她心意已决。</p><p>哈，这就是所谓的希望吗。</p><p>她笑出声。</p><p>什么“希望”，早就不复存在。</p><p>阻隔在她们视线之间的一切全部灰飞烟灭，甚至她们自己也已经分不清是谁下的手。教堂的阴影下，破败的大门前，她们就这样面对面看着彼此。</p><p>光脸上露出一丝轻蔑的微笑，她再一次告诉对立：“我说你啊……你并不需要做到这种地步。”</p><p>那并不是黑色少女想听到的话。</p>
              </div>
            </details>
<details class="pink" data-header-exclude><summary><i class="fa-solid fa-chevron-right"></i>F-3 </summary>
              <div class='content'>
              <p>“我不需要做到这种地步？你在跟我开玩笑吗？”</p><p>对立继续说道。</p><p>“你根本不知道自己为什么会来到这里。不如说除了我之外，还有人知道吗？”</p><p>“我不需要做到这种地步？没错啊，本来什么都不会发生的，这破地方根本就没什么意义。你懂吗？你根本就不懂，你什么都不知道。”</p><p>“我已经受够了。你以为我想来这种地方吗？”</p><p>“这种毫无意义的故事，我是主角还是反派……都已经无所谓了。或许，这场故事要做的……就是要你命丧于此。”“你说得对，我不需要做到这种地步。”</p><p>“那你一开始就不应该那么做。”</p><p>……她的话语，犹如沉重的巨石般，试图压倒眼前的光。</p><p>而对光而言，这些话只能用“疯了”来形容。如今，她感觉到自己和眼前这位少女似乎已经联系在了一起……但对方的内心里只有无尽的疯狂。</p><p>对立也明白自己的心智已经陷入疯狂，但她已经不在乎了。事已至此，已经没有什么可以失去了，也不会再有什么可以得到了。</p><p>她最后一次开口说道：“如果你还想活下去，那就来杀了我。”</p><p>“但在那之前，我要告诉你……”</p><p>“我只求一死。”</p><p>她的决心与杀气尽在言语之中。</p><p>对立的体内充满了力量，她的双手蓄势待发。</p><p>无论如何，她都必须要结束这一切。</p><p>在这股情绪的引导下，她召唤来双方都还未曾掌握过的碎片。</p><p>那是天空破裂之后的碎片。随着它们开始下坠，天际也逐渐堕入深渊。</p>
              </div>
            </details>
<details class="pink" data-header-exclude><summary><i class="fa-solid fa-chevron-right"></i>F-4 </summary>
              <div class='content'>
              <p>光无法控制一切。</p><p>事实上，她在取得主导权后不久便失去了控制。</p><p>这就像是一场拔河比赛……</p><p>不，倒不如说这是一次挣扎——</p><p>或者说是单方面的压制。</p><p>天空塌了下来，其中一部分砸落在大教堂之上，并瞬间扬起无数的尘土，而这一切就发生在她身旁。</p><p>这绝不会是巧合。</p><p>随着越来越多的碎片铺天盖地地砸向地面，光也明白了——对立，已经掌控了整个天空。</p><p>这太荒谬了，荒谬到难以置信。</p><p>整个世界变得天昏地暗。碎片与狂风交织在一起，杂乱无章而又遍布各地。面对着混乱的碎片，她伸手一指将它们化为苍白的火焰燃烧殆尽。</p><p>她也可以掌控天空的一部分。就在对立将整个世界都砸向她时，她也会接住这一切并还以颜色。</p><p>眼前的景象完全就是灾难，就好像是泰坦巨人从天而降肆意践踏着大地一般。</p><p>而在那白色的风暴中，有一些光无法干涉的黑色碎片正从远处被召唤而来。那是被对立掌控的碎片，那是光无法主导的一切。</p><p>在她回击之时，周遭的地面、建筑、大门无不为之震动，甚至她的牙齿都为之发颤。她站稳脚跟，然而战栗感依旧从指尖传到了全身。</p><p>她们上方的大教堂因为无数碎片的摧残而发出沉闷的低鸣。但大教堂依旧屹立不倒，而她也绝不会倒下。</p><p>……她本可以阻止这一切。她曾经有那样的机会。</p><p>伴随着猛烈的心跳，她眯起眼睛思考着——</p><p>接下来要崩溃的，会是这个世界的核心吗？这就是那名少女的目的，不是吗？</p><p>她努力不让眼前的景象彻底分崩离析，同时拼命思考着该如何阻止对方，但就在这时——</p><p>她突然感到胸口透不过气来。一群Arcaea从黑暗中飞奔而出，如同锋利的锁链般捆住了她的胸口。她急忙用火焰将它们烧成灰烬，可是很快就会有新的锁链缠绕住她。</p><p>她的双臂很快也被束缚。她努力地转过头去，却发现自己双脚到双腿全都无一幸免。</p><p>最后，连她的腹部也被缠紧。她不断召唤火焰，不惜整个身体都遍布于火焰之中，可碎片很快就会再次缠绕住她。</p><p>束缚着她的全身的，是那些充满悲伤的记忆。</p><p>如同讽刺般悲伤的记忆。</p><p>光艰难地解开了双脚的束缚，却发现对立已经向她靠近。</p><p>她向后退了一步，却发现身后暗藏了一块尖锐的碎片，而它已经瞄准了光刚被解开束缚的四肢。</p><p>情急之下，她双眼紧盯着那片玻璃，企图用意念将其烧毁。</p><p>但那片玻璃不为所动。</p><p>她很快又被捆住，然后跪倒在地上动弹不得。</p><p>说不定还有一条出路。</p><p>或许曾经有一条出路——</p><p>在某一个时间点，她还能有一线生机？</p><p>光思索着抬起头，发现对立一动不动地站在她面前。</p>
              </div>
            </details>
<details class="pink" data-header-exclude><summary><i class="fa-solid fa-chevron-right"></i>F-5 </summary>
              <div class='content'>
              <p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/arcaea_story_cg/Story_F-5_cg.jpg"
                      
                ></p><p>她们就这样在沉默中相遇了。</p><p>沉默的少女，沉默的视线。纵使方才战斗的声音在耳边回响，她们也依然目不转睛地注视着彼此。</p><p>大地在轰隆声中破裂，狂风在呼啸声中肆虐，建筑在倒塌声中扬起漫天尘土……但这些都无法让两名少女的视线从对方身上移开。</p><p>而光也看得很清楚——</p><p>对立的眼神中，依旧燃烧着战斗的怒火。</p><p>这不是休战的信号，这是无声的威胁。光深吸一口气，而对立则把目光投向了光的喉咙。她痛恨着光的每一次呼吸，也痛恨着光的每一道声音。</p><p>这股恨意刺透着光身上的每一片肌肤。</p><p>光现在希望时间能够再次停止，然而时光依旧。</p><p>她试着用火焰去烧穿束缚住她的锁链，但它们不为所动。</p><p>大地没有颤动，天空也没有响应。</p><p>她的脑袋一片空白，这才发现自己已经不知不觉间屏住了呼吸。</p><p>“……”</p><p>天空已陷落得所剩无几……教堂也逐渐化为废墟……</p><p>漫天纷飞的尘土弥漫在她们之间，覆盖了整个天空。</p><p>对立的眼神里依旧充满着尖锐的杀气。</p><p>那股杀气逐渐聚焦在对方身上。这一刻，整片废墟已然变得鸦雀无声。</p><p>……光依然死死地盯着她，而对立这时把目光放向了一份记忆。她发出一声冷笑。</p><p>“我们又回到这里了。”对立微微歪起头继续说道，“你还要再来一次吗？又要祈求有奇迹发生了吗？”</p><p>光没有回答。</p><p>“……奇迹之所以被称作奇迹，就是因为它们太完美了，完美到根本不可能存在。”</p><p>“你透过这些碎片……透过Arcaea见识过太多破碎的世界。所以你应该明白，奇迹也只不过是另一种‘希望’罢了。”</p><p>“更何况，无论有没有奇迹的存在……你都难逃一死。”</p><p>光深呼着气，而对立则逐渐挺直了身体。</p><p>黑色少女继续说道：“你应该很清楚，如果可以的话，我宁可选择忘记世间所有的一切。”</p><p>光再次试着动起来，却还是无奈意识到自己已经被完全固定住。她的肩膀被拉得紧绷，脚趾也蜷缩在了一起。</p><p>“我要杀了你。”对立说道。“连带着这个世界……‘你的世界’Arcaea也会一同灰飞烟灭。”</p><p>她的嘴角再次扬起一抹微笑。这一次，她深吸一口气，随后挤出一记诡异的笑声。</p><p>接着，她伸出一只手摸向光的脸颊。随后轻轻抬起少女的下巴。</p><p>“你说得确实没错。”对立一边说道、一边把手伸向对方。“我确实不需要……为了你做到这种地步。”</p><p>她收回了笑容，身体也向前倾去。</p><p>对立的目光……那是一道熟悉的眼神。</p><p>是悔恨的眼神，是同情的眼神。</p><p>她黑色的翅膀向下收起。</p><p>而头顶的夜空，依旧闪亮。</p><p>尽管方才狂暴的战斗都已经烟消云散……但光的心脏依旧猛烈跳动着。</p><p>她不得不承认，单纯“阻止”对方是没有用的。</p><p>对立将左手从光的喉咙处收回，而就在这时……</p><p>……她的手掌中，多出了一块尖锐且闪亮的黑色碎片。</p><p>在这最后，对立说道：</p><p>“至少，我想告诉你：</p><p>在这里，我的名字是对立，而你的名字是光。”</p><p>“求求你……”</p><p>光勉强发出一丝微弱的声音。</p><p>“求求你住手……”</p><p>对立歪过头来。</p><p>“……还来啊？” 她思考片刻，随后补充道：“什么都不会再改变了。”</p><p>而就在这时，一道耀眼的光芒粉碎了光身上的束缚。她站起身并伸出手，试图祈求一把武器——</p><p>她的身体很快又被束缚住。</p><p>即便如此，她的祈求并没有消失，一把利剑开始在她的手掌中逐渐成形。那是一把“全新”的武器，虽然同样由玻璃构成，但却并不是什么记忆。</p><p>这根本就难以置信……剑刃周围的空间似乎在光亮中发生着扭曲。Arcaea甚至改写了自身，让自己逐渐适应了这把武器的存在。</p><p>对立心想：这真是太可笑了……</p><p>她以前也见过这种参差的玻璃长柱。</p><p>光再一次挣脱身上的锁链，并转起手中的利剑，将其重重插入地面。随即，一股诡异的强风突然升起，并把对立推往远处。</p><p>光举起剑，将剑刃瞄准对立。 但在此时，她发现自己的手在颤抖。</p><p>对立并未因为这股强风而乱了阵脚，她的目光再次落在了那把熟悉的利剑之上。</p><p>无言的视线。</p><p>无言的等待。</p><p>……她紧咬牙关。</p><p>她看向光的脸庞，却发现对方完全无法集中精神。</p><p>她看到的，只有摇摆的表情，和踌躇的身躯。</p><p>这让她失去了最后的耐心。</p><p>光的四周开始升起玻璃状的高墙，每面墙壁都倒映出对立逼近的身影，而她们的手中全都闪烁着黑色的光芒。这是镜像还是实体或许已无从得知，但当这种景象从这些四面八方的玻璃中显现之时，还是让光的背后惊出一身冷汗。</p><p>对立抬起了手，下一秒，她便将穿透对方的喉咙。</p><p>白色少女的双手一直在颤抖，但她还是紧握着手中的剑。</p><p>刺耳的声音开始在她脑中回响，紧接着，心跳声也再一次传到了她的耳边。</p><p>只要她再次收回手上的剑并将其插向地面，周围的墙壁就会倒下，而对立也会被再一次击退。</p><p>理性告诉她这样的情况将会反复上演。</p>
              </div>
            </details>
<details class="pink" data-header-exclude><summary><i class="fa-solid fa-chevron-right"></i>F-6 </summary>
              <div class='content'>
              <p>理性告诉她这样的情况还会反复上演。</p><p>只要她再次收回手上的剑并将其插向地面，周围的墙壁就会倒下，而对立也会被再一次击退。</p><p>那么，为什么——？</p><p>当她感受到对立的手轻柔触碰她的右脸颊时……</p><p>为什么，当对立实实在在地出现在她面前之时， 她却举起了剑，刺穿了对面少女的胸膛……？</p><p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/arcaea_story_cg/Story_Testify1_cg.jpg"
                      
                ></p><p>她一切的情感都化为了这一剑。她能从余光看到，对立的右臂因为疼痛向下滑落，而一块黑色的玻璃从她的手中掉了出来。</p><p>一道耀眼的光芒从中由缓至急地迸发而出，直至超越了一切的存在。</p><p>随后，呼啸声破门而出，那是带走生命最后的绝唱。那声音震颤着整个大地，也震颤着对立的全身。</p><p>就这样，结束了。</p><p>声音趋于沉寂，少女的生命也归于沉寂。</p><p>就在她把剑刺穿对方的身躯时，剑刃便吞噬了对方的生命，她的鲜血与一切都被那道玻璃全然吞没。紧接着，那道玻璃也开始碎裂消散。短短一瞬，她的生命便失去了活力，而仅存的身躯也随之倒下。</p><p>光下意识抓住对立触碰着她脸颊的手。然而，对方的生命却在极速消逝。不过寥寥数秒，眼前的少女，便只剩下了一具冰冷的身体。</p><p>当玻璃制成的剑身瓦解消散之时，一丝温度传遍了光的指尖可是她的另一只手，却已察觉不到对立的一丝气力。</p><p>那名少女的双脚着地，而她的身体则被光打湿而温暖的手托着。如今的她已阖上了双眼，她眉头紧锁……但也渐渐失去了光泽。这并非一场安详的告别，可是她的生命就这样画上了句号。</p><p>光睁大双眼，感受着自己心脏的跳动。直到现在，她才彻底明白这一切。</p><p>她缓缓收回左手，将面前少女的身躯放下。随后，她再次把手伸向那名了无生气的少女。她睁大眼睛，紧紧攥着她的手，任凭自己和对方就这样跪倒在地上。</p><p>她将手靠在对立早已停止跳动的胸前，从中的暖意，似乎提醒着她这道伤口是由她而造成的。</p><p>事实上，即使是大地和天空也没有幸免于这一剑……只是她的注意力全部都集中在那个已经血肉模糊的窟窿，而她的周围早已被彻底夷平。那一剑所施展的力量想必是何等的强大……</p><p>周围的景象早已面目全非，天空变得空荡荡的，大教堂也完全不见踪影。</p><p>对立身后，有一面碎裂的砖墙再也支撑不住冲击而倒塌，而那还是因为身处眼前这名少女之后才免于分崩离析。可是……即使是这面强大的盾牌，也已被彻底刺穿。</p><p>光贴近另一名少女的脸，似乎在侥幸地等待着对方的下一次呼吸。可那再也不会发生了。</p><p>她更用力地握住对方的手，只是那只手永远不会再回应她。这一切逐渐让她气急败坏，她恼怒地将对方的手甩到地上，并将手指甲深深嵌入眼前少女的衣襟。她再次从手心感受到了一丝温暖，这才发现泪水已经滑落于手掌之上。</p><p>她很清楚，她刚刚还体会过这份暖意。但看到自己亲手被泪水划出血色的泪痕时，她还是被吓得不知所措。</p><p>她被吓得一阵哆嗦，差点没有站稳。</p><p>她的表情变得扭曲，嘴唇也不停地发颤。</p><p>她啜泣出声。尽管她一直用另一只干净的手擦着眼泪，可泪水却止不住地向外流。</p><p>她渐渐失去了平衡，而对立也跟她一同倒下。光把那被血水浸湿的手收回裙摆，而另一名少女的身体则向后靠在了大教堂的残骸上。</p><p>她自己的声音在脑海内回荡。</p><p>对现在的她而言，那仿佛是充满讽刺的惩罚——</p><p>"你不需要做到这种地步。"</p><p>……这并不好笑。</p><p>现实的一切都没法被轻易忽视。无论你如何挥舞着双手，皮肤传来的灼烧感也永远不会消失，就如同那把剑一样。</p><p>她就这样结束了生命，而你就是杀人凶手。是你杀了她。</p><p>可你真的有试着去了解她吗？你知道她承受了多大的痛苦吗？</p><p>"现在你又要怎么做呢……？"不，难道你还不明白吗？</p><p>这可不是什么微不足道的小事。 这个世界已经记录下了你刚才所做的一切，而你再也不用像过去那样接着踏上旅途了。</p><p>你不应该很开心吗？你赢了啊，毕竟你活了下来。</p><p>还是说，你讨厌成为活着的一方？</p><p>讨厌活着的不应该是她吗？</p><p>因为她讨厌活着，所以你就让她得以解脱。对啊，所以这是多幺正确的决定啊。一定是这样的，是吧。</p><p>……你脑袋里都装了些什么东西？</p><p>即便到了现在……</p><p>你还是满脑子只有自己。</p><p>这种内疚的想法越是强烈，她的心灵就变得越发脆弱。她抓住自己的头发，但依旧无法抬起左手。</p><p>她止不住一直谴责自己。</p><p>谴责自己的卑微，谴责自己的自私，谴责自己是多么自以为是。</p><p>然而这时，有什么东西开始在她身边徘徊，并告诉着她……</p><p>……这种感觉你并不陌生吧？</p><p>恢复意识的她，发现自己苏醒于这个飞舞着玻璃蝴蝶的地方。"多么令人愉快啊，"她想，"这些美妙的图案居然能在空中移动呢。牵引着它们的丝线在哪里？"</p><p>她蹲了下来，整了整裙子，环顾四周才发现这附近没有任何丝线。那些事物，也并不是蝴蝶——玻璃碎片，不依靠任何外力便飞舞于空中。 "太美妙了！"她自心底赞叹道。</p><p>这些玻璃反射出了另一个纯洁的世界。她从中看见海洋、都市、火焰、光芒；美好的景象目不暇接。她抬起了自己的手，试图去抓住它们，开心地笑了出来。</p><p>……我并不知道这些玻璃碎片有个名字：Arcaea。实际上，名字对这些过于美好的事物来说并不重要。我触碰、旋转、观察它们；靠这样来娱乐自己。这已经足够了，难道不是吗？</p><p>不。</p><p>你早就明白这并不够。或许你差点就因此而感到满足，但事实是，人类终究是本性难移的。</p><p>而这一点你一直以来也心知肚明。</p><p>帷幕并不会就此落下。这个故事永远也不会有"尽头"。</p><p>只是，这个地方已经没有什么意义，就和你所想的一样——</p><p>不过是个哭泣的少女，独自一人置身于这个死寂的世界。</p><p>但至少，以牺牲那名少女为代价，你得到了一个值得欣慰的真相。虽然她差点就能带你离开这里。 这是用少女血的教训换来的真相——</p><p>没错。</p><p>这里一直以来都是一片乐园。</p>
              </div>
            </details>
<details class="pink" data-header-exclude><summary><i class="fa-solid fa-chevron-right"></i>F-7 </summary>
              <div class='content'>
              <p>乐园—— 在生命结束后，那个名为“天堂”的世界。 那是生命落脚安息的终点。那是灵魂游荡徘徊的远方。</p><p>我就在那里，而你也是。</p><p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/arcaea_story_cg/Story_F-7_cg.jpg"
                      
                ></p><p>“……所以就这么结束了？ 再也感受不到把手搭在她脸颊上的触感，再也体会不到被她用玻璃活活刺穿的疼痛……我什么都感觉不到了……也感觉不到她……</p><p>……让我解脱吧……”</p><p>为什么？你人在这里，但是……你不是还有一些心结没解开吗？你明明还有些微弱的心跳……至少还能再撑一会儿。</p><p>“不，已经够了……”</p><p>不，这件事还没有结束…… 听好了……快想起来。 快想起来你自己是谁……你所经历的时间远不止这些，不是吗？你肯定见过比这些还要糟的事。所以赶紧站起来，再次战——</p><p>“闭嘴。”</p><p>……那好吧。 那我们就随便聊聊。</p><p>“我刚才说话你没听见吗？我已经说过我不想说话了。我只想……想要……”</p><p>我只想要你想起来。</p><p>“……你真的挺烦的，你知道吗？那你又想起来了吗？如果你真的记得，你应该知道我为什么不……</p><p>啊……这是？…………我好像想起来了……这些记忆正在不停地涌入我的脑海，我全都想起来了。这么说来……如果这些记忆全是真的话……哈，我以前就这么想过，但……这是在跟我开玩笑吗？”</p><p>……</p><p>“在过去的人生里……我为活在这个世界上而感恩，但是……生活……却是那么的糟糕。世间践踏我多少次？又唾弃我多少次？无论怎么做，憎恶都如影随形地跟着我。但我们想要的明明只是……只是运用这股力量来…… 来……帮助他人。”</p><p>我们吓到了她们。</p><p>“‘我们’？你究竟是谁？”</p><p>那，“你”又是谁？</p><p>“真是奇怪……这件事情我居然还想不起来。 …………你还是就叫我‘对立’吧。”</p><p>这样的话……你也这样称呼我吧。</p><p>“开玩笑……真的假的？你的意思……该不会是我说对了吧？”</p><p>说对什么？</p><p>“我是说，她没有经过任何的思考就创造了这个世界。如果你就是我……如果我在这里曾经度过的人生就这样被重蹈覆辙…………那她……真是恶劣到了极点。”</p><p>……我认为她只是还没意识到这一切。</p><p>“……如果只是这种理由的话，那她没什么值得同情的。或许她和我来自不同的世界，但这不是她没有认清自己能力的借口。她绝对知道，只是不在乎罢了。所以说……哪怕她真的和我一样了解这个世界，我也不会原谅她。我和她不一样，不是因为我跟塑形者练习了多久，学到了多少东西，而是因为我们对待这个世界的态度就完全不在一条线上。要是我有足够的力量……要是我的力量足够改变这个世界——”</p><p>要是有的话我也会这么做的，但是我做不到，也没有这么做。</p><p>“……所以最后的结果就是：我又获得了一次机会。这就是她所想看到的，而且不止我一个人，她给了所有人第二次机会。真是蠢到无可救药啊，完全就是一场笑话，不觉得很好笑吗？”</p><p>……</p><p>“什么？你笑不出来？你当然笑不出来。是啊，这算哪门子的第二次机会，倒不如说是莫大的讽刺。我如此挣扎地活着，甚至与世界为敌。即使身心憔悴，血流不止，但我也没有轻易倒下！即使我早知道这一切都是徒劳，但我还是一次又一次站起来奋战到底！为什么她要逼我重新经历所有的一切？啊？快回答我啊！…… 我只是想做出改变……我只是不想……就这样放弃……”</p><p>……那第二次呢？这一次，你放弃了吗？</p><p>“嗯……我放弃了。 …… 嘿……我知道我要不行了。在离开之前，我还能再看一眼外面的世界吗？我还能透过我的鸟儿再看她那个小小牢笼最后一眼吗？”</p><p>……没问题。</p><p>“太好了。 ……这样看过去，还有好多狭小而未知的角落，而且那里都充满了被困的灵魂。不，她们或许都不能被称作灵魂。这里的一切说到底都只是记忆，哪怕是我们也不例外。也不知道她们到底在想什么……那个时候，我只接触到那份碎片的一角，还远没有到完全理解的程度。”</p><p>大家都很幸福呢。真的，少女们都非常的高兴。</p><p>“……那她真是太残忍了…… 我…………我现在真的只想大哭一场。为什么我要这么做？为什么我就这么死了？”</p><p>……</p><p>“……你的脸色看起来很不错，难道你已经知道答案了吗？我好像……终于彻底明白了，而且……好痛苦……这一切都好痛苦。事情的真相如此残酷，而我甚至没有办法流下眼泪……”</p><p>没错，看来就是这样。</p><p>“……？”</p><p>你并非真的想丧命于此。那你当时为什么还是那样做了？</p><p>“……在我最初的人生中，前方的道路或许暗淡无光……但我知道它终将引向无数的可能性。诚然，有些道路的尽头会迈向死亡，但只要我选对了方向，就一定能找到一条出路。可是这里的情况截然不同，而我当时居然还以为自己同样能在这里找到出路。我对自己曾抱有这种天真的想法感到厌恶。</p><p>这里的道路荒芜贫瘠，而且根本没有能落脚的地方。不论是踏上哪一条道路，都只能无休无止地盲目前行，直到双腿变得彻底麻木，才能看清真相。而真相就是，无论你选择了哪条道路走下去，都会发现最后什么都没有。”</p><p>……我其实并不这么认为。我觉得……一定会有通往其它可能性的道路的。</p><p>“你知道你刚才在说什么吗？你现在可是困在这里，只能跟死人说话啊。拜托，能不能至少认清一次现实？”</p><p>……我只是觉得这难以置信。我不会就这样放弃希望的……我不能接受那……那样的……</p><p>“我刚才已经说过了，你不是想知道真相吗？真相就是这里的一切都毫无意义。”</p><p>不。 真相不该如此。 我不会让这变成真相的。你也很清楚，如果这就是真相，那这真相实在是过于悲惨而丑陋。</p><p>“…………这我倒是还记得，那是来自我生前的记忆。我就是带着那样的想法才能坚持活下去的。你真的是跟我一模一样呢。看来她真的彻底复制了我……真相果然如此，我们大家都是被复制出来的空洞灵魂。 没错…… 她还活着，而我们都死了。”</p><p>……</p><p>“但话又说回来……为什么你会在这里？其他人的思绪都到哪里去了？她们的灵魂呢？”</p><p>……我不知道，这些我都不知道。</p><p>“好吧，但是……话说，你还没承认过对吧？……那你……直接告诉我好吗？你真的是那个真正的我吗？你就是我的灵魂吗？”</p><p>是的……我就是你的灵魂。没错，我一直以来都一个人在这里。而且，我也一直以来都在观察着。你还挺烦的，你知道吗？ 对立，你不也是真正的我吗？我们大家都是。</p><p>“或许是这样吧。有可能我曾经是。”</p><p>是啊，你是挺烦人的。 像你这么烦人的家伙，一定不可能是假的。</p><p>“哈…… …… 谢谢你。”</p><p>我从来没有想过会看着自己在第二段人生中再一次经历同样悲惨的命运，只是这次事情的走向却不尽相同。</p><p>“哪里不同了？”</p><p>你自己也说了。 你放弃了。 我想让你去……我也不知道。我真的只是希望事情能往……好的方向发展。</p><p>…… 你还是觉得这一切没有希望吗？毕竟这位“反派”已经死了……</p><p>“我知道你是在跟我开玩笑，但……对不起。 我当时气坏了。我也不想完全放弃。 我也不觉得这真的是穷途末路。我的意思是，即便在一切结束之后，你也依然在这里，对吧？说不定等我离开之后，你也还是会继续待在这里…… 而且我觉得……到时候如果你还在继续观察的话…………你也不该像我一样放弃希望。 或许吧，我也不清楚…… ……不，我应该很清楚。那些还在这里的少女，说不定有办法拯救自己。但愿如此，就像你所说的，让这一切变得更好…… 那就是我想要的一切。如果我没有真的离去，如果你在这一切过后还有办法找到我，我希望你能告诉我，她们找到了属于自己的出路。”</p><p>我会的。</p><p>“呵，说来也很神奇……在我还活着的时候，在其他人都还不在的时候，我记得我一直在自言自语……就像现在一样。但是你知道的……我从来没有感到孤单。”</p><p>没有人是完全孤独地活着的。</p><p>“没错，就是这句话……我每次都这样告诉自己…………我想要再次见证这个世界。</p><p>虽然这片世界已经被白色所笼罩，只有崩塌的高塔，和飘浮在空中的玻璃碎片。而且越来越多的碎片，划过白色的轨迹，飞向了逝去的灵魂……</p><p>但是，我能从她们的脸庞看出： 这些少女都已不再迷惘。”</p><p>……“都”？看样子你终于忘掉她了。</p><p>“‘她’……？对哦，她啊……其实我也看得见她。唔，她对于这件事情感到很伤心…………但这难道不是好事吗？至少，她的内心能感受到悲伤和痛苦了……这总比没有反应好。”</p><p>嗯……是啊。</p><p>“我不知道她能否缓过来，但我相信她会带着这份悲痛活下去的。老实说……现在想想，我还得向她道歉。我认为我做的事都是正确的，但是——”</p><p>你可没做什么正确的事情。</p><p>“噗……！哈，好吧，但是……我不认为自己有做错什么。我只是想说……我愿意向她道歉。我们都是真实存在的。如果她也是真实存在的……那么她也不过是一个愚蠢的复制品，看不到自己的无知，却因为这份无知平白受害。</p><p>…… 看来，我们要到此为止了，是吗……？”</p><p>很遗憾，但……是的，时间就要到了。 …… 不要就这样离开，好吗。</p><p>“很遗憾，但……我也没有办法。说实话，我其实不能算是……真的在这里……”</p><p>……</p><p>告诉她吧。</p><p>“……是啊。 ……光……我真的很抱歉。我不后悔所做的一切，但……我刚才心中的那股恨意，其实……并不是冲着你来的，而是……另外一个你……她现在还在……某个地方，至今依然……还活着……我还是……不能原谅她。 但你…… …… 我希望你明白……你比她更加强大。光，正是因为如此…… ……我知道你一定还会再站起来。”</p><p>闭上你的眼睛吧。</p><p>“我已经闭上眼睛了。”</p><p>不要再有任何担忧……</p><p>“我心中并没有担忧。”</p><p>我们还会再见面的。</p><p>“我觉得不可能了。 但是没关系。 我已经接受了。</p><p>我受尽苦难，但即便如此，我还是想要做出改变，让一切变得更好……</p><p>我为了它而战……无论我要面对的是什么……无论我……因此变得……多么的迷茫……</p><p>……</p><p>对不起……我选择了死亡。 很抱歉我把一切都抛之脑后。</p><p>……但即便一切都是徒劳……我也很幸运地获得过重来一次的机会。所以没关系……我接受这样的命运。”</p><p>我知道。</p><p>“我希望她知……知道……我不想要……自己在这个世界……唯一留下的足迹……是个可悲……愚蠢的结局。</p><p>……如果你听得见我说的话……光……我想告诉你…… 真的……请你一定……要记住……</p><p>……</p><p>……</p><p>我接受这样的人生。”</p><p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/arcaea_story_cg/Story_F-7-2_cg.jpg"
                      
                ></p><p>白色少女在黑色少女的遗体面前哭泣。</p><p>她因为强烈的痛苦和悲伤而不能自已，丝毫没有发现对方嘴角划过的那一丝转瞬即逝的微笑。</p><p>这则故事还有很多地方不为人们所知。事实上，有些故事一直到结局都没有被完整搬上台面。</p><p>这些故事只剩下零星的残片散落在各处，只有加以拼凑之后才能看清全貌。</p><p>这就是这个由碎片组成的世界的故事。</p><p>被遗忘在这里的少女们日复一日地拾起这些碎片。</p><p>她们相信，倒影之中存在着意义；她们相信，她们的存在本身，自有存在的意义。</p><p>在这里，有一名白色少女伤痕累累地倒在地上，她身心受创，她孤身一人。</p><p>但她也将寻找碎片并带着它们前行。</p><p>这里的记忆还在继续。</p><p>一切都会被记住，并被保留到最后。</p><p>它们会不断延续下去。</p><p>不会有任何事物被遗忘。</p>
              </div>
            </details>
<h2 id="e-结局">E-结局</h2>
<div class="tabs" id="tab-e"><ul class="nav-tabs"><li class="tab active"><a class="#e-1">E-1（最终之梦）</a></li><li class="tab"><a class="#e-2">E-2（完美之愿）</a></li></ul><div class="tab-content"><div class="tab-pane active" id="e-1"><p>光瘫坐在尘土与血泊中。</p>
<p>我看到她在那里……她的愚蠢和自怨自艾毁了她。</p>
<p>从捂着脸的指缝间看出去时，她再一次发现你的视线所指向的，是已经死去的，
我的第二个自我。冷漠，也可说是造成这一切的元凶，致使了你的死亡，而它一定会威胁着要卷土重来。</p>
<p>我知道，这名身穿红白衣服的少女感觉得到。
她感觉得到，她就是为此而存在。</p>
<p>你的死早已注定， 而她就是那个杀害了你的人。</p>
<p>她的后背放松下来…… 这世界……Arcaea……她好像感到压力在从中释放。
那是一种解脱……</p>
<p>混沌已经散去……现在安全了…… 但我也听到了……
有个像低语的东西缓慢进入她的内心，仿佛在要求她接受这个状态。</p>
<p>接受她自身，接受Arcaea。 ……然而——</p>
<p>"……对立……"</p>
<p>……她对自己低语道一个名字。她声音颤抖，泣不成声。</p>
<p>"你是什么意思……？我们在‘这里’的名字是那样的……？"</p>
<p>她沉默不语，感到讶异。</p>
<p>低语再次对她说道：只要你想，那些答案就会浮现。
这地方，封存了所有的回忆…… ……而她依旧沉默不语。</p>
<p>"……"</p>
<p>埋藏在她武装的冷漠之下，是纯粹又刺眼的憎恶。 她无法停止憎恨自己。</p>
<p>很明显她做不到。在一切之后……她要如何接受这样的结局？这代表什么？
对她来说有什么意义？</p>
<p>她……曾漫步于此的她，绝对不可能接受。</p>
<p>反胃感吞噬着她的腹部，她咬紧牙关。</p>
<p>"……"</p>
<p>光将手放至身下的尘土与沙子中，然后在膝盖上抖了抖。</p>
<p>她问道： "Arcaea……你是来治愈我的吗？"</p>
<p>她的手臂放松下来，就像是有一道凉爽穿过了她的手臂。</p>
<p>"……我感觉得到。"</p>
<p>光慢慢闭上双眼，喃喃自语的说道。她的声音依然沙哑。"
"……这是害怕、疲惫且虚弱之人的乐园……"</p>
<p>"……"</p>
<p>她吞下干燥的空气，张开双眼， 抓起一把沙子并起身，
大部分的沙子从她指缝间流出。</p>
<p>"我不知道该如何是好……"</p>
<p>光继续说道： "……把一切都再次交付给你，是正确的吗？""
"绝对……不是。"</p>
<p>"我……不想要这样…"</p>
<p>"我不想要这样……！"</p>
<p>—— "呃——！"</p>
<p>光突然弯腰抱住腹部， 用另一只手捂住嘴。她剧烈地颤抖着。</p>
<p>她的"抗拒"似乎足以让这世界再次感觉到她。
就在她恐惧的说不出话，双眼睁大时，她突然皱了一下眉头。
我也听到有个刺耳的噪音，突然穿过她的耳朵、她的头脑——</p>
<p>再次进入她的内心，但这已经不是低语了，几乎可说是震颤的怒吼。
一个沉静却有力的声音出现，说道：决定吧，说出你内心的想法。</p>
<p>"说出……我的……？"</p>
<p>因为…… ……光是一名受内心驱使的少女。
早在她生平第一次张开双眼前，她的内心便指引她至此。</p>
<p>是本能反应吗？这个"身体"记得一切是怎么发生的吗‥…？她之前是怎么样的人……？</p>
<p>哈…… 我其实并不在意。
只是……我觉得这很有趣又讽刺，这个新的心脏会在下一次跳动前就颠覆一切。</p>
<p>她呼吸急促，内心颤抖了整整一分钟， 最终得到一个清晰且坚定的答案：</p>
<p>"我要…推翻现状。"</p>
<p>"我必须带她回来。"</p>
<p>"这世界……一点都不合理！
你以为我会为此死去？还是以为我会让‘其他’人为之死去……！ ？ "</p>
<p>"我做不到！我不会这么做的！
不论我必须做什么，放弃什么……作为交换，这些我都愿意牺牲……！"</p>
<p>她手中牢牢的抓了一把泥土，接着甩出她的手并将其撒出去。</p>
<p>她宣布： "如果我的死亡可以改变这一切，那我愿意——！"</p>
<p>世界的心脏在跳动，而这心跳声让她完全的安静下来。
这世界从未放弃她，以后也不会。 这个声音再次布满她的体内——</p>
<p>而其中的情感和知识，进入了她的胸口，传达至她每个指尖。</p>
<p>它说道：你不能死。 你注定会活下去，而且这是你的选择。</p>
<p>这件事……光是明白的。 自责，内疚，使她眼中充满泪水。</p>
<p>在她哭出来之前，这世界的心脏又再次跳动。 Arcaea 说道：别死。 ——
只要让它结束就好。</p>
<p>……她的双唇紧闭。 她的泪水从眼角流出，滑落脸颊。 她点了点头。</p>
<p>心脏再次跳动…… 仿佛—— —— Arcaea 开始失去光芒。</p>
<p>这样做后，Arcaea 淹没了她，流入她的双手和内心。
她感到失落，几乎就要崩溃。</p>
<p>这段时间，记忆闪现在她眼前，但我知道……这些是被忽略的记忆。
她的双眼反而专注在你了无生气的遗体上。</p>
<p>我想她现在唯一知道的……就是"她该做什么。"</p>
<p>我可以感觉到自己被往下拉至那里……一直下沉，下沉……
下沉至你被杀害的地方。" …… 她……是否真的明白她舍弃的东西是什么？
她真的明白这里的"结束"是什么意思吗？</p>
<p>我不知道。 ……你也无从得知。</p>
<p>……事实上，如果她带我走，那……我还会记得每件事吗？我会明白吗？
不……或许不会。但是……她现在似乎对自己很有信心。</p>
<p>……</p>
<p>我会让她的内心成为之后任何事的灯塔。 ……我深信着。你也会，不是吗？
毕竟，你是对的…… 她们俩人……是完全不一样的。</p>
<p>……"对立"…… ……我现在要走了。 不过别担心。 我一定会把你带在身边。</p>
<p>天空再次落下，而土地依她的意愿上升。 为了死亡，也为了让对立重生。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/arcaea_story_cg/Story_Last1_epilogue_cg.jpg"
                      
                ></p>
<p>生命和灵魂不会真的被带进这个亡者的世界。
这里只有她们的形象以及回声……</p>
<p>首先， 光芒之女和纷争之女的灵魂……从来就不平凡。</p>
<p>没错，这世界不是为此而生。 确实，这个世界将因此支离破碎。
为了改写这一切，它愿意做任何事，或至少一试。</p>
<p>它需要黑衣女子的"第一灵魂"</p>
<p>以及可在她第二人格中找到的残片……"
而现在一个破碎的灵魂，呼唤着另一个完整的灵魂。
很快，这另一个灵魂便被强行带入这个苍白的世界。</p>
<p>一道旋风围绕在光的身边，
在阴影和光芒的激流中，划破了身边笼罩的现实。</p>
<p>Arcaea"记得"另一名少女，在光的指示之下，这些记忆以玻璃的形态瞬间赶到。
这些记忆看似突然出现。又或许说，它们一直都在。
……它们是否足够？这世界能否编织两个破碎的灵魂？</p>
<p>……这个世界会的。规则并不重要。光会做到的……
带着名为对立的少女拥有的记忆……
这些记忆的玻璃迅速出现，在整场风暴中发光。</p>
<p>过去有名少女曾备受煎熬的走过这些土地。 悲痛如影随形地跟着这名少女……
但她仍大步向前，想要拯救自己。</p>
<p>为了拯救自己，为了紧紧抓住自由。 她只盼望着：
有机会能有一个理由让她微笑。</p>
<p>为了打造一个更好的世界，这名少女曾挺身而出，
即使"更好"可能代表要让世界天翻地覆。</p>
<p>这些回忆在光的双眼中闪现， 让她更加无法专注在她侵占中的回忆。</p>
<p>另一名少女的眼泪，只有少许穿越了这场风暴，而她大部分的痛苦似乎都已被遗忘。</p>
<p>看起来是这样没错……但事实上，身为光芒的灵魂，仍然抗拒着那灵魂和她一样的残酷的真相，
光唯一能做的事，就是找到另一名少女最真挚的绝望，
即便只是其中短暂的瞬间——
而剩余的那些较长的时刻，则超出她的能力范围。</p>
<p>……不过，当知道那最真实的痛苦引导黑衣少女至何方后，光便不再难过，
也放弃寻找她怎么也找不到的，那个她们相遇的时刻。</p>
<p>由这一切产生出的对立……从未看过她所处的困境实际有多深，
但仍明白自己注定活在挣扎之中。</p>
<p>光产生了一股新的能量。地面喷发四柱光芒，是巨大的力量泉源。
这是世界要保护她，因为她所召唤的暗影之魂最终降临了。</p>
<p>这个灵魂靠近时，她几乎看不出来这是什么。在她前面漂浮并遮蔽天空的，
是一个与死亡相仿的东西：那是一个巨大又令人毛骨悚然的鬼魂形象。
这东西靠近时轻轻放慢了速度，随即便开始流入转动中的玻璃。</p>
<p>她完全明白这是怎么回事。她坚决的点了点头，引导灵魂至玻璃，让过程更加顺畅。
对立"之前"迷失的灵魂，成为了新身体来临时的生命精华。
而对立"之后"迷失的灵魂，则用于稳定躯壳的剩余部分。</p>
<p>光脚下的震动就快让人无法忍受。
她尽可能维持不动，并用双手不停引导这个新生命。
她听到雷鸣般的悲鸣，她感觉世界在痛苦中扭曲，但她依然紧紧抓住她的愿望。</p>
<p>她没有被吓到，并在心中重申了她的誓言。</p>
<p>她扭曲了世界的核心，这样做也将导致堕落之神的重生。
就这样最后，曾经绝对的规则被改写了。光发出坚定且沉静的命令后，
新的死亡便牢牢刺入至这个核心之中。</p>
<p>在光芒和暗影巨大的脉冲之下，Arcaea 开始迈向灭亡。</p>
<p>创造存在的愿望被推翻了。天空在头上迅速移动，而现实的余光从四面八方倾泻而下至她身上。
光将这打造出的灵魂推入至浮在半空中极度美艳的对立的身体时，
她的汗珠滴至眉间，但同时她也推动了整个世界——</p>
<p>她引导着大地的生命。</p>
<p>她抛弃了Arcaea。</p>
<p>在白天要结束之时，双胞胎少女看着云朵从上空快速飘过。</p>
<p>而在夜晚的天空之下，有一名贵族看着裂缝慢慢将大地分裂，
看着星星从空中逐渐落下。</p>
<p>有一名关心又在乎的少女，有一名四处游荡并探索的少女，有一名看顾并许下愿望的少女——</p>
<p>有一个愉悦的灵魂，有一个饥渴的灵魂，有一个有抱负的灵魂——</p>
<p>有一颗战争的心，有一颗歌唱的心——</p>
<p>——
在这世界上所有的活力都被带至一个遥远地方之时，她们也看见了尾声。</p>
<p>而很快地……</p>
<p>……光感觉这些活力，最后有几缕流入了她希望拯救的那名少女体内。
当这活力从光的双手中退去时，对立的形体开始飘落至地面， 同时……</p>
<p>……这名身穿白衣的少女也感觉到了，她自身也有一部分开始迷失在这股流动之中。</p>
<p>……但她一点都不担心。</p>
<p>当风声平息，Arcaea 上方的天空也回归平缓后……
她感到头晕目眩，并在可能跌倒前尽力站稳脚步。</p>
<p>她试着让自己冷静下来，并试图理解她究竟做了什么。 但是……她做不到。
她无法抗拒地专注在一件事情上：</p>
<p>对立活了吗？</p>
<p>——</p>
<p>尘土再次从天空飘落。</p>
<p>她确实记得……</p>
<p>……在最后，在最低点的时候……</p>
<p>没有人在那里，她闭上眼，眼泪开始留下。</p>
<p>她现在缓缓张开双眼……</p>
<p>……而那些回忆也离开了她。</p>
<p>光看见她额头有些动静。
这名白衣女子双手握拳放在嘴前，喉咙也深吸一口气。</p>
<p>就这一切的璀璨来说，她认为，真是太简单了——</p>
<p>太简单—— 这些微的希望和努力，能否实现她的愿望？</p>
<p>光对于这些想法摇摇头，她颤抖着向前。
对立的双眼张开，眨了一下，接着再次眯起。</p>
<p>光赶紧上前，跪下并抱着眼前这名少女。</p>
<p>"这……你……！？你这是——！？"</p>
<p>光紧紧抱住她，这是她一生中抱得最紧的一次， 而另一名少女则沉默不语。
然后，光开始啜泣。</p>
<p>她不顾自我地靠在另一个少女的肩膀上哭泣，
而那名少女回过头看着她，对这一切都感到难以置信。</p>
<p>……更多裂缝都已经在那片景色中被凿开。
过去从天空中不断倾泻的光芒，突然也变得黯淡许多。 这个世界……受损了。</p>
<p>而光的注意力仍放在有"什么"—— 有"谁"还在。
对立抬起一只手，轻轻地放在光颤抖的背上。
她们各自都不知道发生了什么事，在世界结束之时就这样安抚彼此。</p>
<p>"抱歉……我真的很抱歉……"</p>
<p>光不停地说着。" "……不论你做了什么，"</p>
<p>对立回应道： "你都做到了，不是吗？为何要道歉……？""
光缓缓移开身子，但仍抱着这名少女。
她的双眼跟鼻子都哭红了，强颜欢笑地注视着对立。</p>
<p>突然之间，光把脸埋进对立的胸口，而对立也轻轻地抱住她。
这一幕都安静了下来，黑衣少女就这样让白衣少女一直哭泣。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/arcaea_story_cg/Story_Last2_epilogue_cg.jpg"
                      
                ></p>
<p>—— 她们在灰色世界中启程。</p>
<p>对立牵着另一名少女的手带她向前走了一阵子，但没多久，
另一名少女就调整好脚步跟上。</p>
<p>她不记得发生在自己身上的悲剧，至少，不记得最糟糕的部分。</p>
<p>还有这些黑色碎片……这些碎片也不再对她感兴趣。</p>
<p>光的情况也一样。这些原本非常喜欢光的白色碎片，再也不在她身边舞动或亲近她。</p>
<p>一个已经失去部分黑暗，而另一个……而这世界……也持续失去光芒。 不过……
光那真诚的微笑，也不再需要玻璃的光芒。</p>
<p>少女们走到悬崖边。 她们小心地寻找充满被忘却的记忆并缓慢腐败的大地。
这大地将腐败。它将崩溃，褪色，并且瓦解为虚无。</p>
<p>她们站在那里，对此并不知情，她们仅"知道"彼此，
为此放弃了过去与回忆。</p>
<p>对立带着沉着而温暖的表情看着光——
这是她在另外一个生命中，只要可以就会露出的神情。
光看见了她的神情，回以最单纯自在的微笑。</p>
<p>"等着我们的是什么"……？ 什么可能都不重要了。</p>
<p>她们各自感到的"完整"……是不容动摇的。</p>
<p>而且…… 毫无疑问，光知道这场旅程已进入尾声。
未来的道路就在前方，新的旅程即将展开。</p>
<p>……她花了一段时间意识到自己是无法精准得知这趟旅程会带来什么的。
她永远无法得知未来会发生什么事。</p>
<p>她接受这个事实，并闭上双眼思考：
……对立之前是否知道，她走的每一步会将她带到哪？ 她只会一路向前。</p>
<p>……</p>
<p>如果你已选择生命，那便是选择了活下去。
活在这个世界。见证这个世界。体验它，并真切地接受这最后的每个当下。
有了这样的体悟，她选择去牢牢把握。</p>
<p>她睁开双眼，并且呼吸着空气。 前方蜿蜒的未知、身旁的少女、
没见过的脸庞、以及远方未知的地方……</p>
<p>她把这些放在心中最重要的位置。</p>
<p>她牵着对立的手。</p>
<p>因为她们将会继续前进。</p></div><div class="tab-pane" id="e-2"><p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/arcaea_story_cg/Story_E-1_epilogue_cg.jpg"
                      
                ></p>
<p>不久以前……</p>
<p>有个黑暗且寒冷的地方……</p>
<p>贫瘠空虚的土地上一片寂静；在乌云密布的天空之下，是全新的冰冷以及虚无。红花绿叶皆蒙上灰色，
而只剩生者的足迹，持续述说着他们曾经来过。白色此刻从天而降，掩盖了他们的足迹。落下的不是雪花，
只有灰烬。</p>
<p>冬日尚未来临，然一切皆已冰封。</p>
<p>在满是灰烬和冰霜的大地上，有一位跪着的少女，她抬起脖子，看着这片灰色中渗出的光芒。
她睁大双眼注视着。那光芒前的是一位天使，又或许是一位神。</p>
<p>她无家可归。双亲皆已过世，监护人也已过世，她同期的新任塑形者全都过世，
还有她那些总是看不起她的人民也已全部过世。她知道所剩下的一切只有手中的玻璃碎片，
这是她窗户的碎片。但仍或许还有机会——</p>
<p>她是特别的天选之人。</p>
<p>虽然年轻但知识渊博。</p>
<p>她必须一试。</p>
<p>如果她努力尝试，或许还有极小的机会……能够让时间回流，发动回击。</p>
<p>或者甚至让她自身成为某种"神"。</p>
<p>思考着她可以阻止这一切。 思考着她可以将每个人带回来。</p>
<p>这名少女看着手中的玻璃碎片，希望能拯救这个世界。</p>
<p>—— 但是……</p>
<p>……她做不到。</p>
<p>只靠她的意志并不能从虚无中制造力量。人可以想像得到的任何意志力她都具备，但这没有任何意义。</p>
<p>她明白这个真相后，开始哭泣。</p>
<p>神的意志更有意义。神的愿望是她和她的同类消失、坠落、化为尘土，而这个愿望很快就会被神亲手实现。</p>
<p>少女从她的倒影中看见自己的双眼，而那倒影因自己的泪水而变得扭曲。从那颤抖的下颚中，
她看见自己的悲痛，以及无力与痛苦。</p>
<p>一切都不重要。她一事无成，不论是现在还是过去。</p>
<p>当天使降临时，这名黑发少女始终低着头。天使靠近她时，祂举起了祂的手。</p>
<p>没多久，她就被带走了。</p>
<p>这个孩子的名字已被忘却。</p>
<p>而她死亡的原因……远远超出她的理解。</p>
<p>没有人会记得她的存在。</p>
<p>但当她死亡时，另一个愿望带她离去。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/arcaea_story_cg/Story_E-2_epilogue_cg.jpg"
                      
                ></p>
<p>—</p>
<p>这件事的不久以前……</p>
<p>有个黑暗但却温暖的地方……</p>
<p>黑暗是她造成的。那是在不同时光不同地点，另一位名字都被遗忘的少女。她拉起帘幕。
她锁上房门。把手下有一张椅子。她坐在床上，睁大双眼注视着。</p>
<p>她抱着膝盖。</p>
<p>只是注视着。</p>
<p>注视着虚空。</p>
<p>她被"自己"弄得不知所措。</p>
<p>脑中无穷无尽地拨放着一段回忆。她能从楼梯上看见景色，并且清楚听到她父母从远处传来的低语。</p>
<p>他们不是在说她的坏话，但仍是在讨论她的事。</p>
<p>她的父母并非不爱她。</p>
<p>她无法爱自己，同时她感到自己内心缺少了一样让她能够爱她父母的东西。</p>
<p>她仍可以从楼梯上方看见景色。但她感到一切都在拉住她，要她松开栏杆，并且飞奔至下方的大理石门厅。</p>
<p>但如果这样没用怎么办？</p>
<p>在那之后，这名少女回到了自己的房间，并且安静地将自己锁起来。</p>
<p>为什么她不能消失？ 为什么她不能走向虚无？ 为什么她会拥有这些想法？
为什么她的脑海会浮现这个？ 为什么她不能消失……？</p>
<p>她将指甲刺入她的小腿。</p>
<p>她张大双眼凝视，呼吸急促。</p>
<p>她希望可以逃离这一切。</p>
<p>白发少女是一个神。白发少女有麻烦了。</p>
<p>但这麻烦并非因为她是神，事实上她从来不知道自己的神性。</p>
<p>在她的内心，她许下一个阴郁的愿望，想受庇护，而愿望成真了：</p>
<p>"我要某个能够让我快乐的地方。"</p>
<p>—</p>
<p>黑发少女死去了，而一个愿望要她的灵魂离开。</p>
<p>在遥远的世界，在另一个现实，有一名更强大的少女许下了这个愿望。</p>
<p>白发少女的力量非常强大，强大到她的愿望能打造一个世界。</p>
<p>这个世界拥有一个没有意义的名字："Arcaea"。</p>
<p>Arcaea 是为了拯救亡者的庇护所。</p>
<p>虽然她许下愿望时还活着，但她仍然强烈感到"死亡"的感觉。</p>
<p>对此她完全没有想法；事实上，如果她试过，她就不会如此搞不清楚状况。
她只想从那里为自己得到一些东西。这是有可能的，真的，如果她知道那些被Arcaea
之网抓住的命运， 她就会发现自己做了一件很棒的事。</p>
<p>这个世界跨越时间和不同的现实，延伸至其他无数地方。</p>
<p>它是活的，虽然它没有想法，但这世界仍"许愿"与这些亡者分享生命。</p>
<p>在没有任何指示的情况下，这世界尽可能抓住任何与其"内心"对话的东西。</p>
<p>在介于真实的接缝中被打造出来的空间里，在点缀着柔软且遥远的紫色星光的黑暗中……</p>
<p>……许多灵魂被包覆其中，并被带往一个跨越黑暗，全新且闪耀的边界。</p>
<p>白色的世界……</p>
<p>从这里开始，这个世界给了每个灵魂一个无暇的复制体，并且释放他们。
它给了各个复制体一个温暖的归属，给了它们一个新的形体……</p>
<p>这个世界给了它们永恒，让它们能安全地观察并重温无穷无尽的生命。</p>
<p>但它无法真正拯救它的创造者……</p>
<p>它能够带来真实的灵魂，复制它们，并将这些灵魂带入新的身体中，然后释放，
不管前方等着它们的是什么……不过，"光"的灵魂，被固定回其第一个世界之中。她仍然活着。</p>
<p>……不会思考的 Arcaea 只会尽其所能强行复制那个灵魂。</p>
<p>很久以后，Arcaea
发现了一个灵魂，它从未见过如此悲惨的灵魂，可以与它母亲的灵魂相似……</p>
<p>奇怪的是，该灵魂也无法被妥善的保管。释放时，
这个灵魂不会像其他灵魂一样离开这个虚假世界的边界……
因此它也开始目睹着自己的复制品不幸于这个全新白色大地上诞生。</p>
<p>对立……在一座毁灭的塔中苏醒。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/arcaea_story_cg/Story_E-4_epilogue_cg.jpg"
                      
                ></p>
<p>—</p>
<p>随着时光流逝……</p>
<p>难以想像，被救回的其中一人曾震慑着一切……</p>
<p>但幸运的是，造成这一切的人回来了，很快这个世界也再次变得安全……</p>
<p>Arcaea 只是为了存在而生。 Arcaea
呼唤了它的创造者，而这名创造者注意到了这个呼唤。 就像Arcaea
创造了碎片的监视者，并请求监视者吞噬一切会瓦解其脆弱存在的异常……</p>
<p>因此现在，Arcaea 依然存在着。</p>
<p>它已经存在了超过一千年了。</p>
<p>沾染大地的红色鲜血被抹去了，留下纯洁、白色的大地。对立的身体被烧掉了……</p>
<p>温暖占据着一切。天空变得明亮。</p>
<p>珍珠般近乎无尽的景色再次聚集。</p>
<p>现在，这是一个毋庸置疑的美丽世界……</p>
<p>散布各地的少女们选择在这个无尽旅程大地中停歇。她们选择被冰封，永远凝视着这迷失的世界。
如果她们还在思考……她们思考的会是非常遥远的过去。</p>
<p>而那肯定是更好的选择……</p>
<p>那肯定比较好，相比无尽地行走并观察其他地方……</p>
<p>她们一定很开心。她们需要变得开心。</p>
<p>Arcaea
除了那个选择没什么能够给她们。这个世界仍然埋藏在"缝隙之间"，而解脱方法也是——</p>
<p>——
而且……这世界以外的任何领域……是在外部的另一个地方，且无法再次看见。</p>
<p>因此，双胞胎少女、带着利剑的少女、旅行者、贵族、歌之少女……</p>
<p>她们和其他人善良到如同天使一般。</p>
<p>而 Arcaea
的玻璃碎片现在也经常休止。它们沿着墙壁和柱子集结，压实成又大又多的样子，就像结晶一样。</p>
<p>就像生锈了一样。</p>
<p>——
这个美丽的世界是由神所看护的。光在这一切之上，毫不关心地看照着……</p>
<p>……并且记得……</p>
<p>她记得所有旧世界已经遗忘的事。她有点热情，或着是有点兴趣的看着它们。
这可称得上是那位衰弱且无精打采的神所拥有的一种放纵。</p>
<p>或许……她已经不一样了。她过去是怎样的人，现在的她又是怎样……她现在层次一定"更高"了。</p>
<p>她珍惜着一个真相，对此她只能祈祷其他人能理解—— 虽然即使他们不能……
她也只不过选择了去看着这世界。</p>
<p>但……即便她毫不关心地看着这世界，她也知道自己给了它们"一切"。</p>
<p>……</p>
<p>……在她的范围之外，一名哲学家和卫星在游荡。</p>
<p>在此之下，一个长角的女人正照料着珍贵的回忆。</p>
<p>眼中有花朵的女人……在寂静的大地上跋涉。</p>
<p>这是空虚的，是没有意义的。</p>
<p>Arcaea 现在成为了虚无。</p>
<p>而那样……比另外一种型态还好。</p>
<p>好过一个藐视你的世界。好过那个瞧不起你生存方式的自己。</p>
<p>为爱上活着而活，并臣服在虚无之下……</p>
<p>……现实在其所有的面向中，是个空虚、一文不值且微不足道的事情。一个人想要的唯一一件事情，
就是夺走现实中可以拿走的任何东西。</p>
<p>夺走快乐。夺走爱。夺走希望。夺走力量。</p>
<p>而夺走之后……</p>
<p>……</p>
<p>光相信，什么都不需要做。</p>
<p>夺走。活着。然后真正地爱着活着本身。</p>
<p>爱着它……</p>
<p>虽然在千年之间，甚至千年之后……生命都不会有所意义。</p>
<p>毕竟，现实前进时，没人知道等待着的"结束"是什么样子。 而
Arcaea，具体来说，从来就只是记忆的载体。</p>
<p>无形、限制、沉默的记忆—— 然而外面看不见，注意不到，也不会在乎。</p>
<p>而这些记忆，与光所拯救的那些生命，将沉静地永存在此，而至于那些生命，
她也如往常一样不会看过去一眼。</p>
<p>因为在这里，没有看不到的记忆，没有感觉不到的情感。这就是光芒照耀，
且授予的"一切"。</p>
<p>为了永远的快乐，为了永远的平安。与你可能已经抛弃的任何生命不同，
这，就是她所爱。这，就是Arcaea ——</p>
<p>—— 迷失的生命不会受到偏袒，也不会受到责备。</p>
<p>因此，就像这样，命运的齿轮在这里继续运转……</p>
<p>……而远方不会再有等候着的命运。</p></div></div></div>
]]></content>
      <categories>
        <category>杂七杂八</category>
      </categories>
      <tags>
        <tag>Arcaea</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读笔记：Controlling Vision-Language Models for Multi-Task Image Restoration</title>
    <url>/2025/02/05/luoControllingVisionLanguageModels2024/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script>
  <div class="note p-4 mb-4 rounded-small blue">
    <p><a class="link"   href="https://arxiv.org/abs/2310.01018" >Paper<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a> <a class="link" 
 href="https://github.com/Algolzw/daclip-uir" >Repo<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>

  </div>
<h2 id="摘要">摘要</h2>
<p>视觉语言模型，如CLIP，在零样本或无标签预测的各种下游任务中显示出巨大的影响。然而，当涉及到低级视觉，如图像复原时，由于损坏的输入，它们的性能急剧恶化。在本文中，我们<b>提出了一种退化感知的视觉语言模型（DA-CLIP）</b>，以更好地将预训练的视觉语言模型迁移到低级视觉任务中，作为图像恢复的多任务框架。更具体地说，DA-CLIP训练一个额外的控制器，该控制器适应固定的CLIP图像编码器，以预测高质量的特征嵌入。通过将嵌入操作集成到一个基于交叉注意力的图像复原网络中，我们可以引导模型学习一个高保真的图像重建。<b>控制器自身也会输出一个与输入的真实退化特征相匹配的退化特征，从而产生一个针对不同退化类型的自然分类器。</b>此外，我们构建了一个带有合成字幕的混合退化数据集用于DA-CLIP训练。我们的方法在退化特定的和统一的图像复原任务上都取得了先进的性能，显示了使用大规模预训练的视觉语言模型来促进图像复原的一个很有前途的方向。</p>
<h2 id="引言">引言</h2>
<h3 id="研究背景和问题">研究背景和问题</h3>
<p>现有大规模视觉语言模型（VLM）在图像恢复（IR）等底层视觉任务中表现有限，主要原因在于：</p>
<ol type="1">
<li>特征对齐不足：VLM未有效区分退化类型（如模糊、噪声）的细粒度差异，导致图像特征与退化文本描述不匹配。</li>
<li>数据局限性：VLM通常基于网络规模数据集训练，而IR模型依赖小规模、任务特定的数据集，缺乏图像-文本对支持。</li>
</ol>
<p>传统IR方法仅关注逐像素生成，需针对不同退化类型重复训练模型；最近的工作集中在统一图像恢复上，在混合退化数据集上训练单个模型，并隐式地对恢复过程中的退化类型进行分类，但它们仍然局限于少数退化类型和与之相关的特定数据集。特别是，它们没有充分利用VLM的丰富知识。</p>
<h3 id="解决方法">解决方法</h3>
<p>作者提出了退化感知CLIP（DA-CLIP），将CLIP模型与IR网络结合，形成多任务框架，适用于退化特定与统一IR任务：
1. 图像控制器（Image Controller）： -
调整CLIP图像编码器，输出与纯净文本描述对齐的高质量（HQ）内容嵌入。 -
同时预测退化嵌入以匹配真实退化类型，解决退化输入与干净文本间的特征不匹配问题。
2.
知识融合：通过嵌入VLM的人类级知识，提升图像恢复性能并实现跨退化类型的统一恢复。</p>
<h3 id="数据构建和训练">数据构建和训练</h3>
<p>为了训练DA-CLIP从低质量（LQ）输入中学习高质量特征和退化类型，作者为十个不同的图像恢复任务构建了一个大型混合退化数据集。具体来说：
-
使用BLIP为所有HQ图像生成合成字幕，然后将LQ图像与字幕和相应的退化类型匹配为<b>图像-文本-退化</b>的三元组数据。
-
DA-CLIP可以准确地对十种不同的退化类型进行分类，并可以很容易地集成到现有的恢复模型中（即同时学习HQ特征和退化类型特征）</p>
<figure>
<figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/daclip/fig1.png"
                     
alt="本文利用大规模预训练的视觉语言模型进行多任务图像复原。与CLIP相比，该方法方法精确地预测了损坏输入的退化嵌入，并且还输出了高质量的特征以获得更好的图像恢复性能。对于以上所有例子，该单一统一模型都得到了正确的结果。" 
                ><figcaption>本文利用大规模预训练的视觉语言模型进行多任务图像复原。与CLIP相比，该方法方法精确地预测了损坏输入的退化嵌入，并且还输出了高质量的特征以获得更好的图像恢复性能。对于以上所有例子，该单一统一模型都得到了正确的结果。</figcaption></figure>
<figcaption
aria-hidden="true">本文利用大规模预训练的视觉语言模型进行多任务图像复原。与CLIP相比，该方法方法精确地预测了损坏输入的退化嵌入，并且还输出了高质量的特征以获得更好的图像恢复性能。对于以上所有例子，该单一统一模型都得到了正确的结果。</figcaption>
</figure>
<h3 id="主要贡献">主要贡献</h3>
<p>我们的主要贡献总结如下：</p>
<ol type="1">
<li>提出了DA-CLIP来利用大规模预训练的视觉语言模型作为图像恢复的通用框架。关键组件是图像控制器，它<u>预测退化</u>并适配<u>冻结的CLIP图像编码器</u>，以从损坏的输入中输出高质量的内容嵌入。</li>
<li>利用交叉注意力将内容嵌入融入复原网络，提高复原网络的性能。此外，我们引入了提示学习模块，以更好地<u>利用退化上下文进行统一的图像复原</u>。</li>
<li><u>构建了一个包含10种不同退化类型的高质量合成字幕的混合退化数据集。</u>该数据集既可以用来训练DA-CLIP，也可以用来训练统一的图像复原模型。</li>
<li>将DA-CLIP应用到图像复原模型中，分别应用于特异性退化和统一的图像复原任务，验证了DA-CLIP的有效性。该方法在所有十种退化类型中都取得了极具竞争力的性能。</li>
</ol>

  <div class="note-large blue">
    <div class="notel-title rounded-t-lg p-3 font-bold text-lg flex flex-row gap-2 items-center">
      <p>总结</p>

    </div>
    <div class="notel-content">
      <p>DA-CLIP通过融合VLM的语义知识与退化感知机制，解决了IR任务中特征对齐与多退化统一恢复的难题，为通用图像恢复提供了新思路。</p>

    </div>
  </div>
<h2 id="da-clip">DA-CLIP</h2>
<p><b>论文方法的核心是控制预训练的CLIP模型，以从损坏的图像中输出高质量的图像特征，同时预测退化类型。</b>如图2所示，图像内容嵌入<span
class="math inline">\(e_c^I\)</span>​与干净的标题嵌入​<span
class="math inline">\(e_c^T\)</span>相匹配。此外，由控制器预测的图像退化嵌入<span
class="math inline">\(e_d^I\)</span>指定输入的损坏类型，即来自文本编码器的相应退化嵌入<span
class="math inline">\(e_d^T\)</span>。然后可以将这些特征集成到其他图像恢复模型中，以提高它们的性能。</p>
<p>原本的CLIP是清晰图像匹配本文，但是现在输入的是损坏图像，这就会导致<u>潜在图像内容无法正确匹配GT文本</u>，这里用Image
Controller对CLIP的图像编码器微调，使之适应损坏图像。此外，CLIP的额外输入还有一个降质类型，这个是Image
Controller来额外预测的。</p>
<figure>
<figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/daclip/fig2.png"
                      alt="方法概述" 
                ><figcaption>方法概述</figcaption></figure>
<figcaption aria-hidden="true">方法概述</figcaption>
</figure>
<h3 id="image-controller">Image Controller</h3>
<p>图像控制器是CLIP图像编码器的副本，但使用一些零初始化连接进行包装，以向编码器添加控制。它操纵所有编码器块的输出以控制图像编码器的预测。在本文中，使用ViT作为编码器和控制器的默认主干。</p>
<p>图3(a)说明了控制过程，其中控制器的输出由两部分组成： 1.
图像退化嵌入<span class="math inline">\(e_d^I\)</span> 2. 隐藏控件<span
class="math inline">\(h_c\)</span>（包含来自transformer块的所有输出，这些输出随后被添加到相应的编码器块以控制它们的预测）</p>
<p>transformer块之间的连接是简单的密集神经网络，所有参数都初始化为零，这在训练过程中逐渐影响图像编码器。由于与VLM中使用的网络规模数据集相比，训练数据集很小，因此这种控制策略在保持原始图像编码器能力的同时减轻了过拟合。</p>
<figure>
<figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/daclip/fig3.png"
                      alt="模型结构" 
                ><figcaption>模型结构</figcaption></figure>
<figcaption aria-hidden="true">模型结构</figcaption>
</figure>
<p><strong>冻结预训练的CLIP模型的所有权重，只微调图像控制器。</strong>
为了使退化嵌入空间具有判别性和良好的分离性，使用对比目标来学习嵌入匹配过程。设<span
class="math inline">\(N\)</span>表示训练批中成对嵌入（来自文本编码器和图像编码器/控制器）的数量。对比损失定义为：</p>
<p><span class="math display">\[
\mathcal{L} _{\mathrm{con}}\left( \boldsymbol{x},\boldsymbol{y} \right)
=-\frac{1}{N}\sum_{i=1}^N{\log \left( \frac{\exp \left(
\boldsymbol{x}_{i}^{T}\boldsymbol{y}_i/\tau \right)}{\sum_{j=1}^N{\exp
\left( \boldsymbol{x}_{i}^{T}\boldsymbol{y}_j/\tau \right)}} \right)},
\]</span></p>
<p>然后为了优化内容和降质嵌入，使用以下共同目标： <span
class="math display">\[
\mathcal{L} _c\left( \omega \right) =\mathcal{L} _{\mathrm{con}}\left(
\boldsymbol{e}_{c}^{I},\boldsymbol{e}_{c}^{T};\omega \right)
+\mathcal{L} _{\mathrm{con}}\left(
\boldsymbol{e}_{d}^{I},\boldsymbol{e}_{d}^{T};\omega \right) ,
\]</span></p>
<p>这个损失函数的意思就是，先让CLIP的文本编码器对GT描述和降质类型编码得到<span
class="math inline">\(e_c^T\)</span>和<span
class="math inline">\(e_d^T\)</span>，然后图2中的输入LQ得到输出<span
class="math inline">\(e_c^I\)</span>和<span
class="math inline">\(e_d^I\)</span>。他们做对比学习进行对齐，就可以实验LQ输入匹配HQ的captions和types的编码。</p>
<h3 id="图像复原">图像复原</h3>
<p>使用IR-SDE作为图像恢复的基本框架。它采用了类似于DDPM的U-Net架构，但删除了所有自注意层。为了将纯净的内容嵌入注入扩散过程，作者引入了一种交叉注意力机制，从预先训练的VLM中学习语义指导。考虑到图像恢复任务中输入大小的变化以及将注意力应用于高分辨率特征的成本的增加，为了提高样本效率，只在U-Net的底部块中使用交叉注意力。</p>
<blockquote>
<p><figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/ir-sde/fig1.png"
                      alt="IR-SDE工作概述" 
                ><figcaption>IR-SDE工作概述</figcaption></figure>
简单介绍下IR-SDE，它是与该博客介绍的文章相同的作者提出的一个专用于复原的扩散模型，对于不同任务都需要从头训练一个特定的模型。主要思想和这篇文章一模一样，但是IR-SDE更早点。
这篇论文的介绍博客<a
href="/2025/02/06/luoImageRestorationMeanReverting2023">在这里</a></p>
</blockquote>
<p>另一方面，预测的退化嵌入对于统一图像恢复是有用的，其中目标是用单个模型处理多种退化类型的低质量图像。如图1所示，DA-CLIP准确地对不同数据集和各种退化类型的退化进行了分类，这对于统一的图像恢复至关重要。此外，为了利用这些退化嵌入，作者将它们与即时学习模块相结合，以进一步改进结果，如图3(b)所示。这里的prompt应该就是content
embedding。</p>
<p>通常，可以使用交叉注意力将内容嵌入集成到网络中，以提高它们在图像恢复任务上的性能。相比之下，结合退化嵌入的提示模块则专门针对统一图像复原背景下的退化类型分类进行改进。</p>
<h2 id="数据构成">数据构成</h2>
<p>使用BLIP通过高质量的图像，生成准确的、干净的文本，并与对应的退化图像、退化类型进行组合。</p>
<figure>
<figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/daclip/fig4.png"
                     
alt="利用BLIP生成图像-文本-退化的三元组数据的例子" 
                ><figcaption>利用BLIP生成图像-文本-退化的三元组数据的例子</figcaption></figure>
<figcaption
aria-hidden="true">利用BLIP生成图像-文本-退化的三元组数据的例子</figcaption>
</figure>
<figure>
<figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/daclip/tab1.png"
                      alt="数据构成" 
                ><figcaption>数据构成</figcaption></figure>
<figcaption aria-hidden="true">数据构成</figcaption>
</figure>
<h2 id="实验">实验</h2>
<p>本文提出的方法与现有方法在四个特定退化类型的数据集上进行图像修复的的定量比较与可视化呈现：</p>
<figure>
<figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/daclip/tab2.png"
                      alt="定量比较" 
                ><figcaption>定量比较</figcaption></figure>
<figcaption aria-hidden="true">定量比较</figcaption>
</figure>
<figure>
<figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/daclip/fig5.png"
                      alt="可视化呈现" 
                ><figcaption>可视化呈现</figcaption></figure>
<figcaption aria-hidden="true">可视化呈现</figcaption>
</figure>
<p>本文方法与现有方法进行统一的图像复原任务在若干指标上的对比。每个雷达图报告了一个特定指标的十种不同退化类型的结果。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/daclip/fig6.png"
                      
                ></p>
<p>训练曲线证明DA-CLIP的有效性：</p>
<figure>
<figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/daclip/fig9.png"
                      alt="训练曲线" 
                ><figcaption>训练曲线</figcaption></figure>
<figcaption aria-hidden="true">训练曲线</figcaption>
</figure>
<details class="blue" data-header-exclude><summary><i class="fa-solid fa-chevron-right"></i>指标介绍 </summary>
              <div class='content'>
              <div id="tab-指标介绍" class="tabs"><ul class="nav-tabs"><li class="tab active"><a class="#指标介绍-1">PSNR</a></li><li class="tab"><a class="#指标介绍-2">SSIM</a></li><li class="tab"><a class="#指标介绍-3">LPIPS</a></li><li class="tab"><a class="#指标介绍-4">FID</a></li></ul><div class="tab-content"><div id="指标介绍-1" class="tab-pane active"><p>峰值信噪比(dB)。其中<spanclass="math inline">(L)</span>表示图像数据类型最大动态范围<spanclass="math inline">([0,255])</span>，<spanclass="math inline">(MSE)</span>表示预测数据和原始数据的均方误差。PSNR越大说明评估结果越好。</p><p><span class="math display">[<span class="math display">\[\begin{aligned}    PSNR&amp;amp;=\displaystyle{10\log _{10}\frac{L^2}{MSE}}    \\    MSE&amp;amp;=\displaystyle{\frac{1}{mn}\sum_0^{m-1}{\sum_0^{n-1}{\left(f\left(i,j \right) -g\left( i,j \right) \right) ^2}}}\end{aligned}\]</span>]</span></p></div><div id="指标介绍-2" class="tab-pane"><p>PSNR在计算每个位置上的像素差异时，其结果仅与当前位置的两个像素值有关，与其它任何位置上的像素无关，忽略了图像内容所包含的一些视觉特征，特别是图像的局部结构信息。</p><p>SSIM计算两张图像在每个位置上的差异时，不是在该位置上从两张图中各取一个像素，而是各取了一个区域的像素。SSIM综合考虑了图像的亮度、对比度和结构，取值在<spanclass="math inline">([0,1])</span>之间，越大说明结果越好。</p><p><span class="math display">[ SSIM( x,y ) = ]</span></p><p><span class="math inline">(_x,_y)</span>分别是图像<spanclass="math inline">(x,y)</span>的均值，<spanclass="math inline">(_x^2,<em>y^2)</span>是方差，<spanclass="math inline">(</em>{xy})</span>是协方差。<spanclass="math inline">(C_1=(k_1L)<sup>2,C_2=(k_2L)</sup>2)</span>是稳定除法运算的小常数，<spanclass="math inline">(L)</span>是像素值动态范围。默认取<spanclass="math inline">(k_1=0.01,l_2=0.03)</span>。</p></div><div id="指标介绍-3" class="tab-pane"><p>通过训练一个神经网络学习图像块之间的差异，通常使用预训练的CNN作为特征提取器，然后训练一个额外的层预测图像对的相似性。取值范围<spanclass="math inline">([0,1])</span>，取值越小越好。</p></div><div id="指标介绍-4" class="tab-pane"><p>用于评估生成图像和真实图像在特征空间中的分布差异，量化二者的距离。取值越小表示生成图像与真实图像越相似。</p><p>首先用Inception网络将图像映射到高维特征向量，计算这两个特征向量的均值向量和协方差矩阵，最后综合计算距离：</p><p><span class="math display">[ d^2=| _1-<em>2 | </em>{2}^{2}+( _1+_2-2(_1_2 ) ^{} ) ]</span></p></div></div></div>
              </div>
            </details>
<h2 id="总结">总结</h2>
<p>本文提出DA-CLIP框架，利用大规模预训练视觉语言模型（VLM）构建通用图像恢复系统：</p>
<ul>
<li>核心机制：
<ul>
<li>退化嵌入预测：通过控制器从低质（LQ）图像中精准提取退化特征。</li>
<li>内容嵌入对齐：控制CLIP图像编码器输出与干净内容对齐的高质量（HQ）特征。</li>
</ul></li>
<li>训练数据：基于高质量图像生成合成文本描述，构建混合退化数据集。</li>
<li>下游应用：通过提示学习模块和交叉注意力机制，将DA-CLIP嵌入现有恢复模型。</li>
</ul>
<p>在退化特定与统一恢复任务中，DA-CLIP显著提升多种退化类型的恢复性能。但当前数据集难以处理<b>同一场景的混合退化问题</b>。未来计划开发更鲁棒的模型，适配真实拍摄场景，并实现多退化类型的完全恢复。</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>论文阅读</tag>
        <tag>图像修复</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读笔记：Image Restoration with Mean-Reverting Stochastic Differential Equations</title>
    <url>/2025/02/06/luoImageRestorationMeanReverting2023/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script>
  <div class="note p-4 mb-4 rounded-small blue">
    <p><a class="link"   href="https://arxiv.org/abs/2301.11699" >Paper<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a> <a class="link" 
 href="https://github.com/Algolzw/image-restoration-sde" >Repo<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>
参考：<a class="link" 
 href="https://zhuanlan.zhihu.com/p/602890737" >作者在知乎上的解读<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>

  </div>
<h2 id="摘要">摘要</h2>
<p>本文提出了一种用于通用图像复原的随机微分方程（SDE）方法： -
关键的构造包含一个均值回复的SDE，<u>它将高质量的图像转换为具有固定高斯噪声的均值状态的退化图像。</u>然后，通过模拟相应的逆时SDE，我们能够在不依赖任何特定任务的先验知识的情况下，恢复低质量图像的原点。
-
关键的是，所提出的均值回复SDE具有闭式解，允许我们计算真实值的时间依赖分数，并使用神经网络对其进行学习。
-
此外，我们提出了一个最大似然目标来学习一个最优的反向轨迹，从而稳定训练并改善恢复结果。实验表明，我们提出的方法在图像去雨、去模糊和去噪上的定量比较中取得了极具竞争力的性能，在两个去雨数据集上设置了新的最先进水平。</p>
<p>最后，通过图像超分辨率、修复和去雾的定性结果进一步证明了我们方法的普遍适用性。</p>
<h2 id="引言">引言</h2>
<p>扩散模型在各种图像生成任务中表现出令人印象深刻的性能，其基础是<b>对一个扩散过程进行建模，然后学习其反向的过程</b>。在常用的公式中，我们采用了由随机微分方程（SDE）定义的扩散模型。这就需要使用SDE将图像逐渐扩散到纯噪声分布，然后通过学习和模拟相应的反向时间SDE来生成样本。<b><u>其实质是训练一个神经网络来估计噪声数据分布的得分函数。</u></b></p>

  <div class="note p-4 mb-4 rounded-small blue">
    <p>图像复原是指从降质的低质量图像中恢复出高质量图像的总任务。常见的具体实例包括图像去雨、去模糊、去噪、超分辨率等。</p>

  </div>
<p>最近，扩散模型已经被应用到不同的图像恢复任务中。这些方法都采用了标准的前向过程，将图像扩散到纯噪声中。因此，反向(生成)过程用高方差的采样噪声初始化，这可能导致高质量图像的真实恢复效果不佳。大量实验表明，<u>扩散模型可以产生更好的感知分数，但在一些基于像素/结构的失真标准方面往往表现不尽人意。</u></p>
<p>为了解决这个问题，作者提出<b>使用均值回归SDE来解决图像复原问题</b>。如图1所示，这适应了前向过程，使其对图像退化本身进行建模，从高质量图像到低质量图像。通过模拟相应的逆时偏移，可以恢复出高质量的图像。<u>重要的是，不需要任务特定的先验知识来建模测试时刻的图像退化，只需要一组图像对用于训练。</u></p>
<figure>
<figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/ir-sde/fig1.png"
                      alt="过程概述" 
                ><figcaption>过程概述</figcaption></figure>
<figcaption aria-hidden="true">过程概述</figcaption>
</figure>
<p>主要贡献： 1.
提出了一种使用均值回归SDE的通用图像复原方法，该方法直接建模图像退化过程。该公式有一个封闭形式的解，使得我们能够计算真实时间依赖的得分函数，并训练一个神经网络来估计它。
2.
提出一个简单的替代损失函数来训练神经网络，基于最大化反向时间轨迹的可能性。与常见的分数匹配目标相比，该损失被证明能够稳定训练并一致地提高图像恢复性能。
3.
该方法不需要知道图像恢复任务的任何先验知识或参数设置，也不局限于线性退化或简单非线性退化，只需改变数据集即可用于任意任务，非常灵活（可应用于六种不同的图像复原任务：图像去雨、去模糊、去噪、超分辨率、修复和去雾，证明了我们提出的方法的普遍适用性）。
4.
该基于diffusion的方法在图像去雨、去模糊和去噪的定量比较中取得了极具竞争力的复原性能，在两个去雨数据集上开创了最新的研究水平。</p>
<h2 id="方法">方法</h2>
<p>该方法的关键思想是<u>将均值回归SDE与最大似然目标相结合用于神经网络训练</u>。我们将其称为<b>图像复原随机微分方程(IR-SDE)</b>。我们首先描述均值回归SDE的正向和反向过程，并采用先前描述的、基于分数的训练方法来估计这个SDE。然后，我们将其与我们提出的基于最大似然目标的损失函数进行描述和对比。</p>
<h3 id="用于图像退化的前向sde">用于图像退化的前向SDE</h3>
<p>考虑一种特殊的SDE：</p>
<p><span class="math display">\[
\mathrm{d}x=\theta _t\left( \mu -x \right) \mathrm{d}t+\sigma
_t\mathrm{d}w
\tag{1}
\]</span></p>
<p>其中<span class="math inline">\(\mu\)</span>是状态均值，<span
class="math inline">\(\theta_t\)</span>和<span
class="math inline">\(\sigma_t\)</span>是与时间相关的正参数，分别刻画了均值回复和随机波动的速度（这两个参数的选择会对恢复性能产生较大影响）。</p>
<p>一般情况下，<span class="math inline">\(\mu\)</span>和起始状态<span
class="math inline">\(x(0)\)</span>可以设置为任意一对不同的图像。然后，前向SDE将一幅图像传递给另一幅图像，作为一种噪声插值。为了进行图像退化，我们令<span
class="math inline">\(x(0)\)</span>和<span
class="math inline">\(\mu\)</span>分别为真实的高质量(HQ)图像和其退化的低质量(LQ)图像（见图1）。值得注意的是，虽然<span
class="math inline">\(\mu\)</span>依赖于<span
class="math inline">\(x(0)\)</span>（因为它们是同一对象或场景的配对HQ-LQ图像），但<span
class="math inline">\(x(0)\)</span>独立于布朗运动，因此SDE在Ito意义下仍然成立。</p>
<p>当<span class="math inline">\(t\to\infty\)</span>时，<span
class="math inline">\(x\)</span>均值收敛于低质量图像<span
class="math inline">\(\mu\)</span>，方差收敛于平稳方差<span
class="math inline">\(\lambda^2\)</span>。也就是说，前向SDE<span
class="math inline">\((1)\)</span>将高质量图像扩散为固定高斯噪声的低质量图像。</p>
<h3 id="用于图像修复的反向sde">用于图像修复的反向SDE</h3>
<p>将SDE<span
class="math inline">\((1)\)</span>逆变换得到一个图像恢复SDE(IR-SDE)，即
<span class="math display">\[
\mathrm{d}x=\left[ \theta _t\left( \mu -x \right) -\sigma _{t}^{2}\nabla
_x\log p_t\left( x \right) \right] \mathrm{d}t+\sigma
_t\mathrm{d}\hat{w}
\tag{2}
\]</span></p>
<p>与普通score估计的方式不同，这里提出的SDE是对score function <span
class="math inline">\(\nabla _x\log p_t\left( x
\right)\)</span>有确定解的。具体来说，令<span
class="math inline">\(\sigma_t^2/\theta
_t=2\lambda^2\)</span>，此时可以证明forward-SDE的解为：</p>
<p><span class="math display">\[
x\left( t \right) =\mu +\left( x\left( s \right) -\mu \right)
e^{-\bar{\theta}_{s:t}}+\int_s^t{\sigma
_ze^{-\bar{\theta}_{s:t}}\mathrm{d}w\left( z \right)}
\tag{3}
\]</span></p>
<p>其中<span class="math inline">\(\bar{\theta}_{s:t}=\int_{s}^{t}\theta
_z\mathrm{d}z\)</span>，其任意时刻<span class="math inline">\((s\to
t)\)</span>的转移概率为正态分布 <span class="math display">\[
p\left( x\left( t \right) |x\left( s \right) \right) =\mathcal{N} \left(
x\left( t \right) |m_{s:t}\left( x\left( s \right) \right) ,v_{s:t}
\right)
\tag{4}
\]</span></p>
<p>其中均值和方差分别为 <span class="math display">\[
\begin{aligned}
    m_{s:t}\left( x\left( s \right) \right) &amp;=\mu +\left( x\left( s
\right) -\mu \right) e^{-\bar{\theta}_{s:t}}\\
    v_{s:t}&amp;=\int_s^t{\sigma
_{z}^{2}e^{-2\bar{\theta}_{s:t}}\mathrm{d}z}=\lambda ^2\left(
1-e^{-2\bar{\theta}_{s:t}} \right)\\
\end{aligned}
\tag{5}
\]</span></p>
<p>在训练中，给定LQ和GT图像对，根据以上解可以算出正确的score为 <span
class="math display">\[
\nabla _{\boldsymbol{x}}\log p_t\left( \boldsymbol{x} \right)
=-\frac{\boldsymbol{x}\left( t \right) -m_t\left( \boldsymbol{x}
\right)}{v_t}
\tag{6}
\]</span></p>
<p>然后就可以通过网络来估计这个score。与score-matching之类的方法比，这里估计的score更加准确且是针对图像复原任务本身的（包含了降质退化过程）。</p>
<h3 id="基于最大似然的损失函数">基于最大似然的损失函数</h3>
<p>当应用于图像复原中遇到的复杂退化时，训练往往变得不稳定。这个困难可能源于试图学习给定时刻的瞬时噪声。因此，我们基于在给定高质量图像<span
class="math inline">\(x_0\)</span>的情况下，试图寻找最优轨迹<span
class="math inline">\(x_{1:T}\)</span>的思想，提出了一个备选的最大似然目标。<u>这个目标并不是为了学习一个更准确的得分函数而提出的。相反，它被用于稳定训练和恢复更准确的图像。</u></p>
<p>具体来说，我们希望最大化的可能性<span
class="math inline">\(p(x_{1:T}|x_0)\)</span>可以因式分解为 <span
class="math display">\[
p\left( x_{1:T}|x_0 \right) =p\left( x_T|x_0 \right)
\prod_{i=2}^T{p\left( x_{i-1}|x_i,x_0 \right)}
\tag{7}
\]</span></p>
<p>其中$p( x_T|x_0 ) = ( x_T;m_T( x_0 ) ,v_T ) <span
class="math inline">\(。反向过程则可以由贝叶斯法则推导出来：\)</span>$
p( x_{i-1}|x_i,x_0 ) = $$</p>
<p>由于所有的分布都是高斯分布，因此直接找到一个最优的反向状态使得负对数似然最小化来求解最优路径，即是求：
<span class="math display">\[
x_{i-1}^{*}=\mathrm{arg}\underset{x_{i-1}}{\min}\left[ -\log p\left(
x_{i-1}|x_i,x_0 \right) \right]
\tag{9}
\]</span></p>
<p>其中，令<span class="math inline">\(x_{i-1}^{*}\)</span>表示从<span
class="math inline">\(x_i\)</span>反转过来的理想状态。为了简化记号，我们令<span
class="math inline">\(\theta_i^\prime\coloneqq\int_{i-1}^{i}{\theta_t\mathrm{d}t}\)</span>。</p>
<p>因此，给定一个初始状态<span
class="math inline">\(x_0\)</span>，对于离散时间<span
class="math inline">\(i&gt;0\)</span>的任意状态<span
class="math inline">\(x_i\)</span>，式<span
class="math inline">\((9)\)</span>的最优反向解<span
class="math inline">\(x_{i-1}^*\)</span>为： <span
class="math display">\[
x_{i-1}^{*}=\frac{1-e^{-2\bar{\theta}_{i-1}}}{1-e^{-2\bar{\theta}_i}}e^{-\theta
_{i}^{\prime}}\left( x_i-\mu \right) +\frac{1-e^{-2\theta
_{i}^{\prime}}}{1-e^{-2\bar{\theta}_i}}e^{-\bar{\theta}_{i-1}}\left(
x_0-\mu \right) +\mu
\tag{10}
\]</span></p>
<p>随后就可以使用网络估计噪声并学习最优的复原步骤了。</p>
<p>这篇论文的公式推导很多，详情可以看论文原文的Appendix部分。</p>
<h2 id="实验">实验</h2>
<p>这一部分主要就是一些指标数据和可视化对比的呈现，具体的可以直接参阅论文。</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>论文阅读</tag>
        <tag>图像修复</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习基础：基于CNN网络进行图像分类</title>
    <url>/2025/02/20/attncnn-imgclassify/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="引言">引言</h2>
<p>图像分类任务是计算机视觉的核心问题之一，早在上世纪六十年代就已经开始发展。在深度学习技术出现之前，图像分类主要依赖人工设计特征，然后使用传统机器学习方法进行分类（如使用边缘检测等方法提取特征，然后使用SVM、KNN等分类器进行分类）。尽管这些方法在小规模数据集上取得了一定的成功，但它们的泛化能力很弱。并且特征提取需要大量专业领域知识，成本较高且不方便实行。</p>
<p>上世纪九十年代，神经网络开始进入研究者们的视野。但由于其计算资源消耗较大且模型可解释性弱，训练非常困难。1998年，由卷积层、池化层和全连接层组成的卷积神经网络（LeNet-5）出现，并在MNIST数据集上获得巨大的成功。</p>
<p>本文我们使用包含注意力层的卷积神经网络实现对CIFAR-10数据集的图像分类任务。</p>

  <div class="note p-4 mb-4 rounded-small blue">
    <p>关于注意力机制的讲解可以参考这篇博客：<a
href="/2025/02/19/AttentionAnalysis">注意力机制解析</a></p>

  </div>
<h2 id="cifar-10数据集"><a class="link" 
 href="https://www.cs.toronto.edu/~kriz/cifar.html" >CIFAR-10数据集<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></h2>
<p>CIFAR-10数据集共包含60,000张图片，每张图片是32*32的RGB图像。整个数据集分为包含50,000个样本的训练集和10,000个样本的测试集。每个样本对应一个标签，用于描述该图片包含的物体。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/attention_cnn/cifar10.png"
                      
                ></p>
<p>另外，还有一个与之非常类似的数据集CIFAR-100，共有100个类，每个类包含600个样本，其中500个样本作为训练图像，100个样本作为测试图像。100个子类被分为20个大类，每个图像有一个“fine”标签（所属的子类）和一个“coarse”标签（所属的大类）。</p>
<p>下面使用Pytorch对该任务进行代码实现。</p>
<h2 id="代码实现">代码实现</h2>
<h3 id="配置文件">配置文件</h3>
<p>对于一个项目来说，我们要力求做到一套代码可以适应不同的参数，即当我们希望修改参数时，不应该对代码本身做出修改。而所用到的参数就可以放在配置文件中，供程序直接从中调用。</p>
<p>常用的方式主要有两种：</p>
<ol type="1">
<li>使用<code>argparse</code>库设定不同形参，在外部的<code>sh</code>脚本文件编写好确定了参数的命令，再运行该脚本文件。</li>
<li>使用<code>yaml/yml</code>文件存储参数，程序使用<code>pyyaml</code>库进行调用。</li>
</ol>
<p>这里我们使用第2种方式。</p>
<p>在工作区创建<code>options.yml</code>文件，写入以下内容：</p>
<div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">train:</span></span><br><span class="line">  <span class="attr">data_root:</span> <span class="string">&#x27;./data&#x27;</span>           <span class="comment"># 数据集缓存位置</span></span><br><span class="line">  <span class="attr">n_epochs:</span> <span class="number">100</span>                 <span class="comment"># 训练周期数</span></span><br><span class="line">  <span class="attr">batch_size:</span> <span class="number">64</span>                </span><br><span class="line">  <span class="attr">lr:</span> <span class="number">0.001</span>                     <span class="comment"># 学习率</span></span><br><span class="line">  <span class="attr">resume:</span> <span class="literal">false</span>                 <span class="comment"># 是否从预训练的权重继续训练</span></span><br><span class="line">  <span class="attr">pretrained_path:</span> <span class="string">~</span>            <span class="comment"># 预训练权重的路径</span></span><br><span class="line">  <span class="attr">save_dir:</span> <span class="string">&#x27;./saved_model&#x27;</span>     <span class="comment"># 权重保存位置</span></span><br></pre></td></tr></table></figure></div>

  <div class="note-large yellow">
    <div class="notel-title rounded-t-lg p-3 font-bold text-lg flex flex-row gap-2 items-center">
      <p>注意</p>

    </div>
    <div class="notel-content">
      正常情况下，模型的训练与测试过程可以用下面这个流程图表示：
<pre class="mermaid">flowchart LR
    subgraph ds [Dataset]
    E[trainset]
    F[valset]
    G[testset]
    end
    A[Training] --> B[Validating]
    B --> C{epoch <= MAX_EPOCHS?}
    C -->|Yes| A
    C -->|No| D[Testing]

    E --> A
    F --> B
    G --> D</pre>
<p>在整个模型的训练（Training+Validating）过程中是不能有测试数据集的出现的。打个比方，模型是一位高中生，训练集是平时的作业，验证集是平时的模拟卷，测试集就是最终的高考卷。</p>

    </div>
  </div>
<h3 id="数据集下载和数据处理">数据集下载和数据处理</h3>
<p>新建文件<code>dataset.py</code>，写入以下内容： <div class="code-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torchvision.transforms <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">import</span> yaml</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;./options.yml&#x27;</span>, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    opt = yaml.safe_load(f)</span><br><span class="line"></span><br><span class="line">transform = transforms.Compose([</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">trainset = torchvision.datasets.CIFAR10(</span><br><span class="line">    root=opt[<span class="string">&#x27;train&#x27;</span>][<span class="string">&#x27;data_root&#x27;</span>],</span><br><span class="line">    train=<span class="literal">True</span>,</span><br><span class="line">    download=<span class="literal">True</span>,</span><br><span class="line">    transform=transform</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">testset = torchvision.datasets.CIFAR10(</span><br><span class="line">    root=opt[<span class="string">&#x27;test&#x27;</span>][<span class="string">&#x27;data_root&#x27;</span>],</span><br><span class="line">    train=<span class="literal">False</span>,</span><br><span class="line">    download=<span class="literal">True</span>,</span><br><span class="line">    transform=transform</span><br><span class="line">)</span><br></pre></td></tr></table></figure></div></p>
<p>该程序可以从配置文件中读取<code>train -&gt; dataroot</code>的路径，并将数据集下载到这个位置。<code>transform</code>的作用是对图像数据进行预处理（这里是转化为张量并对图像张量进行标准化）。</p>
<h3 id="模型结构">模型结构</h3>
<p>如果你希望保持该项目良好的延展性，未来开发了其他图像分类模型时可以方便地插入该工作区，可以先新建<code>modules</code>目录，并在其中新建文件<code>__init__.py</code>作为该工作区下的一个库。然后再在该目录中新建文件<code>attention_cnn.py</code>，在该文件中编写模型。</p>
<p>导入必要的库并实现注意力层的结构：</p>
<div class="code-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.utils</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SelfAttn</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_dim</span>):</span><br><span class="line">        <span class="built_in">super</span>(SelfAttn, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.query = nn.Conv2d(in_dim, in_dim // <span class="number">8</span>, kernel_size=<span class="number">1</span>)</span><br><span class="line">        <span class="variable language_">self</span>.key = nn.Conv2d(in_dim, in_dim // <span class="number">8</span>, kernel_size=<span class="number">1</span>)</span><br><span class="line">        <span class="variable language_">self</span>.value = nn.Conv2d(in_dim, in_dim, kernel_size=<span class="number">1</span>)</span><br><span class="line">        <span class="variable language_">self</span>.softmax = nn.Softmax(dim=-<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: torch.Tensor</span>):</span><br><span class="line">        B, C, H, W = x.size()</span><br><span class="line"></span><br><span class="line">        Q = <span class="variable language_">self</span>.query(x).view(B, -<span class="number">1</span>, H*W).permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>)  <span class="comment"># (B, H*W, C//8)</span></span><br><span class="line">        K = <span class="variable language_">self</span>.key(x).view(B, -<span class="number">1</span>, H*W)  <span class="comment"># (B, C//8, H*W)</span></span><br><span class="line">        V = <span class="variable language_">self</span>.value(x).view(B, -<span class="number">1</span>, H*W)  <span class="comment"># (B, C, H*W)</span></span><br><span class="line"></span><br><span class="line">        attention = <span class="variable language_">self</span>.softmax(torch.bmm(Q, K))  <span class="comment"># (B, H*W, H*W)</span></span><br><span class="line"></span><br><span class="line">        out = torch.bmm(V, attention.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>))  <span class="comment"># (B, C, H*W)</span></span><br><span class="line">        out = out.view(B, C, H, W)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> out + x</span><br></pre></td></tr></table></figure></div>
<ul>
<li><code>query</code>：1*1卷积层，可以将输入特征映射到一个低维空间（<code>C//8</code>），减少了计算量</li>
<li><code>key</code>：1*1卷积层，用于计算注意力分数</li>
<li><code>value</code>：1*1卷积层，将输入特征映射到新的特征空间</li>
<li>该层的前向传播<code>forward</code>函数用于计算输入图像<code>x</code>的自注意力分数矩阵，<code>out</code>诠释了特征图不同位置之间的相关性。残差连接（<code>out + x</code>）使得模型既可以学习注意力特征，又可以保留CNN提取的局部信息，避免信息的丢失。</li>
</ul>
<p>接着实现包含该注意力层的CNN结构： <div class="code-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">AttentionCNN</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_classes=<span class="number">10</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(AttentionCNN, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.conv1 = nn.Conv2d(<span class="number">3</span>, <span class="number">64</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        <span class="variable language_">self</span>.attn1 = SelfAttn(<span class="number">64</span>)</span><br><span class="line">        <span class="variable language_">self</span>.conv2 = nn.Conv2d(<span class="number">64</span>, <span class="number">128</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        <span class="variable language_">self</span>.attn2 = SelfAttn(<span class="number">128</span>)</span><br><span class="line">        <span class="variable language_">self</span>.conv3 = nn.Conv2d(<span class="number">128</span>, <span class="number">256</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        <span class="variable language_">self</span>.attn3 = SelfAttn(<span class="number">256</span>)</span><br><span class="line">        <span class="variable language_">self</span>.pool = nn.AdaptiveAvgPool2d((<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        <span class="variable language_">self</span>.fc = nn.Linear(<span class="number">256</span>, num_classes)</span><br><span class="line">        <span class="variable language_">self</span>.activate = torch.relu</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = <span class="variable language_">self</span>.activate(<span class="variable language_">self</span>.conv1(x))</span><br><span class="line">        x = <span class="variable language_">self</span>.attn1(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.activate(<span class="variable language_">self</span>.conv2(x))</span><br><span class="line">        x = <span class="variable language_">self</span>.attn2(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.activate(<span class="variable language_">self</span>.conv3(x))</span><br><span class="line">        x = <span class="variable language_">self</span>.attn3(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.pool(x).view(x.shape[<span class="number">0</span>], -<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.fc(x)</span><br></pre></td></tr></table></figure></div></p>
<p>在这个模块中，图像经过了三个【卷积+注意力】层，通道数不断增加（3
-&gt; 64 -&gt;
128），每个自注意力层计算图像各部分之间的注意力。池化层<code>self.pool = nn.AdapterAvgPool2d</code>将特征图压缩为<code>(B, 256, 1, 1)</code>的特征向量，并由<code>fc</code>全连接层将该向量映射到<code>num_classes</code>维度（这里为10），作为分类结果。</p>
<details class="blue" data-header-exclude><summary><i class="fa-solid fa-chevron-right"></i>网络结构图 </summary>
              <div class='content'>
              <p>（神经网络可视化绘图工具：<a class="link"  href="https://github.com/lutzroeder/Netron?tab=readme-ov-file" >Netron<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>）</p><p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/attention_cnn/networks.png"
                      
                ></p>
              </div>
            </details>
<h3 id="模型训练">模型训练</h3>
<p>新建<code>train.py</code>，先导入必要的库和配置文件中的参数：</p>
<div class="code-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.utils</span><br><span class="line"><span class="keyword">import</span> torch.utils.data</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> modules.attention_cnn <span class="keyword">import</span> AttentionCNN</span><br><span class="line"><span class="keyword">from</span> dataset <span class="keyword">import</span> trainset</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> yaml</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line">now = datetime.now()</span><br><span class="line">curr_time = now.strftime(<span class="string">&quot;%Y%m%d-%H%M%S&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tensorboardX <span class="keyword">import</span> SummaryWriter</span><br><span class="line">writer = SummaryWriter(log_dir=<span class="string">f&#x27;logs/tb_logger/<span class="subst">&#123;curr_time&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;options.yml&#x27;</span>, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    opt = yaml.safe_load(f)</span><br><span class="line"></span><br><span class="line">opt = opt[<span class="string">&#x27;train&#x27;</span>]</span><br><span class="line">EPOCHS = opt[<span class="string">&#x27;n_epochs&#x27;</span>]</span><br><span class="line">BATCH_SIZE = opt[<span class="string">&#x27;batch_size&#x27;</span>]</span><br><span class="line">LR = opt[<span class="string">&#x27;lr&#x27;</span>]</span><br><span class="line">SAVE_ROOT = opt[<span class="string">&#x27;save_dir&#x27;</span>]</span><br><span class="line"></span><br><span class="line">os.makedirs(os.path.join(SAVE_ROOT, curr_time))</span><br></pre></td></tr></table></figure></div>
<p>编写训练过程的主函数： <div class="code-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">model: AttentionCNN, trainloader: DataLoader, epochs, device</span>):</span><br><span class="line">    model.train()</span><br><span class="line">    <span class="keyword">global</span> step_num</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">        tic = time()</span><br><span class="line">        total_loss, correct, total_samples = <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> images, labels <span class="keyword">in</span> tqdm(trainloader, ncols=<span class="number">60</span>):</span><br><span class="line">            images, labels = images.to(device), labels.to(device)</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            outputs = model(images)</span><br><span class="line"></span><br><span class="line">            loss = criterion(outputs, labels)</span><br><span class="line">            loss.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line">            total_loss += loss.item()</span><br><span class="line"></span><br><span class="line">            correct += (outputs.argmax(<span class="number">1</span>)==labels).<span class="built_in">sum</span>().item()</span><br><span class="line">            total_samples += labels.size(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">            writer.add_scalar(<span class="string">&#x27;loss/steps&#x27;</span>, loss.item(), step_num)</span><br><span class="line">            step_num += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        toc = time()</span><br><span class="line">        train_acc = correct / total_samples</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;Epoch <span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>/<span class="subst">&#123;epochs&#125;</span> Loss: <span class="subst">&#123;total_loss / <span class="built_in">len</span>(trainloader): <span class="number">.4</span>f&#125;</span> Acc: <span class="subst">&#123;train_acc * <span class="number">100</span>: <span class="number">.2</span>f&#125;</span>% (cost <span class="subst">&#123;toc-tic: <span class="number">.1</span>f&#125;</span>s)&#x27;</span>)</span><br><span class="line">        writer.add_scalar(<span class="string">&#x27;loss/epochs&#x27;</span>, total_loss / <span class="built_in">len</span>(trainloader), epoch + <span class="number">1</span>)</span><br><span class="line">        writer.add_scalar(<span class="string">&#x27;acc/train&#x27;</span>, train_acc, epoch + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        torch.save(model.state_dict(), os.path.join(SAVE_ROOT, curr_time, <span class="string">f&#x27;epoch_<span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>.pth&#x27;</span>))</span><br></pre></td></tr></table></figure></div></p>
<p>在这里，<code>criterion</code>定义了模型使用的损失函数，<code>optimizer</code>是模型使用的优化器，决定了模型中参数的优化方式（如梯度下降、SGD等）。</p>
<details class="blue" data-header-exclude><summary><i class="fa-solid fa-chevron-right"></i>训练过程流程图 </summary>
              <div class='content'>
              <pre class="mermaid">flowchart BT    subgraph inputs        img[images]        l[labels]    end    subgraph model        optim[optimizer]        subgraph net[networks]            param[parameters]        end    end    out[outputs]    cr[criterion]    loss[loss]    result[[final results]]    img --> net --> out    out --> epoch{epoch <= MAX_EPOCHS?}    epoch -->|Yes| cr    epoch -->|No| result    l --> cr --> loss -->|"loss.backward()"| optim     optim -->|"optimizer.zero_grad()    optimizer.step()"| param</pre>
              </div>
            </details>
<p>添加以下部分之后就可以尝试运行了： <div class="code-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line">    trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    model = AttentionCNN(num_classes=<span class="number">10</span>).to(device)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> opt[<span class="string">&#x27;resume&#x27;</span>]:</span><br><span class="line">        <span class="keyword">if</span> os.path.exists(opt[<span class="string">&#x27;pretrained_path&#x27;</span>]):</span><br><span class="line">            model.load_state_dict(torch.load(opt[<span class="string">&#x27;pretrained_path&#x27;</span>]))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    criterion = nn.CrossEntropyLoss()</span><br><span class="line">    optimizer = torch.optim.Adam(model.parameters(), lr=LR)</span><br><span class="line"></span><br><span class="line">    main(model=model, trainloader=trainloader, epochs=EPOCHS, device=device)</span><br></pre></td></tr></table></figure></div></p>
<p>这个程序使用了tensorboard进行数据的可视化，我们可以方便地观察训练过程中模型准确率和损失的变化情况。<del class="mask">以后有时间的话打算写一期如何使用tensorboard，先挖个坑在这</del></p>
<figure>
<figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/attention_cnn/train_loss.png"
                     
alt="模型在100个训练周期内的损失变化情况" 
                ><figcaption>模型在100个训练周期内的损失变化情况</figcaption></figure>
<figcaption
aria-hidden="true">模型在100个训练周期内的损失变化情况</figcaption>
</figure>
<figure>
<figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/attention_cnn/train_acc.png"
                     
alt="模型在100个训练周期内的准确率变化情况（在训练集上）" 
                ><figcaption>模型在100个训练周期内的准确率变化情况（在训练集上）</figcaption></figure>
<figcaption
aria-hidden="true">模型在100个训练周期内的准确率变化情况（在训练集上）</figcaption>
</figure>
<p>从图上可以看出，模型的准确率和损失在训练过程中的变化还是相对平稳的，并且最后在训练集上的准确率基本稳定在了95%左右。</p>
<p>为了考察模型的泛化能力，接下来还要对模型进行测试。</p>
<h3 id="模型测试">模型测试</h3>
<p>在先前的配置文件<code>options.yml</code>中，添加以下内容：
<div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">test:</span></span><br><span class="line">  <span class="attr">data_root:</span> <span class="string">&#x27;./data&#x27;</span></span><br><span class="line">  <span class="attr">batch_size:</span> <span class="number">64</span></span><br><span class="line">  <span class="attr">load_path:</span> <span class="string">&#x27;/path/to/your/pretrained/weight&#x27;</span></span><br></pre></td></tr></table></figure></div></p>
<p>新建文件<code>test.py</code>，模型测试程序如下： <div class="code-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> modules.attention_cnn <span class="keyword">import</span> AttentionCNN</span><br><span class="line"><span class="keyword">from</span> dataset <span class="keyword">import</span> testset</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> yaml</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;options.yml&#x27;</span>, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    opt = yaml.safe_load(f)</span><br><span class="line"></span><br><span class="line">opt = opt[<span class="string">&#x27;test&#x27;</span>]</span><br><span class="line">BATCH_SIZE = opt[<span class="string">&#x27;batch_size&#x27;</span>]</span><br><span class="line">LOAD_PATH = opt[<span class="string">&#x27;load_path&#x27;</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>(<span class="params">model: AttentionCNN, testloader: DataLoader, device</span>):</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> images, labels <span class="keyword">in</span> testloader:</span><br><span class="line">            images, labels = images.to(device), labels.to(device)</span><br><span class="line">            outputs = model(images)</span><br><span class="line">            correct += (outputs.argmax(<span class="number">1</span>)==labels).<span class="built_in">sum</span>().item()</span><br><span class="line">    acc = correct / <span class="built_in">len</span>(testset)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;Acc: <span class="subst">&#123;acc: <span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> acc</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line">    testloader = DataLoader(testset, batch_size=BATCH_SIZE, shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    model = AttentionCNN(num_classes=<span class="number">10</span>).to(device)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">assert</span> os.path.exists(LOAD_PATH), <span class="string">&#x27;Invalid load path.&#x27;</span></span><br><span class="line">    model.load_state_dict(torch.load(LOAD_PATH))</span><br><span class="line"></span><br><span class="line">    main(model=model, testloader=testloader, device=device)</span><br></pre></td></tr></table></figure></div></p>
<p>这样，在配置文件中设置一个存放模型权重的路径，程序就可以在控制台输出模型在测试集上的准确率了。由于我们先前的训练程序将模型在每个周期上的权重都保存了下来，我们对程序稍作修改就可以在tensorboard上输出模型在测试集上的准确率随训练周期的变化情况。（这部分改动我就不写了，感兴趣的读者可以自己尝试实现一下。从训练程序中应该可以看出来tensorboard的使用并不难）</p>
<figure>
<figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/attention_cnn/test_acc.png"
                     
alt="模型在100个训练周期内的准确率变化情况（在测试集上）" 
                ><figcaption>模型在100个训练周期内的准确率变化情况（在测试集上）</figcaption></figure>
<figcaption
aria-hidden="true">模型在100个训练周期内的准确率变化情况（在测试集上）</figcaption>
</figure>
<p>模型在测试集上的表现似乎只能用差强人意来形容。模型在第20个训练周期左右时准确率已经达到最高水平（72%左右），之后略微出现下降，最后在70%附近振荡，在其中一处甚至出现了严重的退化（Epoch
71, Acc
0.6530）。可见，模型在训练了20个周期之后就出现了<b>过拟合</b>的现象。</p>
<p>在实际的模型训练任务中，需要将数据集划分为训练集、验证集和测试集，并在每个训练周期结束时使用验证集监测模型的泛化能力变化情况。这有助于我们监测模型是否发生过拟合等情况，并作出相应的调整。本文的模型并未引入验证流程。</p>
<p>但需要注意的是，<b>测试集是不可以当作验证集使用的。</b>规范的训练流程中，模型面对测试集如同高三考生面对高考，是只能见一次的。根据模型在测试集上的表现而有针对地改变训练策略，实际上是一种作弊。<del class="mask">但事实上很多论文为了刷指标都这么搞……懂得都懂</del></p>
<h2 id="结语">结语</h2>
<p>在入门深度学习的过程中，如果想复现其他人的小项目的话建议把代码跟着手敲一遍，在敲的过程中可能会遇到很多不理解的问题，但起码不会漏掉很多问题，毕竟总有一条它们还是会再找上来，并且在需要独立实现项目的情况下变得更加棘手。<del class="mask">（也算是个人的一点点小体会，我也是努力入门中T^T）</del></p>
]]></content>
      <categories>
        <category>实践记录</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>经验分享</tag>
      </tags>
  </entry>
  <entry>
    <title>UNet结构介绍</title>
    <url>/2025/02/17/unet/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="引言">引言</h2>
<p>UNet实际上是一种比较老的架构，最初于2015年的论文<a class="link" 
 href="https://arxiv.org/abs/1505.04597" >U-Net: Convolutional Networks
for Biomedical Image
Segmentation<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>中提出，主要用于医学图像分割。但近年来随着AIGC的兴起，UNet也逐渐被用于其他领域，如图像生成、图像修复等。Unet的结构并不复杂，但效果不错。对于扩散模型来说，UNet结构几乎是标配，仅使用残差网络的效果远不及它。</p>
<p>下面对这个网络结构作简要介绍，并在后面给出Pytorch实现。</p>
<h2 id="unet结构">UNet结构</h2>
<figure>
<figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/unet/architecture.png"
                      alt="网络结构示意图" 
                ><figcaption>网络结构示意图</figcaption></figure>
<figcaption aria-hidden="true">网络结构示意图</figcaption>
</figure>
<p>UNet结构如上图所示，它的主体是一个Encoder-Decoder的结构。其中，编码器由多个下采样层组成，解码器由多个上采样层组成。编码器和解码器之间通过跳跃连接连接，以保留更多的特征信息。因其结构类似于字母U，故得名UNet。除此之外，它的最大的特点来自于其跳层连接（copy
and crop）。</p>
<ul>
<li><code>conv 3x3, ReLU</code>
卷积层，卷积核大小为3x3，激活函数为ReLU。</li>
<li><code>max pool 2x2</code> 最大池化层，池化核大小为2x2。</li>
<li><code>up-conv 2x2</code>
这里是用于图像<b>上采样</b>的反卷积层，卷积核大小为2x2。</li>
<li><code>conv 1x1</code>
1*1的卷积层，可以调整通道数而不改变图像尺寸。</li>
</ul>
<h2 id="pytorch实现">Pytorch实现</h2>
<p>本文对UNet结构进行简要的代码实现。（叠甲：写的比较简陋，图像尺寸设的不好可能还会出现报错。此外，该网络可以结合时间步编码和注意力机制等，这里暂未体现。）</p>
<p>首先导入必要的库：</p>
<div class="code-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br></pre></td></tr></table></figure></div>
<p>UNet类的初始化：</p>
<div class="code-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">UNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, out_channels, device, layers=<span class="number">4</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(UNet, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.layers = layers</span><br><span class="line">        <span class="variable language_">self</span>.device = device</span><br><span class="line">        <span class="variable language_">self</span>.to_be_cropped_list = []</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.input_encoder = nn.Conv2d(in_channels, <span class="number">64</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">        <span class="variable language_">self</span>.output_decoder = nn.Conv2d(<span class="number">64</span>, out_channels, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.downs = nn.ModuleList([])</span><br><span class="line">        <span class="variable language_">self</span>.ups = nn.ModuleList([])</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(layers):</span><br><span class="line">            <span class="variable language_">self</span>.downs.append(nn.Sequential(</span><br><span class="line">                nn.Conv2d(<span class="number">64</span> * (<span class="number">2</span> ** i), <span class="number">64</span> * (<span class="number">2</span> ** (i + <span class="number">1</span>)), kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>),</span><br><span class="line">                nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">                nn.Conv2d(<span class="number">64</span> * (<span class="number">2</span> ** (i + <span class="number">1</span>)), <span class="number">64</span> * (<span class="number">2</span> ** (i + <span class="number">1</span>)), kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>),</span><br><span class="line">                nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            ))</span><br><span class="line">            <span class="variable language_">self</span>.ups.insert(<span class="number">0</span>, nn.Sequential(</span><br><span class="line">                nn.Conv2d(<span class="number">64</span> * (<span class="number">2</span> ** (i + <span class="number">1</span>)), <span class="number">64</span> * (<span class="number">2</span> ** i), kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>),</span><br><span class="line">                nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">                nn.Conv2d(<span class="number">64</span> * (<span class="number">2</span> ** i), <span class="number">64</span> * (<span class="number">2</span> ** i), kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>),</span><br><span class="line">                nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            ))</span><br></pre></td></tr></table></figure></div>
<p>参数： - <code>in_channels</code>：输入通道数 -
<code>out_channels</code>：输出通道数 -
<code>device</code>：设备（cpu或cuda） -
<code>layers</code>：UNet的层数</p>
<p><code>input_encoder</code>和<code>output_decoder</code>用于改变图像的通道数，而<code>downs</code>和<code>ups</code>分别对应模型主体的编码器和解码器。这里为了方便，使用循环将编码器和解码器的采样层使用<code>ModuleList</code>存储，并且每轮循环（每层）对称地加入采样层。</p>
<p>注意到在这段代码中，我们并没有将池化和反卷积（即<b>改变图像尺寸大小</b>）的操作加入到<code>downs</code>和<code>ups</code>中，而是只有卷积的<b>改变图像通道数</b>的操作。这是因为该网络还需要实现“跳层连接”，即需要将最大池化之前的张量经过裁剪之后和上采样之后的张量进行拼接。如果将池化和反卷积的操作放在<code>Sequential</code>里面，拼接操作所需要的张量无法提取出来。</p>
<p>（事实上代码的写法可以改进，比如将上采样层和下采样层分别封装成类<code>UpBlock</code>和<code>DownBlock</code>，这样可以将反卷积和池化操作包含其中，并提取出跳层连接所需的张量。但是我懒得改了QAQ）</p>
<p>还有一个小细节是，原论文中的卷积操作是将<code>padding</code>设为0了的，这样每次卷积会使得图像尺寸发生改变。我个人更倾向于设置<code>padding</code>使得图像尺寸不发生改变，这样在拼接操作时不会出现尺寸不匹配的问题。<del class="mask">（其实是因为<code>padding</code>设为0会在拼接时发生报错，两个张量的通道数会相差1。这个问题暂时还没有修正，充分体现出作者的代码能力亟待提高。哭……）</del></p>
<p>将在图像编码过程中提取的张量经过裁剪操作后与解码过程中对应的张量拼接，其中的裁剪操作实现如下：</p>
<div class="code-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">crop_tensor</span>(<span class="params">self, x: torch.Tensor, target: torch.Tensor</span>) -&gt; torch.Tensor:</span><br><span class="line">    target_size = target.shape[<span class="number">2</span>]</span><br><span class="line">    x_size = x.shape[<span class="number">2</span>]</span><br><span class="line">    delta = (x_size - target_size) // <span class="number">2</span></span><br><span class="line">    <span class="keyword">return</span> x[:, :, delta:x_size - delta, delta:x_size - delta]</span><br></pre></td></tr></table></figure></div>
<p>注意：这个函数输入的两个张量的通道数最好为偶数，否则后续的张量拼接可能会因为通道数不匹配出现报错。因此输入的图像尺寸（张量[Batch_size,
Channels, Height, Width]中的后两个）最好为2的整数次幂。</p>
<p>图像编码和解码操作的实现如下：</p>
<div class="code-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">encode</span>(<span class="params">self, x: torch.Tensor</span>) -&gt; torch.Tensor:</span><br><span class="line">    <span class="keyword">for</span> idx, down <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="variable language_">self</span>.downs):</span><br><span class="line">        <span class="comment"># print(f&#x27;Down &#123;idx + 1&#125;.1\t&#x27;, x.shape)</span></span><br><span class="line">        x = down(x)  <span class="comment"># conv</span></span><br><span class="line">        <span class="comment"># print(f&#x27;Down &#123;idx + 1&#125;.2\t&#x27;, x.shape)</span></span><br><span class="line">        <span class="variable language_">self</span>.to_be_cropped_list.insert(<span class="number">0</span>, x) <span class="keyword">if</span> idx &lt; <span class="variable language_">self</span>.layers - <span class="number">1</span> <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">        x = nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)(x)</span><br><span class="line">        <span class="comment"># print(f&#x27;Down &#123;idx + 1&#125;.3\t&#x27;, x.shape) if not idx &lt; self.layers - 1 else None</span></span><br><span class="line">    <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">decode</span>(<span class="params">self, x: torch.Tensor</span>) -&gt; torch.Tensor:</span><br><span class="line">    <span class="keyword">for</span> idx, up <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="variable language_">self</span>.ups):</span><br><span class="line">        <span class="comment"># print(f&#x27;Up &#123;idx + 1&#125;.1\t\t&#x27;, x.shape)</span></span><br><span class="line">        conv_trans = nn.ConvTranspose2d(</span><br><span class="line">            <span class="number">64</span> * (<span class="number">2</span> ** (<span class="variable language_">self</span>.layers - idx)), </span><br><span class="line">            <span class="number">64</span> * (<span class="number">2</span> ** (<span class="variable language_">self</span>.layers - idx - <span class="number">1</span>)), </span><br><span class="line">            kernel_size=<span class="number">2</span>, </span><br><span class="line">            stride=<span class="number">2</span>, </span><br><span class="line">            padding=<span class="number">0</span></span><br><span class="line">        ).to(<span class="variable language_">self</span>.device)</span><br><span class="line">        x = conv_trans(x)</span><br><span class="line">        <span class="comment"># print(f&#x27;Up &#123;idx + 1&#125;.2\t\t&#x27;, x.shape)</span></span><br><span class="line">        cropped = <span class="variable language_">self</span>.crop_tensor(<span class="variable language_">self</span>.to_be_cropped_list[idx], x)</span><br><span class="line">        x = torch.cat([x, cropped], dim=<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># print(f&#x27;Up &#123;idx + 1&#125;.3\t\t&#x27;, x.shape)</span></span><br><span class="line">        x = up(x)  <span class="comment"># conv</span></span><br><span class="line">        <span class="comment"># print(f&#x27;Up &#123;idx + 1&#125;.4\t\t&#x27;, x.shape) if not idx &lt; self.layers - 1 else None</span></span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure></div>
<p>前向传播函数的实现如下：</p>
<div class="code-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: torch.Tensor</span>) -&gt; torch.Tensor:</span><br><span class="line">    <span class="comment"># print(&#x27;Input Size\t&#x27;, x.shape)</span></span><br><span class="line">    x = <span class="variable language_">self</span>.input_encoder(x)</span><br><span class="line">    <span class="variable language_">self</span>.to_be_cropped_list.insert(<span class="number">0</span>, x)</span><br><span class="line">    <span class="comment"># print(&#x27;Encoded Input\t&#x27;, x.shape)</span></span><br><span class="line">    x = <span class="variable language_">self</span>.encode(x)</span><br><span class="line">    x = <span class="variable language_">self</span>.decode(x)</span><br><span class="line">    x = <span class="variable language_">self</span>.output_decoder(x)</span><br><span class="line">    <span class="comment"># print(&#x27;Output Size\t&#x27;, x.shape)</span></span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure></div>
<p>主函数：</p>
<div class="code-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">    model = UNet(in_channels=<span class="number">1</span>, out_channels=<span class="number">1</span>, device=device, layers=<span class="number">4</span>).to(device)</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    H = <span class="number">512</span></span><br><span class="line">    W = <span class="number">512</span></span><br><span class="line">    input_tensor = torch.randn(<span class="number">1</span>, <span class="number">1</span>, H, W).to(device)</span><br><span class="line">    output_tensor = model.forward(input_tensor)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure></div>
<p>注意到这里的代码将打印张量维度的语句都注释掉了。运行这些语句可以方便地查看张量的维度变化情况（#处为本文中手动添加的注释）：</p>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">Input Size       torch.Size([1, 1, 512, 512])</span><br><span class="line">Encoded Input    torch.Size([1, 64, 512, 512])</span><br><span class="line">Down 1.1         torch.Size([1, 64, 512, 512])</span><br><span class="line"># conv</span><br><span class="line">Down 1.2         torch.Size([1, 128, 512, 512])</span><br><span class="line"># maxpool</span><br><span class="line">Down 2.1         torch.Size([1, 128, 256, 256])</span><br><span class="line"># conv</span><br><span class="line">Down 2.2         torch.Size([1, 256, 256, 256])</span><br><span class="line"># maxpool</span><br><span class="line">Down 3.1         torch.Size([1, 256, 128, 128])</span><br><span class="line"># conv</span><br><span class="line">Down 3.2         torch.Size([1, 512, 128, 128])</span><br><span class="line"># maxpool</span><br><span class="line">Down 4.1         torch.Size([1, 512, 64, 64])</span><br><span class="line"># conv</span><br><span class="line">Down 4.2         torch.Size([1, 1024, 64, 64])</span><br><span class="line"># maxpool</span><br><span class="line">Down 4.3         torch.Size([1, 1024, 32, 32])</span><br><span class="line">Up 1.1           torch.Size([1, 1024, 32, 32])</span><br><span class="line"># conv_trans</span><br><span class="line">Up 1.2           torch.Size([1, 512, 64, 64])</span><br><span class="line"># crop and cat</span><br><span class="line">Up 1.3           torch.Size([1, 1024, 64, 64])</span><br><span class="line"># conv</span><br><span class="line">Up 2.1           torch.Size([1, 512, 64, 64])</span><br><span class="line"># conv_trans</span><br><span class="line">Up 2.2           torch.Size([1, 256, 128, 128])</span><br><span class="line"># crop and cat</span><br><span class="line">Up 2.3           torch.Size([1, 512, 128, 128])</span><br><span class="line"># conv</span><br><span class="line">Up 3.1           torch.Size([1, 256, 128, 128])</span><br><span class="line"># conv_trans</span><br><span class="line">Up 3.2           torch.Size([1, 128, 256, 256])</span><br><span class="line"># crop and cat</span><br><span class="line">Up 3.3           torch.Size([1, 256, 256, 256])</span><br><span class="line"># conv</span><br><span class="line">Up 4.1           torch.Size([1, 128, 256, 256])</span><br><span class="line"># conv_trans</span><br><span class="line">Up 4.2           torch.Size([1, 64, 512, 512])</span><br><span class="line"># crop and cat</span><br><span class="line">Up 4.3           torch.Size([1, 128, 512, 512])</span><br><span class="line"># conv</span><br><span class="line">Up 4.4           torch.Size([1, 64, 512, 512])</span><br><span class="line">Output Size      torch.Size([1, 1, 512, 512])</span><br></pre></td></tr></table></figure></div>
<p>可以看到，在编码器部分，张量的尺寸逐渐减小，通道数逐渐增多；而在解码器部分，张量的尺寸逐渐增大，通道数逐渐减少。</p>

  <div class="note-large blue">
    <div class="notel-title rounded-t-lg p-3 font-bold text-lg flex flex-row gap-2 items-center">
      <p>参考博客</p>

    </div>
    <div class="notel-content">
      <ul>
<li><a class="link" 
 href="https://blog.csdn.net/knighthood2001/article/details/138075554" >Unet网络架构讲解（从零到一，逐行编写并重点讲解数据维度变化）
- CSDN<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link"   href="https://zhuanlan.zhihu.com/p/313283141" >图像分割必备知识点
| Unet详解 理论+ 代码 - 知乎<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
</ul>

    </div>
  </div>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>正则表达式介绍</title>
    <url>/2025/02/24/regular-expressions/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="什么是正则表达式">什么是正则表达式？</h2>
<p>学过编程的应该都知道正则表达式（regular
expressions）这个东西，使用它可以方便地从文本中筛选出所需格式的字符串。</p>
<p>举个例子，很多网站的注册界面都会要求用户输入邮箱，那么如何判定用户输入的字符串是合法的邮箱格式呢？可以使用如下的正则表达式进行判定：</p>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]&#123;2,&#125;$</span><br></pre></td></tr></table></figure></div>
<p>看起来还是很抽象的，但实际上把正则表达式中常用的语法搞清楚之后就一目了然了。</p>
<p>推荐一个用于测试和练习正则表达式的网站：https://regex101.com/</p>
<h2 id="语法">语法</h2>
<p>正则表达式主要依赖于元字符。这些元字符往往具有特殊的含义，组成了正则表达式的语义和筛选条件。下面对一些主要的元字符作介绍：</p>
<table>
<thead>
<tr>
<th>元字符</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>.</code></td>
<td>匹配除换行符外的任意单个字符</td>
</tr>
<tr>
<td><code>[]</code></td>
<td>可理解为一个字符集合，匹配方括号内的任意字符</td>
</tr>
<tr>
<td><code>[^ ]</code></td>
<td>否定的字符种类，匹配除了方括号里的任意字符</td>
</tr>
<tr>
<td><code>*</code></td>
<td>匹配<b>不小于0个重复的</b>在<code>*</code>号之前的字符</td>
</tr>
<tr>
<td><code>+</code></td>
<td>匹配<b>大于0个重复的</b>在<code>+</code>号之前的字符</td>
</tr>
<tr>
<td><code>?</code></td>
<td>标记在<code>?</code>号前的字符为可选字符</td>
</tr>
<tr>
<td><code>&#123;&#125;</code></td>
<td>通常作为量词使用，常用于限定一个或一组字符可以重复出现的次数</td>
</tr>
<tr>
<td><code>(xyz)</code></td>
<td>字符集，匹配与括号内相等的字符串</td>
</tr>
<tr>
<td><code>\|</code></td>
<td>或运算符，匹配该符号前<b>或</b>后的字符</td>
</tr>
<tr>
<td><code>\</code></td>
<td>转义字符，用于匹配保留的元字符</td>
</tr>
<tr>
<td><code>^</code></td>
<td>从开始行开始匹配</td>
</tr>
<tr>
<td><code>$</code></td>
<td>从末端开始匹配</td>
</tr>
</tbody>
</table>
<h3 id="基本匹配">基本匹配</h3>
<p>这是一种最简单的正则表达式，由一些字母和数字组合而成，匹配其本身组成的字符串。例如，<code>the</code>匹配字符串<code>the</code>。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/regular_expressions/base.png"
                      
                ></p>
<h3 id="点运算符-.">点运算符 <code>.</code></h3>
<p>最简单的元字符，可以匹配<b>除换行符外</b>的任意单个字符。例如对于正则表达式<code>.he</code>，它匹配任意一个字符后跟着<code>he</code>的字符串。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/regular_expressions/dot.png"
                      
                ></p>
<h3 id="字符集">字符集 <code>[]</code></h3>
<p>方括号用于指定一个字符集合，在方括号中使用连字符<code>-</code>指定字符集的范围。方括号内的字符集不关心顺序，类似于集合中元素的无序性。</p>
<p><img 

                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/regular_expressions/square_brackets.png"
                      
                ></p>
<h3 id="否定字符集">否定字符集 <code>^</code></h3>
<p>一般使用<code>^</code>表示一个字符串的开头，但用在字符集中的开头时，它表示该字符集是否定的，匹配该字符集<b>在所有字符的集合中的补集</b>。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/regular_expressions/negative.png"
                      
                ></p>
<h3 id="星号">星号 <code>*</code></h3>
<p>星号匹配在它之前的字符出现不小于0次的字符。例如，<code>[a-z]*</code>表示所有小写字母组成的子串。</p>
<p><img 

                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/regular_expressions/star_lowercase.png"
                      
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/regular_expressions/star_number.png"
                      
                ></p>

  <div class="note p-4 mb-4 rounded-small blue">
    <p><code>.</code>和<code>*</code>搭配可以匹配所有的字符（<code>.*</code>）</p>

  </div>
<h3 id="加号">加号 <code>+</code></h3>
<p>加号匹配在它之前的字符出现不小于<b>1次</b>的字符。例如<code>a.+\s</code>匹配以<code>a</code>开头、后面至少跟着一个字符并最终以空格结尾的子串。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/regular_expressions/plus.png"
                      
                ></p>
<h3 id="问号">问号 <code>?</code></h3>
<p>在<code>?</code>号前面的字符为可选，即出现0或1次。例如<code>t?he</code>匹配字符串<code>the</code>或<code>he</code>。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/regular_expressions/question_mark.png"
                      
                ></p>
<h3 id="花括号">花括号 <code>&#123;&#125;</code></h3>
<p>花括号在正则表达式中常用作量词，限定其前面的字符可以重复出现的次数，可以传入不多于两个的参数。</p>
<p>例如<code>a&#123;2,5&#125;</code>匹配连续出现次数在2和5之间的连续<code>a</code>串，<code>a&#123;2,&#125;</code>匹配连续出现次数不小于2的连续<code>a</code>串，<code>a&#123;,5&#125;</code>匹配连续出现次数不多于5的<code>a</code>串。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/regular_expressions/curly_braces.png"
                      
                ></p>
<h3 id="特征标群">特征标群 <code>()</code></h3>
<p>特征标群是一组写在小括号内的子模式，括号内的内容会被看作一个整体。例如<code>ab*</code>匹配<code>a</code>后连续出现不小于0个<code>b</code>的字符串，而<code>(ab)*</code>匹配连续出现不小于0个<code>ab</code>的字符串。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/regular_expressions/parentheses.png"
                      
                ></p>
<h3 id="或运算符">或运算符 <code>|</code></h3>
<p>或运算符<code>|</code>表示“或”的判断条件。如<code>(T|t)he|car</code>匹配<code>The</code>，<code>the</code>和<code>car</code>。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/regular_expressions/or.png"
                      
                ></p>
<h3 id="转义字符">转义字符 <code>\</code></h3>
<p>转义字符用于转码紧跟其后的特殊字符，例如以上提到的这些。如果想要在字符串中匹配这些字符需要在其前面加上<code>\</code>符号。例如<code>\.</code>用于匹配字符<code>.</code>。值得注意的是，如果再在后面添加问号，即<code>\.?</code>，表示该字符（<code>.</code>）是选择性匹配的。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/regular_expressions/escape.png"
                      
                ></p>
<h3 id="锚点-与">锚点 <code>^</code>与<code>$</code></h3>
<p>锚点<code>^</code>和<code>$</code>分别表示输入的字符串的开头和结尾。例如，<code>^(T|t)he</code>仅匹配在句首出现的<code>the</code>或<code>The</code>，而<code>(at)\.?$</code>仅匹配在句尾出现的<code>at.</code>或<code>at</code>。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/regular_expressions/beginning.png"
                      
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/regular_expressions/end.png"
                      
                ></p>
<h3 id="简写字符集">简写字符集</h3>
<p>正则表达式提供了一些常用的字符集简写：</p>
<table>
<thead>
<tr>
<th>简写</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>\w</code></td>
<td>匹配所有字母和数字，相当于<code>[a-zA-Z0-9_]</code></td>
</tr>
<tr>
<td><code>\W</code></td>
<td>匹配所有非字母数字，相当于<code>[^\w]</code></td>
</tr>
<tr>
<td><code>\d</code></td>
<td>匹配数字，相当于<code>[0-9]</code></td>
</tr>
<tr>
<td><code>\D</code></td>
<td>匹配非数字，相当于<code>[^\d]</code></td>
</tr>
<tr>
<td><code>\s</code></td>
<td>匹配空格字符</td>
</tr>
<tr>
<td><code>\S</code></td>
<td>匹配非空格字符</td>
</tr>
<tr>
<td><code>\f</code></td>
<td>匹配一个换页符</td>
</tr>
<tr>
<td><code>\n</code></td>
<td>匹配一个换行符</td>
</tr>
<tr>
<td><code>\r</code></td>
<td>匹配一个回车符</td>
</tr>
<tr>
<td><code>\t</code></td>
<td>匹配一个制表符</td>
</tr>
<tr>
<td><code>\v</code></td>
<td>匹配一个垂直制表符</td>
</tr>
<tr>
<td><code>\p</code></td>
<td>匹配CR/LF（相当于<code>\r\n</code>），用于匹配DOS行终止符</td>
</tr>
</tbody>
</table>
<h3 id="零宽度断言">零宽度断言</h3>
<p>包括<b>先行</b>断言和<b>后发</b>断言，匹配结果不包含该确定格式，仅作为约束条件。共包括四类：</p>
<table>
<thead>
<tr>
<th>符号</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>?=</code></td>
<td>正先行断言</td>
</tr>
<tr>
<td><code>?!</code></td>
<td>负先行断言</td>
</tr>
<tr>
<td><code>?&lt;=</code></td>
<td>正后发断言</td>
</tr>
<tr>
<td><code>?&lt;!</code></td>
<td>负后发断言</td>
</tr>
</tbody>
</table>
<p>看名称可能有点难理解，通俗点解释就是： -
“正/负”表示该断言用于判断存在某格式（正）还是排除某格式（负）； -
“先行/后发”表示该断言用于筛选其后跟随某格式（先行）还是其前跟随某格式（后发）。</p>
<p>下面作出更详细的解释：</p>
<ul>
<li>先行断言用于根据<b>第一部分表达式</b>之后<u>是否存在</u>断言定义的表达式进行筛选。
<ul>
<li>正先行断言表示第一部分表达式之后必须跟着<code>?=</code>定义的表达式。比如，<code>a(?=b)</code>匹配后面跟着<code>b</code>的<code>a</code>。如果<code>a</code>后面没有<code>b</code>则不会被匹配。被断言定义的表达式<code>b</code>不会被匹配。
<img 

                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/regular_expressions/positive_lookahead_assertion.png"
                      
                ></li>
<li>负先行断言<code>?!</code>则相反，简单理解为正先行断言的反例即可。
<img 

                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/regular_expressions/negative_lookahead_assertion.png"
                      
                ></li>
</ul></li>
<li>后发断言用于根据<b>第二部分表达式</b>之前<u>是否存在</u>断言定义的表达式进行筛选。
<ul>
<li>正后发断言表示第二部分表达式之前必须跟着<code>?&lt;=</code>定义的表达式。比如<code>(?&lt;=a)b</code>匹配前面有<code>a</code>的<code>b</code>。如果<code>b</code>前面没有<code>a</code>则不会被匹配。被断言定义的表达式<code>a</code>不会被匹配。
<img 

                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/regular_expressions/positive_lookbehind_assertion.png"
                      
                ></li>
<li>负后发断言<code>?&lt;!</code>则相反，简单理解为正后发断言的反例即可。
<img 

                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/regular_expressions/negative_lookbehind_assertion.png"
                      
                ></li>
</ul></li>
</ul>
<h3 id="模式修正符">模式修正符</h3>
<p>模式修正符也叫标志，可以用于修改表达式的搜索结果。这些标志可以任意组合使用，属于整个正则表达式的一部分。这里仅介绍三个最常用的模式修正符。</p>
<table>
<thead>
<tr>
<th>标志</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>g</code></td>
<td>全局搜索</td>
</tr>
<tr>
<td><code>i</code></td>
<td>忽略大小写</td>
</tr>
<tr>
<td><code>m</code></td>
<td>多行修饰符：锚点元字符<code>^</code>和<code>$</code>工作范围在每行的起始</td>
</tr>
</tbody>
</table>
<figure>
<figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/regular_expressions/patterns_flags.png"
                     
alt="可以在网站的右边修改模式修正符" 
                ><figcaption>可以在网站的右边修改模式修正符</figcaption></figure>
<figcaption
aria-hidden="true">可以在网站的右边修改模式修正符</figcaption>
</figure>
<ul>
<li><p>全局搜索<code>g</code>常用于执行一个全局的搜索匹配，即不仅仅返回第一个匹配的，而是返回全部的匹配结果。</p>
<p><img 

                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/regular_expressions/global_search.png"
                      
                ></p></li>
<li><p>忽略大小写标志<code>i</code>顾名思义，不再赘述。</p>
<p><img 

                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/regular_expressions/case_insensitive.png"
                      
                ></p></li>
<li><p>多行修饰符<code>m</code>可以使得锚点元字符<code>^</code>和<code>$</code>在输入字符串的每行的开头和结尾均生效。</p>
<p><img 

                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/regular_expressions/multiline.png"
                      
                ></p></li>
</ul>
<h3 id="贪婪匹配与惰性匹配">贪婪匹配与惰性匹配</h3>
<p>正则表达式默认采用<b>贪婪匹配</b>模式，在该模式下意味着会匹配<b>尽可能长的子串</b>。我们可以使用<code>?</code>将贪婪匹配模式转化为&lt;b&lt;惰性匹配</b>模式，该模式下会匹配尽可能短的子串。</p>
<p><img 

                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/regular_expressions/greedy_lazy_matching.png"
                      
                ></p>

  <div class="note-large blue">
    <div class="notel-title rounded-t-lg p-3 font-bold text-lg flex flex-row gap-2 items-center">
      <p>参考资料</p>

    </div>
    <div class="notel-content">
      <p><a class="link" 
 href="https://blog.csdn.net/LLLLQZ/article/details/118278287" >正则表达式学习笔记（超级详细！！！）|
有用的小知识 - CSDN博客<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a> <a class="link"   href="https://regex101.com/" >regular
expressions 101<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>

    </div>
  </div>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>编程</tag>
      </tags>
  </entry>
  <entry>
    <title>博客建立经验分享</title>
    <url>/2025/02/03/%E5%8D%9A%E5%AE%A2%E5%BB%BA%E7%AB%8B%E7%BB%8F%E9%AA%8C%E5%88%86%E4%BA%AB/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>过年这几天比较清闲，正好原先也有用博客记录一下学习过程的想法，因此着手研究了一番。与其编辑文章发到博客园或者CSDN，我感觉还是不如直接建立一个个人博客主页来得有意义。毕竟自己的博客可以自己装修，哪怕是看着自己精心打造的主页外观也令人心旷神怡不是。</p>
<p>最初本人并不了解Hexo框架，以为建立博客是需要自己花钱购买域名的（实际上这样也可以，但免费的总比花钱的香）。后来才偶然发现一个帖子介绍了Hexo，可以基于GitHub仓库建立博客主页，不仅不需要自己编写繁琐的前端代码还可以随心所欲更换主题外观。<del class="mask">最重要的是免费啊</del></p>
<p>实际操作体验下来，使用Hexo建立博客确实比较简便，最费时费力的其实是主题的挑选和页面配置。如果不打算更换主题什么的话，五分钟就可以建好博客开写了。</p>
<h2 id="环境准备">环境准备</h2>
<h3 id="node.js安装">Node.js安装</h3>
<p>Hexo是基于Node.js的，因此需要先安装它。安装过程非常简单，直接在<a class="link" 
 href="https://nodejs.org/en/download/" >官网<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>下载安装即可。安装完成后，打开cmd命令行输入<code>node -v</code>和<code>npm -v</code>，如果出现版本号则说明安装成功。</p>
<h3 id="git安装">Git安装</h3>
<p>如果是Windows系统，前往<a class="link" 
 href="https://git-scm.com/downloads/win" >官网<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>下载并安装git。安装完成后，打开cmd命令行输入<code>git --version</code>，出现版本号则说明安装成功。</p>
<p>（话说能看到这个贴子的应该已经使用过git了吧）</p>

  <div class="note-large blue">
    <div class="notel-title rounded-t-lg p-3 font-bold text-lg flex flex-row gap-2 items-center">
      <p>Linux操作系统的git安装</p>

    </div>
    <div class="notel-content">
      <p>Linux (Ubuntu, Debian): <code>sudo apt-get install git</code> Linux
(CentOS, Fedora): <code>sudo yum install git</code></p>

    </div>
  </div>
<figure>
<figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/nodejs_git_install.png"
                     
alt="成功安装Node.js和git的命令行" 
                ><figcaption>成功安装Node.js和git的命令行</figcaption></figure>
<figcaption aria-hidden="true">成功安装Node.js和git的命令行</figcaption>
</figure>
<h3 id="hexo安装">Hexo安装</h3>
<div class="code-container" data-rel="Cmd"><figure class="iseeu highlight cmd"><table><tr><td class="code"><pre><span class="line">npm install -g hexo-cli</span><br></pre></td></tr></table></figure></div>
<p>安装完成后，打开<strong>git
bash</strong>命令行输入<code>hexo -v</code>，出现版本号则说明安装成功。（注：若在cmd命令行输入这个指令可能会显示“无法加载文件，因为在此系统上禁止运行脚本”的报错）</p>
<!-- ![成功安装Hexo的命令行](/images/hexo_install.png) -->
<p>至此环境准备已经完成，接下来对博客的工作区进行初始化。</p>
<h2 id="博客站点初始化">博客站点初始化</h2>

  <div class="note p-4 mb-4 rounded-small blue 提示">
    <p>以下的命令行操作均在Git Bash中进行。</p>

  </div>
<p>选择一个合适的文件夹作为博客的工作区，在文件夹中打开git
bash命令行输入：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">hexo init</span><br></pre></td></tr></table></figure></div>
<p>注意该命令要在<strong>空文件夹</strong>下才可运行成功。然后输入：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">npm install</span><br></pre></td></tr></table></figure></div>
<p>此时Hexo站点就已经在本地安装完成。以下是站点中已经出现的主要目录和文件：</p>
<div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">.</span><br><span class="line">├── _config.yml             # 站点配置文件</span><br><span class="line">├── _config.landscape.yml   # 主题配置文件，默认主题为landscape</span><br><span class="line">├── package.json            # 项目配置文件</span><br><span class="line">├── package-lock.json</span><br><span class="line">├── node_modules            # 项目依赖包</span><br><span class="line">├── scaffolds               # 模板文件夹</span><br><span class="line">├── source                  # 资源文件夹，存放用户的博客文章和页面</span><br><span class="line">└── themes                  # 主题文件夹</span><br></pre></td></tr></table></figure></div>
<p>接下来生成页面静态文件：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">hexo generate</span><br><span class="line"><span class="comment"># hexo g</span></span><br></pre></td></tr></table></figure></div>
<p>此时站点中会生成一个public文件夹，里面存放的就是静态网页文件。</p>
<p>现在可以在本地启动服务器预览博客：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">hexo server</span><br><span class="line"><span class="comment"># hexo s</span></span><br></pre></td></tr></table></figure></div>
<p>访问<code>http://localhost:4000</code>即可看到博客的预览效果。</p>
<figure>
<figure class="image-caption"><img src="/images/posts/hexo_start.png"
alt="Hexo本地预览(http://localhost:4000)" /><figcaption>Hexo本地预览(http://localhost:4000)</figcaption></figure>
<figcaption
aria-hidden="true">Hexo本地预览(http://localhost:4000)</figcaption>
</figure>
<h2 id="github建站">GitHub建站</h2>
<h3 id="创建仓库并推送">创建仓库并推送</h3>
<p>在GitHub上创建一个仓库，仓库名称必须为<code>用户名.github.io</code>，否则无法访问。接着在本地的站点文件夹中安装hexo上传插件（这一步不能跳，否则出现<code>ERROR Deployer not found: git</code>的报错）：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">npm install hexo-deployer-git --save</span><br></pre></td></tr></table></figure></div>
<p>在站点目录的<code>_config.yml</code>文件中找到<code>deploy</code>模块添加以下内容：</p>
<div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Deployment</span></span><br><span class="line"><span class="comment">## Docs: https://hexo.io/docs/one-command-deployment</span></span><br><span class="line"><span class="attr">deploy:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">git</span></span><br><span class="line">  <span class="attr">repo:</span> <span class="string">https://github.com/username/username.github.io.git</span></span><br><span class="line"><span class="comment">#   branch: 仓库里用的哪个分支就写哪个，不一致比较麻烦</span></span><br><span class="line">  <span class="attr">branch:</span> <span class="string">main</span></span><br></pre></td></tr></table></figure></div>

  <div class="note-large red">
    <div class="notel-title rounded-t-lg p-3 font-bold text-lg flex flex-row gap-2 items-center">
      <p>踩雷提醒</p>

    </div>
    <div class="notel-content">
      <p>在<code>_config.yml</code>文件中找到<code>url</code>，将其改为：</p>
<div class="code-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># URL</span></span><br><span class="line"><span class="comment">## Set your site url here. For example, if you use GitHub Page, set url as &#x27;https://username.github.io/project&#x27;</span></span><br><span class="line"><span class="attr">url:</span> <span class="string">https://username.github.io</span></span><br></pre></td></tr></table></figure></div>
<p>注释里最后写的是project，但我们不要写，并且后面不需要再加上斜杠。原因是<code>hexo d</code>自动生成的文件存放在<code>.deploy_git</code>文件夹，而其中<code>index.html</code>可以视作<strong>网页本体</strong>，其加载文件的路径是<code>站点目录绝对路径/.deploy_git/...</code>。</p>
<blockquote>
<p>举个例子，我的站点目录为<code>D:/Hexo/blog</code>。我在某个地方引用了一张图片，使用的语句为<code>/images/img1.png</code>。则使用<code>hexo d</code>命令上传后，其中<code>index.html</code>获取图片资源的路径为<code>D:/Hexo/blog/.deploy_git/images/img1.png</code>。
如果后面加上了多余的东西（比如加了<code>/project</code>），则<code>index.html</code>获取图片资源的路径就变成了<code>D:/Hexo/blog/.deploy_git/project/images/img1.png</code>，就会发生路径错误。</p>
</blockquote>
<p>如果加上project或者其他，之后<u>本地预览调试网页的时候没有问题，但推送到GitHub后网页内容和主题会加载失败。</u></p>

    </div>
  </div>
<p>现在可以通过以下命令将博客推送到GitHub：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">hexo deploy</span><br><span class="line"><span class="comment"># hexo d</span></span><br></pre></td></tr></table></figure></div>

  <div class="note-large blue">
    <div class="notel-title rounded-t-lg p-3 font-bold text-lg flex flex-row gap-2 items-center">
      <p>提示</p>

    </div>
    <div class="notel-content">
      <p>从2021年8月14日开始，GitHub官方加强安全访问。<strong>不能通过原有账号密码git访问</strong>，密码需要用官方的token或者采用SSH公私钥访问。</p>
<p>如果之前没有为账号设置过SSH密钥，可以通过setting -&gt; Developer
settings -&gt; Personal access
tokens创建一个新的token，然后可以把它当密码输入。</p>
<p>SSH密钥的设置可以自行搜索相关教程，这个设置好了之后也很方便。</p>

    </div>
  </div>
<p>可以从仓库查看到文件的上传情况。以仓库名称作为域名访问即可成功查看到博客界面：<code>https://username.github.io</code>。</p>
<h2 id="创建与删除文章">创建与删除文章</h2>
<h3 id="创建文章">创建文章</h3>
<p>在站点目录下使用以下git bash命令创建文章：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">hexo new <span class="string">&quot;文章标题&quot;</span></span><br></pre></td></tr></table></figure></div>
<p>此时会在<code>./source/_posts</code>目录下生成一个<code>文章标题.md</code>的文件，打开文件后可以看到以下内容：</p>
<div class="code-container" data-rel="Markdown"><figure class="iseeu highlight markdown"><table><tr><td class="code"><pre><span class="line">---</span><br><span class="line">title: 文章标题</span><br><span class="line">date: 2021-08-14 16:03:12</span><br><span class="line"><span class="section">tags:</span></span><br><span class="line"><span class="section">---</span></span><br></pre></td></tr></table></figure></div>
<p>在<code>---</code>之间可以添加文章的属性，如<code>tags</code>、<code>categories</code>等。之后是文章的内容，可以使用markdown语法书写。</p>

  <div class="note p-4 mb-4 rounded-small blue 提示">
    <p>书写文章的markdown文件时不要使用一级标题，以二级标题（<code>##</code>）作为帖子内容的一级标题。帖子的标题在<code>title</code>属性中设置，视效等同于markdown的一级标题。</p>

  </div>
<p>对博客内容更新后，需要清楚缓存（实际上是删除原先的public目录）重新生成静态文件：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">hexo cl     <span class="comment"># 清除缓存</span></span><br><span class="line">hexo g      <span class="comment"># 生成静态文件</span></span><br><span class="line">hexo s      <span class="comment"># 启动本地服务器预览</span></span><br></pre></td></tr></table></figure></div>
<p>如果需要将文章写成草稿而不发布，可输入以下命令：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">hexo new draft <span class="string">&quot;文章标题&quot;</span></span><br></pre></td></tr></table></figure></div>
<p>此时文章会生成在<code>./source/_drafts</code>目录下。需要发布时使用以下命令：</p>
<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">hexo publish <span class="string">&quot;文章标题&quot;</span></span><br></pre></td></tr></table></figure></div>
<p>此时文章会移动到<code>./source/_posts</code>目录下。只有该目录下的文章会作为博客帖子显示在网页中。</p>
<h3 id="删除文章">删除文章</h3>
<p>删除文章可以直接删除<code>./source/_posts</code>目录下的<code>.md</code>文件。如果该文章先前已经推送到仓库，需要将<code>.deploy_git</code>目录删除（否则通过域名访问博客网站会发现文章还在），之后推送的时候会重新生成。</p>
<h2 id="更换主题">更换主题</h2>
<p>在GitHub搜索Hexo主题或前往<a class="link" 
 href="https://hexo.io/themes/" >hexo自带主题官网<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>中选择，不同主题的安装方式可能不同，具体可以参考其说明文档。</p>
<p>我选择的主题是<a class="link" 
 href="https://github.com/EvanNotFound/hexo-theme-redefine" >hexo-theme-redefine<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>，可前往<a class="link" 
 href="https://redefine.ohevan.com/" >展示页预览<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>效果。转了一圈感觉这个算是外观非常好看的那一档。<a class="link" 
 href="https://redefine-docs.ohevan.com/zh/introduction" >教程<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>在这里，写的也还算详细。</p>
<p>关于页面的配置等其他细节应该基本都和主题高度相关的了，这里就先不展开。</p>
<h2 id="其他的细节杂项坑">其他的细节杂项<del class="mask">（坑）</del></h2>
<ol type="1">
<li>博客的作者头像和标签页图标的更改
在<code>./node_modules/hexo-theme-&lt;themename&gt;/source</code>里应该会有相关的图片，将自己想用的图片放在对应目录下，在配置文件选项里替换即可。</li>
<li>修改本地服务器的端口号
如果又建立了一个新的博客工作区，沿用上一套流程会发现无法通过<code>hexo s</code>命令启动本地服务器，因为4000端口被占用。如果想更改使用的端口（比如改成4001），可在<code>./package.json</code>文件中将<code>scripts</code>部分修改为：
<div class="code-container" data-rel="Json"><figure class="iseeu highlight json"><table><tr><td class="code"><pre><span class="line"><span class="attr">&quot;scripts&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;build&quot;</span><span class="punctuation">:</span> <span class="string">&quot;hexo generate&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;clean&quot;</span><span class="punctuation">:</span> <span class="string">&quot;hexo clean&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;deploy&quot;</span><span class="punctuation">:</span> <span class="string">&quot;hexo deploy&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;server&quot;</span><span class="punctuation">:</span> <span class="string">&quot;hexo server -p 4001&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br></pre></td></tr></table></figure></div>
但需要注意的是，此时不能再使用<code>hexo</code>系列命令操作，而是使用<code>npm</code>系列命令：
<div class="code-container" data-rel="Cmd"><figure class="iseeu highlight cmd"><table><tr><td class="code"><pre><span class="line">npm run build    # hexo g</span><br><span class="line">npm run clean    # hexo cl</span><br><span class="line">npm run deploy   # hexo d</span><br><span class="line">npm run server   # hexo s, 好像前面几个可以不换，这个必须换</span><br></pre></td></tr></table></figure></div></li>
<li>数学公式
直接在markdown文件中使用$标记数学公式在网页上是渲染不出来的，详情可参考<a class="link" 
 href="https://redefine-docs.ohevan.com/zh/plugins/mathjax" >这里<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>。但我遇到的一个问题是双美元符号中部分复杂公式还是渲染不出来的，简单的可以。这个问题我暂时还没有解决。

  <div class="note p-4 mb-4 rounded-small blue">
    <p>该问题现已解决，可参阅<a
href="/2025/02/05/hexo渲染数学公式问题解决">这篇博客</a>。</p>

  </div></li>
</ol>
<p>以上是我建立这个博客网站的经历分享，希望对大家有所帮助。<del class="mask">花了两天才差不多搞清楚，中间还是遇到了不少问题的T^T</del></p>
]]></content>
      <categories>
        <category>站务管理</category>
      </categories>
      <tags>
        <tag>经验分享</tag>
        <tag>Hexo</tag>
      </tags>
  </entry>
</search>
