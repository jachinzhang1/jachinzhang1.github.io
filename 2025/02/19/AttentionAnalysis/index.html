<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="keywords" content="Hexo Theme Redefine">
    
    <meta name="author" content="Jachin Zhang">
    <!-- preconnect -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>

    
    <!--- Seo Part-->
    
    <link rel="canonical" href="https://jachinzhang1.github.io/2025/02/19/attentionanalysis/"/>
    <meta name="robots" content="index,follow">
    <meta name="googlebot" content="index,follow">
    <meta name="revisit-after" content="1 days">
    
    
    
        
        <meta name="description" content="Hexo Theme Redefine, Redefine Your Hexo Journey.">
<meta property="og:type" content="article">
<meta property="og:title" content="注意力机制解析">
<meta property="og:url" content="https://jachinzhang1.github.io/2025/02/19/AttentionAnalysis/index.html">
<meta property="og:site_name" content="Jachin&#39;s Blog">
<meta property="og:description" content="Hexo Theme Redefine, Redefine Your Hexo Journey.">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://jachinzhang1.github.io/images/redefine-og.webp">
<meta property="article:published_time" content="2025-02-19T08:14:33.000Z">
<meta property="article:modified_time" content="2025-02-28T15:03:56.001Z">
<meta property="article:author" content="Jachin Zhang">
<meta property="article:tag" content="深度学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://jachinzhang1.github.io/images/redefine-og.webp">
    
    
    <!--- Icon Part-->
    <link rel="icon" type="image/png" href="/images/my-favicon-universe.svg" sizes="192x192">
    <link rel="apple-touch-icon" sizes="180x180" href="/images/my-favicon-universe.svg">
    <meta name="theme-color" content="#0098d7">
    <link rel="shortcut icon" href="/images/my-favicon-universe.svg">
    <!--- Page Info-->
    
    <title>
        
            注意力机制解析 | Jachin&#39;s Blog
        
    </title>

    
<link rel="stylesheet" href="/fonts/Chillax/chillax.css">


    <!--- Inject Part-->
    

    
<link rel="stylesheet" href="/css/style.css">


    
        
<link rel="stylesheet" href="/css/build/tailwind.css">

    

    
<link rel="stylesheet" href="/fonts/GeistMono/geist-mono.css">

    
<link rel="stylesheet" href="/fonts/Geist/geist.css">

    <!--- Font Part-->
    
    
    
    
    
    
        
<script src="/js/build/libs/anime.min.js"></script>

    

    <script id="hexo-configurations">
    window.config = {"hostname":"jachinzhang1.github.io","root":"/","language":"en","path":"search.xml"};
    window.theme = {"articles":{"style":{"font_size":"16px","line_height":1.5,"image_border_radius":"14px","image_alignment":"center","image_caption":true,"link_icon":true,"delete_mask":true,"title_alignment":"left","headings_top_spacing":{"h1":"2.5rem","h2":"2.0rem","h3":"1.7rem","h4":"1.3rem","h5":"1.1rem","h6":"1.0rem"}},"word_count":{"enable":true,"count":true,"min2read":true},"author_label":{"enable":false,"auto":false,"list":[]},"code_block":{"copy":true,"style":"simple","highlight_theme":{"light":"github","dark":"vs2015"},"font":{"enable":false,"family":null,"url":null}},"toc":{"enable":true,"max_depth":3,"number":true,"expand":true,"init_open":true},"copyright":{"enable":true,"default":"cc_by_nc_sa"},"lazyload":true,"pangu_js":false,"recommendation":{"enable":false,"title":"推荐阅读","limit":3,"mobile_limit":2,"placeholder":"/images/wallhaven-wqery6-light.webp","skip_dirs":[]}},"colors":{"primary":"#0098d7","secondary":null,"default_mode":"light"},"global":{"fonts":{"chinese":{"enable":false,"family":null,"url":null},"english":{"enable":false,"family":null,"url":null},"title":{"enable":false,"family":null,"url":null}},"content_max_width":"1000px","sidebar_width":"210px","hover":{"shadow":true,"scale":false},"scroll_progress":{"bar":true,"percentage":true},"website_counter":{"url":"https://cn.vercount.one/js","enable":true,"site_pv":true,"site_uv":true,"post_pv":true},"single_page":true,"preloader":{"enable":true,"custom_message":null},"open_graph":{"enable":true,"image":"/images/redefine-og.webp","description":"Hexo Theme Redefine, Redefine Your Hexo Journey."},"google_analytics":{"enable":false,"id":null}},"home_banner":{"enable":true,"style":"fixed","image":{"light":"/images/day.png","dark":"/images/night.png"},"title":"Welcome to my sekai.","subtitle":{"text":["Stay hungry, stay foolish.","(๑＞ڡ＜)☆"],"hitokoto":{"enable":false,"show_author":false,"api":"https://v1.hitokoto.cn"},"typing_speed":100,"backing_speed":80,"starting_delay":500,"backing_delay":1500,"loop":true,"smart_backspace":true},"text_color":{"light":"#000","dark":"#fff"},"text_style":{"title_size":"2.8rem","subtitle_size":"1.5rem","line_height":1.2},"custom_font":{"enable":false,"family":null,"url":null},"social_links":{"enable":true,"style":"default","links":{"github":"https://github.com/jachinzhang1","instagram":null,"zhihu":null,"twitter":null,"email":"3023518860@qq.com","bilibili":"https://space.bilibili.com/518197475?spm_id_from=333.1007.0.0"},"qrs":{"weixin":"/images/qrs/weixin.png","qq":"/images/qrs/qq.png"}}},"plugins":{"feed":{"enable":false},"aplayer":{"enable":false,"type":"fixed","audios":[{"name":null,"artist":null,"url":null,"cover":null,"lrc":null}]},"mermaid":{"enable":true,"version":"11.4.1"},"markdown-it-emoji":{"enable":true}},"version":"2.8.2","navbar":{"auto_hide":false,"color":{"left":"#f78736","right":"#367df7","transparency":35},"width":{"home":"1200px","pages":"1000px"},"links":{"Home":{"path":"/","icon":"fa-regular fa-house"},"文章":{"path":"/archives","icon":"fa-regular fa-archive"},"分类":{"path":"/categories","icon":"fa-regular fa-list"},"标签":{"path":"/tags","icon":"fa-regular fa-tags"},"Links":{"icon":"fa-regular fa-link","submenus":{"GITHUB":"https://github.com/jachinzhang1","BiliBili":"https://space.bilibili.com/518197475?spm_id_from=333.1007.0.0","资源分享":"/links/","相册":"/masonry/"}}},"search":{"enable":true,"preload":true}},"page_templates":{"friends_column":2,"tags_style":"blur"},"home":{"sidebar":{"enable":true,"position":"left","first_item":"menu","announcement":null,"show_on_mobile":true,"links":null},"article_date_format":"auto","excerpt_length":200,"categories":{"enable":true,"limit":3},"tags":{"enable":true,"limit":3}},"footerStart":"2025/2/2 00:00:00"};
    window.lang_ago = {"second":"%s seconds ago","minute":"%s minutes ago","hour":"%s hours ago","day":"%s days ago","week":"%s weeks ago","month":"%s months ago","year":"%s years ago"};
    window.data = {"masonry":true};
  </script>
    
    <!--- Fontawesome Part-->
    
<link rel="stylesheet" href="/fontawesome/fontawesome.min.css">

    
<link rel="stylesheet" href="/fontawesome/brands.min.css">

    
<link rel="stylesheet" href="/fontawesome/solid.min.css">

    
<link rel="stylesheet" href="/fontawesome/regular.min.css">

    
    
    
    
<meta name="generator" content="Hexo 7.3.0"></head>



<body>
	<div class="progress-bar-container">
	
	<span class="scroll-progress-bar"></span>
	

	
	<span class="pjax-progress-bar"></span>
	<!--        <span class="swup-progress-icon">-->
	<!--            <i class="fa-solid fa-circle-notch fa-spin"></i>-->
	<!--        </span>-->
	
</div>

<style>
    :root {
        --preloader-background-color: #fff;
        --preloader-text-color: #000;
    }

    @media (prefers-color-scheme: dark) {
        :root {
            --preloader-background-color: #202124;
            --preloader-text-color: #fff;
        }
    }

    @media (prefers-color-scheme: light) {
        :root {
            --preloader-background-color: #fff;
            --preloader-text-color: #000;
        }
    }

    @media (max-width: 600px) {
        .ml13 {
            font-size: 2.6rem !important; /* Adjust this value as needed */
        }
    }

    .preloader {
        display: flex;
        flex-direction: column;
        gap: 1rem; /* Tailwind 'gap-4' is 1rem */
        align-items: center;
        justify-content: center;
        position: fixed;
        padding: 12px;
        top: 0;
        right: 0;
        bottom: 0;
        left: 0;
        width: 100vw;
        height: 100vh; /* 'h-screen' is 100% of the viewport height */
        background-color: var(--preloader-background-color);
        z-index: 1100; /* 'z-[1100]' sets the z-index */
        transition: opacity 0.2s ease-in-out;
    }

    .ml13 {
        font-size: 3.2rem;
        /* text-transform: uppercase; */
        color: var(--preloader-text-color);
        letter-spacing: -1px;
        font-weight: 500;
        font-family: 'Chillax-Variable', sans-serif;
        text-align: center;
    }

    .ml13 .word {
        display: inline-flex;
        flex-wrap: wrap;
        white-space: nowrap;
    }

    .ml13 .letter {
        display: inline-block;
        line-height: 1em;
    }
</style>

<div class="preloader">
    <h2 class="ml13">
        Jachin&#39;s Blog
    </h2>
    <script>
        var textWrapper = document.querySelector('.ml13');
        // Split text into words
        var words = textWrapper.textContent.trim().split(' ');

        // Clear the existing content
        textWrapper.innerHTML = '';

        // Wrap each word and its letters in spans
        words.forEach(function(word) {
            var wordSpan = document.createElement('span');
            wordSpan.classList.add('word');
            wordSpan.innerHTML = word.replace(/\S/g, "<span class='letter'>$&</span>");
            textWrapper.appendChild(wordSpan);
            textWrapper.appendChild(document.createTextNode(' ')); // Add space between words
        });

        var animation = anime.timeline({ loop: true })
            .add({
                targets: '.ml13 .letter',
                translateY: [20, 0],
                translateZ: 0,
                opacity: [0, 1],
                filter: ['blur(5px)', 'blur(0px)'],
                easing: "easeOutExpo",
                duration: 1200,
                delay: (el, i) => 300 + 20 * i,
            })
            .add({
                targets: '.ml13 .letter',
                translateY: [0, -20],
                opacity: [1, 0],
                filter: ['blur(0px)', 'blur(5px)'],
                easing: "easeInExpo",
                duration: 1000,
                delay: (el, i) => 15 * i,
                complete: function() {
                    hidePreloader();
                }
            }, '-=700');


        let themeStatus = JSON.parse(localStorage.getItem('REDEFINE-THEME-STATUS'))?.isDark;

        // If the theme status is not found in local storage, check the preferred color scheme
        if (themeStatus === undefined || themeStatus === null) {
            if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches) {
                themeStatus = 'dark';
            } else {
                themeStatus = 'light';
            }
        }

        // Now you can use the themeStatus variable in your code
        if (themeStatus) {
            document.documentElement.style.setProperty('--preloader-background-color', '#202124');
            document.documentElement.style.setProperty('--preloader-text-color', '#fff');
        } else {
            document.documentElement.style.setProperty('--preloader-background-color', '#fff');
            document.documentElement.style.setProperty('--preloader-text-color', '#000');
        }

        window.addEventListener('load', function () {
            setTimeout(hidePreloader, 5000); // Call hidePreloader after 5000 milliseconds if not already called by animation
        });

        function hidePreloader() {
            var preloader = document.querySelector('.preloader');
            preloader.style.opacity = '0';
            setTimeout(function () {
                preloader.style.display = 'none';
            }, 200);
        }
    </script>
</div>

<main class="page-container" id="swup">

	

	<div class="main-content-container flex flex-col justify-between min-h-dvh">
		<div class="main-content-header">
			<header class="navbar-container px-6 md:px-12">
    <div class="navbar-content transition-navbar ">
        <div class="left">
            
            <a class="logo-title" href="/">
                
                Jachin&#39;s Blog
                
            </a>
        </div>

        <div class="right">
            <!-- PC -->
            <div class="desktop">
                <ul class="navbar-list">
                    
                        
                            

                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class=""
                                   href="/"
                                        >
                                    <i class="fa-regular fa-house fa-fw"></i>
                                    HOME
                                    
                                </a>

                                <!-- Submenu -->
                                
                            </li>
                    
                        
                            

                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class=""
                                   href="/archives"
                                        >
                                    <i class="fa-regular fa-archive fa-fw"></i>
                                    文章
                                    
                                </a>

                                <!-- Submenu -->
                                
                            </li>
                    
                        
                            

                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class=""
                                   href="/categories"
                                        >
                                    <i class="fa-regular fa-list fa-fw"></i>
                                    分类
                                    
                                </a>

                                <!-- Submenu -->
                                
                            </li>
                    
                        
                            

                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class=""
                                   href="/tags"
                                        >
                                    <i class="fa-regular fa-tags fa-fw"></i>
                                    标签
                                    
                                </a>

                                <!-- Submenu -->
                                
                            </li>
                    
                        
                            

                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class="has-dropdown"
                                   href="#"
                                        onClick=&#34;return false;&#34;>
                                    <i class="fa-regular fa-link fa-fw"></i>
                                    LINKS
                                    <i class="fa-solid fa-chevron-down fa-fw"></i>
                                </a>

                                <!-- Submenu -->
                                
                                    <ul class="sub-menu">
                                        
                                            <li>
                                                <a target="_blank" rel="noopener" href="https://github.com/jachinzhang1">
                                                    GITHUB
                                                </a>
                                            </li>
                                        
                                            <li>
                                                <a target="_blank" rel="noopener" href="https://space.bilibili.com/518197475?spm_id_from=333.1007.0.0">
                                                    BILIBILI
                                                </a>
                                            </li>
                                        
                                            <li>
                                                <a href="/links/">
                                                    资源分享
                                                </a>
                                            </li>
                                        
                                            <li>
                                                <a href="/masonry/">
                                                    相册
                                                </a>
                                            </li>
                                        
                                    </ul>
                                
                            </li>
                    
                    
                        <li class="navbar-item search search-popup-trigger">
                            <i class="fa-solid fa-magnifying-glass"></i>
                        </li>
                    
                </ul>
            </div>
            <!-- Mobile -->
            <div class="mobile">
                
                    <div class="icon-item search search-popup-trigger"><i class="fa-solid fa-magnifying-glass"></i>
                    </div>
                
                <div class="icon-item navbar-bar">
                    <div class="navbar-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <!-- Mobile sheet -->
    <div class="navbar-drawer h-dvh w-full absolute top-0 left-0 bg-background-color flex flex-col justify-between">
        <ul class="drawer-navbar-list flex flex-col px-4 justify-center items-start">
            
                
                    

                    <li class="drawer-navbar-item text-base my-1.5 flex flex-col w-full">
                        
                        <a class="py-1.5 px-2 flex flex-row items-center justify-between gap-1 hover:!text-primary active:!text-primary text-2xl font-semibold group border-b border-border-color hover:border-primary w-full "
                           href="/"
                        >
                            <span>
                                HOME
                            </span>
                            
                                <i class="fa-regular fa-house fa-sm fa-fw"></i>
                            
                        </a>
                        

                        
                    </li>
            
                
                    

                    <li class="drawer-navbar-item text-base my-1.5 flex flex-col w-full">
                        
                        <a class="py-1.5 px-2 flex flex-row items-center justify-between gap-1 hover:!text-primary active:!text-primary text-2xl font-semibold group border-b border-border-color hover:border-primary w-full "
                           href="/archives"
                        >
                            <span>
                                文章
                            </span>
                            
                                <i class="fa-regular fa-archive fa-sm fa-fw"></i>
                            
                        </a>
                        

                        
                    </li>
            
                
                    

                    <li class="drawer-navbar-item text-base my-1.5 flex flex-col w-full">
                        
                        <a class="py-1.5 px-2 flex flex-row items-center justify-between gap-1 hover:!text-primary active:!text-primary text-2xl font-semibold group border-b border-border-color hover:border-primary w-full "
                           href="/categories"
                        >
                            <span>
                                分类
                            </span>
                            
                                <i class="fa-regular fa-list fa-sm fa-fw"></i>
                            
                        </a>
                        

                        
                    </li>
            
                
                    

                    <li class="drawer-navbar-item text-base my-1.5 flex flex-col w-full">
                        
                        <a class="py-1.5 px-2 flex flex-row items-center justify-between gap-1 hover:!text-primary active:!text-primary text-2xl font-semibold group border-b border-border-color hover:border-primary w-full "
                           href="/tags"
                        >
                            <span>
                                标签
                            </span>
                            
                                <i class="fa-regular fa-tags fa-sm fa-fw"></i>
                            
                        </a>
                        

                        
                    </li>
            
                
                    

                    <li class="drawer-navbar-item-sub text-base my-1.5 flex flex-col w-full">
                        
                        <div class="py-1.5 px-2 flex flex-row items-center justify-between gap-1 hover:!text-primary active:!text-primary cursor-pointer text-2xl font-semibold group border-b border-border-color hover:border-primary w-full "
                             navbar-data-toggle="submenu-Links"
                        >
                            <span>
                                LINKS
                            </span>
                            
                                <i class="fa-solid fa-chevron-right fa-sm fa-fw transition-all"></i>
                            
                        </div>
                        

                        
                            <div class="flex-col items-start px-2 py-2 hidden" data-target="submenu-Links">
                                
                                    <div class="drawer-navbar-item text-base flex flex-col justify-center items-start hover:underline active:underline hover:underline-offset-1 rounded-3xl">
                                        <a class=" text-third-text-color text-xl"
                                           target="_blank" rel="noopener" href="https://github.com/jachinzhang1">GITHUB</a>
                                    </div>
                                
                                    <div class="drawer-navbar-item text-base flex flex-col justify-center items-start hover:underline active:underline hover:underline-offset-1 rounded-3xl">
                                        <a class=" text-third-text-color text-xl"
                                           target="_blank" rel="noopener" href="https://space.bilibili.com/518197475?spm_id_from=333.1007.0.0">BILIBILI</a>
                                    </div>
                                
                                    <div class="drawer-navbar-item text-base flex flex-col justify-center items-start hover:underline active:underline hover:underline-offset-1 rounded-3xl">
                                        <a class=" text-third-text-color text-xl"
                                           href="/links/">资源分享</a>
                                    </div>
                                
                                    <div class="drawer-navbar-item text-base flex flex-col justify-center items-start hover:underline active:underline hover:underline-offset-1 rounded-3xl">
                                        <a class=" text-third-text-color text-xl"
                                           href="/masonry/">相册</a>
                                    </div>
                                
                            </div>
                        
                    </li>
            

            
            
        </ul>

        <div class="statistics flex justify-around my-2.5">
    <a class="item tag-count-item flex flex-col justify-center items-center w-20" href="/tags">
        <div class="number text-2xl sm:text-xl text-second-text-color font-semibold">7</div>
        <div class="label text-third-text-color text-sm">Tags</div>
    </a>
    <a class="item tag-count-item flex flex-col justify-center items-center w-20" href="/categories">
        <div class="number text-2xl sm:text-xl text-second-text-color font-semibold">4</div>
        <div class="label text-third-text-color text-sm">Categories</div>
    </a>
    <a class="item tag-count-item flex flex-col justify-center items-center w-20" href="/archives">
        <div class="number text-2xl sm:text-xl text-second-text-color font-semibold">12</div>
        <div class="label text-third-text-color text-sm">Posts</div>
    </a>
</div>
    </div>

    <div class="window-mask"></div>

</header>


		</div>

		<div class="main-content-body transition-fade-up">
			

			<div class="main-content">
				<div class="post-page-container flex relative justify-between box-border w-full h-full">
	<div class="article-content-container">

		<div class="article-title relative w-full">
			
			<div class="w-full flex items-center pt-6 justify-start">
				<h1 class="article-title-regular text-second-text-color tracking-tight text-4xl md:text-6xl font-semibold px-2 sm:px-6 md:px-8 py-3">注意力机制解析</h1>
			</div>
			
		</div>

		
		<div class="article-header flex flex-row gap-2 items-center px-2 sm:px-6 md:px-8">
			<div class="avatar w-[46px] h-[46px] flex-shrink-0 rounded-medium border border-border-color p-[1px]">
				<img src="/images/luna_jp.png">
			</div>
			<div class="info flex flex-col justify-between">
				<div class="author flex items-center">
					<span class="name text-default-text-color text-lg font-semibold">Jachin Zhang</span>
					
				</div>
				<div class="meta-info">
					<div class="article-meta-info">
    <span class="article-date article-meta-item">
        <i class="fa-regular fa-pen-fancy"></i>&nbsp;
        <span class="desktop">2025-02-19 16:14:33</span>
        <span class="mobile">2025-02-19 16:14:33</span>
        <span class="hover-info">Created</span>
    </span>
    
        <span class="article-date article-meta-item">
            <i class="fa-regular fa-wrench"></i>&nbsp;
            <span class="desktop">2025-02-28 23:03:56</span>
            <span class="mobile">2025-02-28 23:03:56</span>
            <span class="hover-info">Updated</span>
        </span>
    

    
        <span class="article-categories article-meta-item">
            <i class="fa-regular fa-folders"></i>&nbsp;
            <ul>
                
                
                    
                        
                        <li>
                            <a href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">学习笔记</a>&nbsp;
                        </li>
                    
                    
                
            </ul>
        </span>
    
    
        <span class="article-tags article-meta-item">
            <i class="fa-regular fa-tags"></i>&nbsp;
            <ul>
                
                    <li>
                        <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a>&nbsp;
                    </li>
                
            </ul>
        </span>
    

    
    
        <span class="article-wordcount article-meta-item">
            <i class="fa-regular fa-typewriter"></i>&nbsp;<span>2.5k Words</span>
        </span>
    
    
        <span class="article-min2read article-meta-item">
            <i class="fa-regular fa-clock"></i>&nbsp;<span>9 Mins</span>
        </span>
    
    
        <span class="article-pv article-meta-item">
            <i class="fa-regular fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv"></span>
        </span>
    
</div>

				</div>
			</div>
		</div>
		

		


		<div class="article-content markdown-body px-2 sm:px-6 md:px-8 pb-8">
			
  <div class="note-large blue">
    <div class="notel-title rounded-t-lg p-3 font-bold text-lg flex flex-row gap-2 items-center">
      <p>原论文指路</p>

    </div>
    <div class="notel-content">
      <p><a class="link"   target="_blank" rel="noopener" href="https://arxiv.org/abs/1706.03762" >Attention is All You
Need<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>

    </div>
  </div>
<h2 id="背景">背景</h2>
<p>注意力机制早在2014年便被首次用于计算机视觉领域，试图理解神经网络进行预测时正在观察的位置。2015年注意力机制开始用于NLP领域，后于2017年被加入Transformer网络中用于语言建模。Transformers解决了RNN存在的长程依赖、梯度消失和梯度爆炸、所需训练开销和无法并行计算等问题，取代了RNN在NLP领域的统治地位，成为该领域最受欢迎的技术。</p>
<h2 id="词嵌入-embedding">词嵌入 (embedding)</h2>
<p>对于自然语言文本，计算机难以直接使用，因此在NLP中第一步都是将自然语言的单词转化为等长的向量，这个过程叫做<b>嵌入</b>。向量的每个维度都有其潜在的含义，只不过在具体实践中难以对每个维度的含义做具体解释。</p>
<p>词嵌入并无普遍标准，同一个词的嵌入也会因为任务、神经网络、训练阶段的不同而不同。初始嵌入为随机值，在训练期间会不断调整从而最小化神经网络的误差。</p>
<p>举个例子，我们要将这句话输进计算机做处理：</p>
<p><centering>I will come and teach you how to do this
tomorrow.</centering></p>
<p>句子被输入计算机时，程序将该字符串分为若干个token <span
class="math inline">\(t\)</span>，每个token生成一个词嵌入<span
class="math inline">\(a\)</span>。但此时这些词嵌入不包含上下文信息，即对程序来说，这些词嵌入组合相当于一个无序地装着多个单词的词袋，包含的信息十分有限。</p>
<p>而当我们分析句中单词的语义时会发现单词间的关联程度并不和它们之间的距离直接相关，例如will和tomorrow的关联程度明显比其与come的关联程度更高。因此<b>词语之间的关联程度需要根据上下文的语境决定</b>。接下来我们试图调整tokens的词嵌入，使其包含上下文信息。</p>
<h2 id="缩放点积注意力的推导">缩放点积注意力的推导</h2>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/attention/selfattn_1.png"
                      
                ></p>
<p>如图，<span
class="math inline">\(a^i\)</span>是不含上下文信息的词嵌入（这里以NLP的过程为例，事实上注意力机制还可以用于图像处理等，<span
class="math inline">\(a^i\)</span>可为初始输入或来自某个模型的输出），输出的结果<span
class="math inline">\(b^i\)</span>与所有词嵌入都有关。当我们了解<span
class="math inline">\(b^1\)</span>向量如何产生之后，其余向量的产生过程都可以很容易得到。产生<span
class="math inline">\(b^1\)</span>向量的首要步骤是找到<span
class="math inline">\(a^1\)</span>与其他向量的关联程度（也称注意力分数）。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/attention/selfattn_2.png"
                      
                ></p>
<p>对于求<span
class="math inline">\(a^i,a^j\)</span>之间的注意力分数<span
class="math inline">\(\alpha_{i,j}\)</span>，最常用的方法是求出<span
class="math inline">\(a^i\)</span>的查询（query）向量 <span
class="math display">\[
q^i=W^qa^i
\]</span> 求出<span class="math inline">\(a^j\)</span>的键值（key）向量
<span class="math display">\[
k^j=W^ka^j
\]</span> 则注意力分数为查询向量和键值向量的点积 <span
class="math display">\[
\alpha_{i,j}=q^i\cdot k^j
\]</span></p>
<p>这里求<span
class="math inline">\(a^1\)</span>与其他嵌入向量的关联度，求出其查询向量<span
class="math inline">\(q^1\)</span>之后与所有嵌入向量的键值向量<span
class="math inline">\(k^i(i=1,2,3,4)\)</span>做点积，最后对求出的关联度向量组作softmax归一化。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/attention/selfattn_3.png"
                      
                ></p>
<p>这个步骤可以简单理解为：在搜索引擎中输入的内容为<span
class="math inline">\(q\)</span>，搜索到的结果展示了各种信息的键值<span
class="math inline">\(k\)</span>，可以通过键值得到信息的内容（值，value）<span
class="math inline">\(v\)</span>本身。而关联度<span
class="math inline">\(\alpha\)</span>展示了这些信息与我们输入的内容的相关性有多大，这个值越大说明这个键值对应的内容和我输入的查询内容相关程度越高。</p>

  <div class="note p-4 mb-4 rounded-small blue">
    <p>该步骤的激活函数并非必须为softmax，使用其他激活函数（如RELU，GELU等）也可，并且可能达到更好的效果。</p>

  </div>
<p>得到<span
class="math inline">\(a^1\)</span>与自身及其他几个嵌入向量的注意力分数之后，将这些分数与其对应向量的值向量相乘然后求和，即可得到添加了上下文信息的嵌入<span
class="math inline">\(b^1\)</span>。值向量可通过下式求得： <span
class="math display">\[
v^i=W^va^i
\]</span></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/attention/selfattn_4.png"
                      
                ></p>
<p>其余<span
class="math inline">\(b\)</span>向量的产生过程同理。值得注意的是，这个过程并不需要依序产生，所有<span
class="math inline">\(b\)</span>向量可以通过一组矩阵运算同时产生。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/attention/selfattn_5.png"
                      
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/attention/selfattn_6.png"
                      
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/attention/selfattn_7.png"
                      
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/attention/selfattn_8.png"
                      
                ></p>
<p>使用向量形式可以非常简洁地表述上述过程。假设： - <b>查询矩阵</b><span
class="math inline">\(Q\in\mathbb{R}^{m\times d_k}\)</span>(<span
class="math inline">\(m\)</span>表示查询的个数，<span
class="math inline">\(d_k\)</span>是查询向量的维度) - <b>键矩阵</b><span
class="math inline">\(K\in\mathbb{R}^{n\times d_k}\)</span>(<span
class="math inline">\(n\)</span>表示键的个数) - <b>值矩阵</b><span
class="math inline">\(V\in\mathbb{R}^{n\times d_v}\)</span></p>
<p>每个查询<span class="math inline">\(q^i\)</span>和每个键<span
class="math inline">\(k^j\)</span>之间的相似度用点积计算（如式<span
class="math inline">\((3)\)</span>），则所有查询和所有键的点积可以用矩阵表示：
<span class="math display">\[
A=QK^T
\]</span></p>
<p>其中<span class="math inline">\(A\in\mathbb{R}^{m\times
n}\)</span>是所有查询和所有键的相似度矩阵。接着采用softmax对<span
class="math inline">\(A\)</span>进行归一化处理（对矩阵的每一行进行归一化）：
<span class="math display">\[
A^\prime = \mathrm{softmax}(A)
\]</span></p>
<p>最终注意力的输出值是值<span
class="math inline">\(V\)</span>的加权求和： <span
class="math display">\[
o_i = \sum_{j=1}^n{\alpha^\prime_{ij}v_j}
\]</span></p>
<p>即 <span class="math display">\[
O=AV
\]</span> 其中<span class="math inline">\(O\in\mathbb{R}^{m\times
d_v}\)</span>是最终的注意力输出矩阵。</p>
<p>值得注意的是，作者在<a class="link" 
 target="_blank" rel="noopener" href="https://arxiv.org/abs/1706.03762" >原论文<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>中提出了<b>缩放因子</b>：
<span class="math display">\[
A=\frac{QK^T}{\sqrt{d_k}}
\]</span></p>
<p>其原因是：点积值的大小随着<span
class="math inline">\(d_k\)</span>增大而增大。如果<span
class="math inline">\(d_k\)</span>很大，<span
class="math inline">\(QK^T\)</span>的数值会很大，导致Softmax计算时指数项变大，使得梯度消失或过于集中于某些键值，确保注意力分布合理。</p>
<p>最终我们得到了完整的注意力机制公式： <span class="math display">\[
\mathrm{Attention}(Q,K,V)=\mathrm{softmax}\Big(\frac{QK^T}{\sqrt{d}}\Big)V
\]</span></p>
<p><strong>整个过程只有矩阵<span
class="math inline">\(W^Q,W^K,W^V\)</span>是需要训练的。</strong></p>

  <div class="note p-4 mb-4 rounded-small blue">
    <p>在机器翻译或文本生成的任务中，通常需要预测下一个单词出现的概率，这类任务要求注意力只能放在下一个词，不能放在更往后的词上。简而言之，<strong>注意力矩阵不能有非平凡的超对角线分量</strong>。这时我们可以通过添加<strong>掩码矩阵</strong><span
class="math inline">\(M\)</span>来修正注意力，消除神经网络对未来的了解。即
<span class="math display">\[
\mathrm{Attention}(Q,K,V)=\mathrm{softmax}\Big(\frac{QK^T}{\sqrt{d}}+M\Big)V
\]</span></p>
<p>其中， <span class="math display">\[
\begin{aligned}
    M&amp;=\left( m_{i,j} \right) _{i,j=0}^{n}\\
    m_{i,j}&amp;=\begin{cases}
    0&amp;      i\ge j\\
    -\infty&amp;        i&lt;j\\
\end{cases}\\
\end{aligned}
\]</span></p>

  </div>
<p>利用神经网络结构表示注意力机制如下图所示：</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/attention/selfattn_nn.png"
                      
                ></p>

  <div class="note-large blue">
    <div class="notel-title rounded-t-lg p-3 font-bold text-lg flex flex-row gap-2 items-center">
      <p>如何更好地理解注意力机制中的Q,K,V？</p>

    </div>
    <div class="notel-content">
      <ul>
<li><a class="link" 
 target="_blank" rel="noopener" href="https://www.zhihu.com/question/298810062/answer/2274132657" >iynil的回答
- 知乎<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link" 
 target="_blank" rel="noopener" href="https://www.zhihu.com/question/298810062/answer/86505956036" >司马懿的回答
- 知乎<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link" 
 target="_blank" rel="noopener" href="https://www.zhihu.com/question/298810062/answer/1828080188" >陀飞轮的回答
- 知乎<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
</ul>

    </div>
  </div>
<h2 id="多头注意力机制">多头注意力机制</h2>
<p>有时，只用一个注意力头可能无法很好捕捉多个词在语境上复杂的关联。因此，可以添加更多线性层作为键、查询和值。这些线性层在每轮并行训练，彼此权重独立，每层都各提供一个输出，从而各算出独立的权重。每一层被称为一个“头”。可以有任意数量<span
class="math inline">\(h\)</span>个线性层，提供<span
class="math inline">\(h\)</span>个注意力输出，然后将它们连接在一起。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/attention/multihead.png"
                      
                ></p>
<p>仿照上述的向量表示方法，多头注意力可以表示为 <span
class="math display">\[
\begin{aligned}\mathrm{head}_i&amp;=\text{Attention}(QW_i^Q,KW_i^K,VW_i^V)\\
\text{MultiHead}&amp;=\text{Concat}(\text{head}_1,\text{head}_2,\ldots,\text{head}_k)W^O\end{aligned}
\]</span></p>
<p>其中<span
class="math inline">\(QW_i^Q,KW_i^K,VW_i^V\)</span>是不同头的参数矩阵。通过多个头学习不同的注意力模式，最终拼接后投影到输出空间。多头注意力能够提高模型的表达能力，并增强不同语义层次的表示。</p>
<figure>
<figure class="image-caption"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/posts/attention/multihead_nn.png"
                     
alt="多头注意力的神经网络结构表示" 
                ><figcaption>多头注意力的神经网络结构表示</figcaption></figure>
<figcaption aria-hidden="true">多头注意力的神经网络结构表示</figcaption>
</figure>
<h2 id="缩放点积注意力的pytorch实现">缩放点积注意力的Pytorch实现</h2>
<p>使用类<code>ScaledDotProductAttention</code>实现该注意力机制的模型：</p>
<div class="code-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ScaledDotProductAttention</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, d_k</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;设置key和query的维度&quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">super</span>(ScaledDotProductAttention, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.d_k = d_k</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, Q: torch.Tensor, K: torch.Tensor, V: torch.Tensor, mask=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="comment"># 计算Q和K的点积并缩放</span></span><br><span class="line">        scores = torch.matmul(Q, K.transpose(-<span class="number">2</span>, -<span class="number">1</span>) / torch.sqrt(torch.tensor(<span class="variable language_">self</span>.d_k)))</span><br><span class="line">        <span class="comment"># 如果有掩码，对无效部分取负无穷使得softmax后归一化权重趋近于0</span></span><br><span class="line">        <span class="keyword">if</span> mask:</span><br><span class="line">            scores = scores.masked_fill(mask==<span class="number">0</span>, <span class="built_in">float</span>(<span class="string">&#x27;-inf&#x27;</span>))</span><br><span class="line">        <span class="comment"># 使用softmax归一化计算注意力权重</span></span><br><span class="line">        attention_weights = torch.softmax(scores, dim=-<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 计算最终的注意力输出</span></span><br><span class="line">        output = torch.matmul(attention_weights, V)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> output, attention_weights</span><br></pre></td></tr></table></figure></div>
<p>接下来设置参数并尝试运行：</p>
<div class="code-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">batch_size, n_heads, seq_len, d_k, d_v = <span class="number">1</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">3</span></span><br><span class="line">Q = torch.rand(batch_size, n_heads, seq_len, d_k)</span><br><span class="line">K = torch.rand(batch_size, n_heads, seq_len, d_k)</span><br><span class="line">V = torch.rand(batch_size, n_heads, seq_len, d_v)</span><br><span class="line">attention = ScaledDotProductAttention(d_k)</span><br><span class="line">output, attn_weights = attention(Q, K, V)</span><br><span class="line"><span class="built_in">print</span>(output.shape)  <span class="comment"># (batch_size, n_heads, seq_len, d_v)</span></span><br><span class="line"><span class="built_in">print</span>(attn_weights.shape)  <span class="comment"># (batch_size, n_heads, seq_len, d_k)</span></span><br></pre></td></tr></table></figure></div>
<p>对于其中各个参数和输出结果含义的解释： -
<code>batch_size</code>可理解为句子的数量（一次处理多少个句子） -
<code>n_heads</code>代表注意力头的数量 -
<code>seq_len</code>代表一个句子中包含多少个词元（tokens） -
<code>d_k</code>设置了query和key的维度 -
<code>d_v</code>设置了value的维度 -
<code>output</code>表示在输入的序列中，每个词元的value根据其他词元的相关性加权之后的结果，作为每个位置的最终表示
-
<code>attn_weights</code>是注意力分配给每个位置的权重，决定了查询<code>i</code>在计算输出时，从键<code>j</code>的值<code>V[j]</code>获取信息的程度</p>
<p>输出结果： <div class="code-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">torch.Size([1, 1, 5, 3])</span><br><span class="line">torch.Size([1, 1, 5, 5])</span><br></pre></td></tr></table></figure></div></p>

  <div class="note-large blue">
    <div class="notel-title rounded-t-lg p-3 font-bold text-lg flex flex-row gap-2 items-center">
      <p>参考信息</p>

    </div>
    <div class="notel-content">
      <p><a class="link" 
 target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1xM4m1m7vA?p=6" >【强烈推荐】零基础入门【大模型、多模态】CLIP
！-哔哩哔哩<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><a class="link" 
 target="_blank" rel="noopener" href="https://blog.csdn.net/jarodyv/article/details/130867562" >【万字长文】深度解析
Transformer
和注意力机制（含完整代码实现）_transformer架构注意力机制-CSDN博客<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>

    </div>
  </div>

		</div>

		
		<div class="post-copyright-info w-full my-8 px-2 sm:px-6 md:px-8">
			<div class="article-copyright-info-container">
    <ul>
        <li><strong>Title:</strong> 注意力机制解析</li>
        <li><strong>Author:</strong> Jachin Zhang</li>
        <li><strong>Created at
                :</strong> 2025-02-19 16:14:33</li>
        
            <li>
                <strong>Updated at
                    :</strong> 2025-02-28 23:03:56
            </li>
        
        <li>
            <strong>Link:</strong> https://jachinzhang1.github.io/2025/02/19/AttentionAnalysis/
        </li>
        <li>
            <strong>
                License:
            </strong>
            

            
                This work is licensed under <a class="license" target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0">CC BY-NC-SA 4.0</a>.
            
        </li>
    </ul>
</div>

		</div>
		

		
		<ul class="post-tags-box text-lg mt-1.5 flex-wrap justify-center flex md:hidden">
			
			<li class="tag-item mx-0.5">
				<a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">#深度学习</a>&nbsp;
			</li>
			
		</ul>
		

		

		
		<div class="article-nav my-8 flex justify-between items-center px-2 sm:px-6 md:px-8">
			
			<div class="article-prev border-border-color shadow-redefine-flat shadow-shadow-color-2 rounded-medium px-4 py-2 hover:shadow-redefine-flat-hover hover:shadow-shadow-color-2">
				<a class="prev" rel="prev" href="/2025/02/20/attncnn-imgclassify/">
					<span class="left arrow-icon flex justify-center items-center">
						<i class="fa-solid fa-chevron-left"></i>
					</span>
					<span class="title flex justify-center items-center">
						<span class="post-nav-title-item">深度学习基础：基于CNN网络进行图像分类</span>
						<span class="post-nav-item">Prev posts</span>
					</span>
				</a>
			</div>
			
			
			<div class="article-next border-border-color shadow-redefine-flat shadow-shadow-color-2 rounded-medium px-4 py-2 hover:shadow-redefine-flat-hover hover:shadow-shadow-color-2">
				<a class="next" rel="next" href="/2025/02/17/unet/">
					<span class="title flex justify-center items-center">
						<span class="post-nav-title-item">UNet结构介绍</span>
						<span class="post-nav-item">Next posts</span>
					</span>
					<span class="right arrow-icon flex justify-center items-center">
						<i class="fa-solid fa-chevron-right"></i>
					</span>
				</a>
			</div>
			
		</div>
		


		
		<div class="comment-container px-2 sm:px-6 md:px-8 pb-8">
			<div class="comments-container mt-10 w-full ">
    <div id="comment-anchor" class="w-full h-2.5"></div>
    <div class="comment-area-title w-full my-1.5 md:my-2.5 text-xl md:text-3xl font-bold">
        Comments
    </div>
    

        
            
    <div id="giscus-container"></div>
    <script data-swup-reload-script defer>
        async function loadGiscus() {
            const giscusConfig = {
                'src': 'https://giscus.app/client.js',
                'data-repo': 'jachinzhang1/jachinzhang1.github.io',
                'data-repo-id': 'R_kgDONy_q0w',
                'data-category': 'Announcements',
                'data-category-id': 'DIC_kwDONy_q084Cmo0P',
                'data-mapping': 'title',
                'data-strict': '0',
                'data-reactions-enabled': '1',
                'data-emit-metadata': '1',
                'data-theme': 'preferred_color_scheme',
                'data-lang': 'zh-CN',
                'data-input-position': 'top',
                'data-loading': 'lazy',
                'crossorigin': 'anonymous',
                'async': true
            }
            const giscusScript = document.createElement('script');
            for (const key in giscusConfig) {
                giscusScript.setAttribute(key, giscusConfig[key]);
            }
            document.getElementById('giscus-container').appendChild(giscusScript);
        }
        if ('true') {
            let loadGiscusTimeout = setTimeout(() => {
                loadGiscus();
                clearTimeout(loadGiscusTimeout);
            }, 1000);
        } else {
            document.addEventListener('DOMContentLoaded', loadGiscus);
        }
    </script>


        
        
    
</div>

		</div>
		
	</div>

	
	<div class="toc-content-container">
		<div class="post-toc-wrap">
	<div class="post-toc">
		<div class="toc-title">On this page</div>
		<div class="page-title">注意力机制解析</div>
		<ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%83%8C%E6%99%AF"><span class="nav-number">1.</span> <span class="nav-text">背景</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%AF%8D%E5%B5%8C%E5%85%A5-embedding"><span class="nav-number">2.</span> <span class="nav-text">词嵌入 (embedding)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BC%A9%E6%94%BE%E7%82%B9%E7%A7%AF%E6%B3%A8%E6%84%8F%E5%8A%9B%E7%9A%84%E6%8E%A8%E5%AF%BC"><span class="nav-number">3.</span> <span class="nav-text">缩放点积注意力的推导</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A4%9A%E5%A4%B4%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6"><span class="nav-number">4.</span> <span class="nav-text">多头注意力机制</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BC%A9%E6%94%BE%E7%82%B9%E7%A7%AF%E6%B3%A8%E6%84%8F%E5%8A%9B%E7%9A%84pytorch%E5%AE%9E%E7%8E%B0"><span class="nav-number">5.</span> <span class="nav-text">缩放点积注意力的Pytorch实现</span></a></li></ol>

	</div>
</div>
	</div>
	
</div>
			</div>

			
		</div>

		<div class="main-content-footer">
			<footer class="footer mt-5 py-5 h-auto text-base text-third-text-color relative border-t-2 border-t-border-color">
    <div class="info-container py-3 text-center">
        
        <div class="text-center">
            &copy;
            
              <span>2025</span>
              -
            
            2025&nbsp;&nbsp;<i class="fa-solid fa-heart fa-beat" style="--fa-animation-duration: 0.5s; color: #f54545"></i>&nbsp;&nbsp;<a href="/">Jachin Zhang</a>
            
        </div>
        
            <script data-swup-reload-script src="https://cn.vercount.one/js"></script>
            <div class="relative text-center lg:absolute lg:right-[20px] lg:top-1/2 lg:-translate-y-1/2 lg:text-right">
                
                    <span id="busuanzi_container_site_uv" class="lg:!block">
                        <span class="text-sm">VISITOR COUNT</span>
                        <span id="busuanzi_value_site_uv"></span>
                    </span>
                
                
                    <span id="busuanzi_container_site_pv" class="lg:!block">
                        <span class="text-sm">TOTAL PAGE VIEWS</span>
                        <span id="busuanzi_value_site_pv"></span>
                    </span>
                
            </div>
        
        <div class="relative text-center lg:absolute lg:left-[20px] lg:top-1/2 lg:-translate-y-1/2 lg:text-left">
            <span class="lg:block text-sm">POWERED BY <?xml version="1.0" encoding="utf-8"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg class="relative top-[2px] inline-block align-baseline" version="1.1" id="圖層_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" width="1rem" height="1rem" viewBox="0 0 512 512" enable-background="new 0 0 512 512" xml:space="preserve"><path fill="#0E83CD" d="M256.4,25.8l-200,115.5L56,371.5l199.6,114.7l200-115.5l0.4-230.2L256.4,25.8z M349,354.6l-18.4,10.7l-18.6-11V275H200v79.6l-18.4,10.7l-18.6-11v-197l18.5-10.6l18.5,10.8V237h112v-79.6l18.5-10.6l18.5,10.8V354.6z"/></svg><a target="_blank" class="text-base" href="https://hexo.io">Hexo</a></span>
            <span class="text-sm lg:block">THEME&nbsp;<a class="text-base" target="_blank" href="https://github.com/EvanNotFound/hexo-theme-redefine">Redefine v2.8.2</a></span>
        </div>
        
        
            <div>
                Blog up for <span class="odometer" id="runtime_days" ></span> days <span class="odometer" id="runtime_hours"></span> hrs <span class="odometer" id="runtime_minutes"></span> Min <span class="odometer" id="runtime_seconds"></span> Sec
            </div>
        
        
            <script data-swup-reload-script>
                try {
                    function odometer_init() {
                    const elements = document.querySelectorAll('.odometer');
                    elements.forEach(el => {
                        new Odometer({
                            el,
                            format: '( ddd).dd',
                            duration: 200
                        });
                    });
                    }
                    odometer_init();
                } catch (error) {}
            </script>
        
        
        
    </div>  
</footer>
		</div>
	</div>

	
	<div class="post-tools">
		<div class="post-tools-container">
	<ul class="article-tools-list">
		<!-- TOC aside toggle -->
		
		<li class="right-bottom-tools page-aside-toggle">
			<i class="fa-regular fa-outdent"></i>
		</li>
		

		<!-- go comment -->
		
		<li class="go-comment">
			<i class="fa-regular fa-comments"></i>
		</li>
		
	</ul>
</div>
	</div>
	

	<div class="right-side-tools-container">
		<div class="side-tools-container">
	<ul class="hidden-tools-list">
		<li class="right-bottom-tools tool-font-adjust-plus flex justify-center items-center">
			<i class="fa-regular fa-magnifying-glass-plus"></i>
		</li>

		<li class="right-bottom-tools tool-font-adjust-minus flex justify-center items-center">
			<i class="fa-regular fa-magnifying-glass-minus"></i>
		</li>

		<li class="right-bottom-tools tool-dark-light-toggle flex justify-center items-center">
			<i class="fa-regular fa-moon"></i>
		</li>

		<!-- rss -->
		

		

		<li class="right-bottom-tools tool-scroll-to-bottom flex justify-center items-center">
			<i class="fa-regular fa-arrow-down"></i>
		</li>
	</ul>

	<ul class="visible-tools-list">
		<li class="right-bottom-tools toggle-tools-list flex justify-center items-center">
			<i class="fa-regular fa-cog fa-spin"></i>
		</li>
		
		<li class="right-bottom-tools tool-scroll-to-top flex justify-center items-center">
			<i class="arrow-up fas fa-arrow-up"></i>
			<span class="percent"></span>
		</li>
		
		
	</ul>
</div>
	</div>

	<div class="image-viewer-container">
	<img src="">
</div>

	
	<div class="search-pop-overlay">
	<div class="popup search-popup">
		<div class="search-header">
			<span class="search-input-field-pre">
				<i class="fa-solid fa-keyboard"></i>
			</span>
			<div class="search-input-container">
				<input autocomplete="off" autocorrect="off" autocapitalize="off" placeholder="Search..." spellcheck="false" type="search" class="search-input">
			</div>
			<span class="popup-btn-close">
				<i class="fa-solid fa-times"></i>
			</span>
		</div>
		<div id="search-result">
			<div id="no-result">
				<i class="fa-solid fa-spinner fa-spin-pulse fa-5x fa-fw"></i>
			</div>
		</div>
	</div>
</div>
	

</main>



<script src="/js/build/libs/Swup.min.js"></script>

<script src="/js/build/libs/SwupSlideTheme.min.js"></script>

<script src="/js/build/libs/SwupScriptsPlugin.min.js"></script>

<script src="/js/build/libs/SwupProgressPlugin.min.js"></script>

<script src="/js/build/libs/SwupScrollPlugin.min.js"></script>

<script src="/js/build/libs/SwupPreloadPlugin.min.js"></script>

<script>
    const swup = new Swup({
        plugins: [
            new SwupScriptsPlugin({
                optin: true,
            }),
            new SwupProgressPlugin(),
            new SwupScrollPlugin({
                offset: 80,
            }),
            new SwupSlideTheme({
                mainElement: ".main-content-body",
            }),
            new SwupPreloadPlugin(),
        ],
        containers: ["#swup"],
    });
</script>





    

  
  

	
<script src="/js/build/tools/imageViewer.js" type="module"></script>

<script src="/js/build/utils.js" type="module"></script>

<script src="/js/build/main.js" type="module"></script>

<script src="/js/build/layouts/navbarShrink.js" type="module"></script>

<script src="/js/build/tools/scrollTopBottom.js" type="module"></script>

<script src="/js/build/tools/lightDarkSwitch.js" type="module"></script>

<script src="/js/build/layouts/categoryList.js" type="module"></script>



    
<script src="/js/build/tools/localSearch.js" type="module"></script>




    
<script src="/js/build/tools/codeBlock.js" type="module"></script>




    
<script src="/js/build/layouts/lazyload.js" type="module"></script>




    
<script src="/js/build/tools/runtime.js"></script>

    
<script src="/js/build/libs/odometer.min.js"></script>

    
<link rel="stylesheet" href="/assets/odometer-theme-minimal.css">




  
<script src="/js/build/libs/Typed.min.js"></script>

  
<script src="/js/build/plugins/typed.js" type="module"></script>




    
        
<script src="/js/build/libs/mermaid.min.js"></script>

    
    
<script src="/js/build/plugins/mermaid.js"></script>




    
<script src="/js/build/libs/minimasonry.min.js"></script>

    
<script src="/js/build/plugins/masonry.js" type="module"></script>







    
<script src="/js/build/tools/tocToggle.js" type="module" data-swup-reload-script=""></script>

<script src="/js/build/layouts/toc.js" type="module" data-swup-reload-script=""></script>

<script src="/js/build/plugins/tabs.js" type="module" data-swup-reload-script=""></script>




<script src="/js/build/libs/moment-with-locales.min.js" data-swup-reload-script=""></script>


<script src="/js/build/layouts/essays.js" type="module" data-swup-reload-script=""></script>





	
</body>

</html>